{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a33f243-19e5-406b-a177-317f98c978ca",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "## RIASEC<a class=\"anchor\" id=\"PTMD_page_23\"></a>\n",
    "\n",
    "[Back to Top](#PTMD_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a345784-80cb-4fb4-8f7e-cc9c30462345",
   "metadata": {},
   "source": [
    "**RIASEC**, also known as the Holland Codes or Holland's Six Personality Types, is a vocational model that categorizes individuals into six distinct personality types based on their career interests and preferences. Developed by psychologist John L. Holland, this model helps individuals identify suitable career paths and educational pursuits that align with their inherent characteristics and preferences.\n",
    "\n",
    "**Key Components of the RIASEC Model:**\n",
    "\n",
    "1. **Realistic (R):** Realistic individuals are practical, hands-on, and enjoy physical activities. They often prefer careers that involve tangible, concrete tasks and often work outdoors or in technical fields.\n",
    "\n",
    "2. **Investigative (I):** Investigative types are analytical, inquisitive, and enjoy problem-solving and intellectual challenges. They excel in careers that require research, analysis, and critical thinking.\n",
    "\n",
    "3. **Artistic (A):** Artistic individuals are creative, expressive, and imaginative. They thrive in careers that allow for artistic and creative expression, such as the arts, design, or writing.\n",
    "\n",
    "4. **Social (S):** Social types are cooperative, friendly, and empathetic. They excel in roles that involve helping and working closely with others, such as counseling, teaching, or healthcare.\n",
    "\n",
    "5. **Enterprising (E):** Enterprising individuals are persuasive, ambitious, and enjoy taking risks. They often seek careers in leadership, sales, or entrepreneurship.\n",
    "\n",
    "6. **Conventional (C):** Conventional types are organized, detail-oriented, and efficient. They prefer structured and systematic work environments, often excelling in roles related to administration, finance, or data analysis.\n",
    "\n",
    "**Practical Applications of the RIASEC Model:**\n",
    "\n",
    "- **Career Guidance:** RIASEC assessments are widely used in career counseling and guidance to help individuals explore potential career options that align with their personality types and interests.\n",
    "\n",
    "- **Education Planning:** Educational institutions use the model to assist students in selecting majors and courses that match their strengths and preferences.\n",
    "\n",
    "- **Workforce Development:** Organizations and employers use the RIASEC model to assess employee strengths and preferences, helping with career development and job placement.\n",
    "\n",
    "- **Team Building:** Understanding team members' RIASEC profiles can enhance team dynamics by ensuring that individuals are placed in roles that suit their personalities and strengths.\n",
    "\n",
    "- **Personal Development:** Individuals can use the RIASEC model for personal growth and self-riasecovery, helping them make informed decisions about their careers and educational paths.\n",
    "\n",
    "- **Career Change:** The model is valuable for individuals considering a career change, as it provides insights into alternative career options that may be more fulfilling.\n",
    "\n",
    "In summary, the RIASEC model, developed by John L. Holland, categorizes individuals into six personality types based on their career interests and preferences. It is a valuable tool for career guidance, education planning, workforce development, team building, and personal development, helping individuals make informed decisions about their careers and educational pursuits. By aligning career choices with personality types, individuals are more likely to find job satisfaction and success in their chosen fields.\n",
    "\n",
    "Timeline and reference table for the RIASEC model, also known as Holland Codes or the Holland Occupational Themes (HOT), involves outlining key developments of this vocational personality framework. Developed by psychologist John L. Holland, RIASEC represents six personality types and their alignment with different career paths. \n",
    "\n",
    "### RIASEC Model (Holland Codes) Timeline and Reference Table\n",
    "\n",
    "| Year        | Milestone                                         | Contributor(s)                   | Original Work Reference                                       | Key Contributions                                                              | Additional Information                                                             |\n",
    "|-------------|---------------------------------------------------|-----------------------------------|----------------------------------------------------------------|-------------------------------------------------------------------------------|----------------------------------------------------------------------------------|\n",
    "| 1959        | Initial Conceptualization of RIASEC Model.        | John L. Holland                  | Holland, J. L. (1959). \"A theory of vocational choice\". Journal of Counseling Psychology. | Introduced the theory of vocational personalities and work environments, forming the basis of the RIASEC model. | The model categorized individuals and work environments into six types: Realistic, Investigative, Artistic, Social, Enterprising, and Conventional (RIASEC). |\n",
    "| 1973        | Publication of \"Making Vocational Choices\".       | John L. Holland                  | Holland, J. L. (1973). \"Making Vocational Choices: A Theory of Careers\". | Further elaboration of the RIASEC model, solidifying its theoretical framework. | Provided a comprehensive guide to applying the RIASEC model in career counseling and education. |\n",
    "| 1985 onwards | Development of the Self-Directed Search (SDS).   | John L. Holland                  | Holland, J. L. (1985). \"Self-Directed Search: A Guide to Educational and Vocational Planning\". | Introduction of a self-assessment tool designed to help individuals identify their RIASEC types. | The SDS became a widely used tool in career counseling to align individual's interests with suitable career paths. |\n",
    "| 1990s-2000s | Adaptation and Application in Various Contexts.   | Various Researchers              | Studies and publications applying the RIASEC model in different cultural and educational settings. | Validation and adaptation of the RIASEC model across diverse populations and cultures. | Highlighted the universal applicability of the model in career guidance and educational planning. |\n",
    "| 2010s-Present | Ongoing Research and Digitalization.            | Contemporary Career Development Experts | Recent studies and the development of digital platforms for RIASEC assessments. | Further exploration of the model's applications and integration with online career assessment tools. | Reflects the continuing evolution of career development practices and the enduring relevance of Holland's theory. |\n",
    "\n",
    "\n",
    "This table provides an overview of the major developments in the RIASEC model, highlighting key contributions and milestones. Each row represents a significant event in the history of the RIASEC model, detailing the year, milestone, contributors, original work references, key contributions, and additional information.\n",
    "\n",
    "John L. Holland's RIASEC model has been a foundational framework in vocational psychology and career counseling. Its focus on aligning personality types with compatible career environments has made it a critical tool for career guidance and educational planning. The ongoing research and adaptations of the model, including its transition to digital platforms, demonstrate its adaptability and continuing relevance in the field of career development.\n",
    "\n",
    "## RIASEC Reference Table\n",
    "\n",
    "| **#** | **Author(s)**                                | **Year** | **Title**                                                           | **Journal/Source**                    | **Volume** | **Pages**    | **DOI/URL**                                       |\n",
    "|-------|---------------------------------------------|----------|--------------------------------------------------------------------|----------------------------------------|------------|--------------|--------------------------------------------------|\n",
    "| 1     | J. Holland                                  | 1959     | A theory of vocational choice                                     | Journal of Counseling Psychology       | 6          | 35-47       | [DOI](https://doi.org/10.1037/H0040767)          |\n",
    "| 2     | V. H. Hewer                                 | 1963     | What do theories of vocational choice mean to a counselor         | Journal of Counseling Psychology       | 10         | 118-125     | [DOI](https://doi.org/10.1037/H0040014)          |\n",
    "| 3     | I. Gati, E. I. Meir                         | 1982     | Congruence and Consistency Derived from the Circular and the Hierarchical Models as Predictors of Occupational Choice Satisfaction | Journal of Vocational Behavior       | 20         | 354-365     | [DOI](https://doi.org/10.1016/0001-8791(82)90022-7) |\n",
    "| 4     | G. G. Gonyea                               | 1961     | Dimensions of job perceptions                                    | Journal of Counseling Psychology       | 8          | 305-313     | [DOI](https://doi.org/10.1037/H0049163)          |\n",
    "| 5     | S. Osipow, J. Ashby, H. Wall                | 1966     | Personality Types and Vocational Choice: A Test of Holland's Theory | The Personnel and Guidance Journal    | 45         | 37-42       | [DOI](https://doi.org/10.1002/J.2164-4918.1966.TB03063.X) |\n",
    "| 6     | I. Gati                                    | 1991     | The Structure of Vocational Interests                            | Psychological Bulletin                 | 109        | 309-324     | [DOI](https://doi.org/10.1037/0033-2909.109.2.309) |\n",
    "| 7     | J. Holland                                 | 1968     | 3 - A Theory of Vocational Choice                                | -                                      | -          | -           | [DOI](https://doi.org/10.1016/B978-0-08-013391-1.50011-0) |\n",
    "| 8     | A. Roe                                     | 1957     | The psychology of occupations                                    | American Journal of Psychology         | 70         | 663         | [DOI](https://doi.org/10.1037/13192-000)          |\n",
    "| 9     | A. Astin, J. Holland                        | 1961     | The Environmental Assessment Technique: A way to measure college environments | Journal of Educational Psychology     | 52         | 308-316     | [DOI](https://doi.org/10.1037/H0040137)          |\n",
    "| 10    | J. Holland                                 | 1968     | Explorations of a theory of vocational choice. VI. A longitudinal study using a sample of typical college students | The Journal of Applied Psychology     | 52 1      | Suppl:1-37  | [DOI](https://doi.org/10.1037/H0025350)          |\n",
    "| 11    | J. Holland                                 | 1963     | Explorations of a Theory of Vocational Choice and Achievement: II. A Four-Year Prediction Study | Psychological Reports                | 12         | 547-594     | [DOI](https://doi.org/10.2466/pr0.1963.12.2.547) |\n",
    "| 12    | L. Hubert, P. Arabie                        | 1987     | Evaluating order hypotheses within proximity matrices            | Psychological Bulletin                 | 102        | 172-178     | [DOI](https://doi.org/10.1037/0033-2909.102.1.172) |\n",
    "| 13    | D. W. Lacey                                | 1971     | Holland's vocational models: A study of work groups and need satisfaction | Journal of Vocational Behavior       | 1          | 105-122     | [DOI](https://doi.org/10.1016/0001-8791(71)90012-1) |\n",
    "| 14    | T. Tracey                                  | 1997     | RANDALL: A Microsoft FORTRAN Program for a Randomization Test of Hypothesized Order Relations | Educational and Psychological Measurement | 57    | 164-168     | [DOI](https://doi.org/10.1177/0013164497057001012) |\n",
    "| 15    | D. Super                                   | 1953     | A theory of vocational development                               | American Psychologist                  | 8          | 185-190     | [DOI](https://doi.org/10.1037/H0056046)          |\n",
    "| 16    | I. Gati                                    | 1979     | A hierarchical model for the structure of vocational interests  | Journal of Vocational Behavior         | 15         | 90-106     | [DOI](https://doi.org/10.1016/0001-8791(79)90021-6) |\n",
    "| 17    | J. Rounds, T. Tracey                       | 1993     | Prediger's dimensional representation of Holland's RIASEC circumplex | Journal of Applied Psychology       | 78         | 875-890     | [DOI](https://doi.org/10.1037/0021-9010.78.6.875) |\n",
    "| 18    | J. Holland                                 | 1962     | Some explorations of a theory of vocational choice: I. One- and two-year longitudinal studies | -                                      | -          | -           | [DOI](https://doi.org/10.1037/H0093823)          |\n",
    "| 19    | D. Super                                   | 1980     | A life-span, life-space approach to career development          | Journal of Vocational Behavior         | 16         | 282-298     | [DOI](https://doi.org/10.1016/0001-8791(80)90056-1) |\n",
    "| 20    | J. Holland                                 | 1984     | Making vocational choices: A theory of vocational personalities and work environments | -                                      | -          | -           | -                                                |\n",
    "| 21    | T. Frantz, E. Walsh                        | 1972     | Exploration of Holland's theory of vocational choice in graduate school environments | Journal of Vocational Behavior       | 2          | 223-232     | [DOI](https://doi.org/10.1016/0001-8791(72)90027-9) |\n",
    "| 22    | I. Gati                                    | 1984     | On the perceived structure of occupations                       | Journal of Vocational Behavior         | 25         | 1-29       | [DOI](https://doi.org/10.1016/0001-8791(84)90033-2) |\n",
    "| 23    | T. Tracey, J. Rounds                       | 1993     | Evaluating Holland's and Gati's Vocational-Interest Models: A Structural Meta-Analysis | Psychological Bulletin                | 113        | 229-246     | [DOI](https://doi.org/10.1037/0033-2909.113.2.229) |\n",
    "| 24    | J. Ryan, T. Tracey, J. Rounds              | 1996     | Generalizability of Holland's Structure of Vocational Interests Across Ethnicity, Gender, and Socioeconomic Status | Journal of Counseling Psychology    | 43         | 330-337     | [DOI](https://doi.org/10.1037/0022-0167.43.3.330) |\n",
    "| 25    | M. Nauta                                  | 2010     | The development, evolution, and status of Holland's theory of vocational personalities: Reflections and future directions for counseling psychology | Journal of Counseling Psychology   | 57 1     | 11-22      | [DOI](https://doi.org/10.1037/a0018213)         |\n",
    "| 26    | J. Holland                                 | 1973     | Making Vocational Choices: A Theory of Careers                  | -                                      | -          | -           | -                                                |\n",
    "| 27    | D. Prediger, T. Vansickle                  | 1992     | Locating occupations on Holland's hexagon: Beyond RIASEC       | Journal of Vocational Behavior         | 40         | 111-128     | [DOI](https://doi.org/10.1016/0001-8791(92)90060-D) |\n",
    "| 28    | H. Astin, T. Myint                         | 1971     | Career Development of Young Women during the Post-High School Years | Journal of Counseling Psychology | 18 | 369-394     | [DOI](https://doi.org/10.1037/H0031242)          |\n",
    "| 29    | W. Walsh, D. W. Lacey                      | 1969     | Perceived change and Holland's theory                           | Journal of Counseling Psychology       | 16         | 348-352     | [DOI](https://doi.org/10.1037/H0020241)          |\n",
    "| 30    | J. Rounds, T. Tracey                       | 1996     | Cross-cultural structural equivalence of RIASEC models and measures | Journal of Counseling Psychology   | 43         | 310-329     | [DOI](https://doi.org/10.1037/0022-0167.43.3.310) |\n",
    "| 31    | J. Holland, R. Nichols                     | 1964     | Explorations of a Theory of Vocational Choice: III. A Longitudinal Study of Change in Major Field of Study | The Personnel and Guidance Journal | 43  | 235-242 | [DOI](https://doi.org/10.1002/J.2164-4918.1964.TB02667.X) |\n",
    "| 32    | D. Prediger                               | 1982     | Dimensions Underlying Holland's Hexagon: Missing Link between Interests and Occupations? | Journal of Vocational Behavior      | 21         | 259-287     | [DOI](https://doi.org/10.1016/0001-8791(82)90036-7) |\n",
    "| 33    | J. Rounds, T. Tracey, L. Hubert            | 1992     | Methods for Evaluating Vocational Interest Structural Hypotheses | Journal of Vocational Behavior       | 40         | 239-259     | [DOI](https://doi.org/10.1016/0001-8791(92)90073-9) |\n",
    "| 34    | D. Kaldor, D. G. Zytowski                  | 1969     | A Maximizing Model of Occupational Decision-Making             | The Personnel and Guidance Journal     | 47         | 781-788     | [DOI](https://doi.org/10.1002/J.2164-4918.1969.TB03006.X) |\n",
    "| 35    | A. Roe                                     | 1957     | Early determinants of vocational choice                         | Journal of Counseling Psychology       | 4          | 212-217     | [DOI](https://doi.org/10.1037/H0045950)          |\n",
    "| 36    | J. Rounds, M. Davison, R. Dawis            | 1979     | The fit between Strong-Campbell Interest Inventory General Occupational Themes and Holland's hexagonal model | Journal of Vocational Behavior  | 15    | 303-315 | [DOI](https://doi.org/10.1016/0001-8791(79)90027-7) |\n",
    "| 37    | T. Tracey, J. Rounds                       | 1995     | The arbitrary nature of Holland's RIASEC types: A concentric-circles structure | Journal of Counseling Psychology  | 42 | 431-439 | [DOI](https://doi.org/10.1037/0022-0167.42.4.431) |\n",
    "| 38    | R. Martin                                 | 1972     | Relationships Between Holland's Vocational Preference Inventory and Vocational-Technical Student Achievement | - | - | - | - |\n",
    "| 39    | E. Bordin, B. Nachmann, S. Segal           | 1963     | An articulated framework for vocational development             | Journal of Counseling Psychology       | 10         | 107-116     | [DOI](https://doi.org/10.1037/H0046072)          |\n",
    "| 40    | F. J. Reardon, J. Senier, J. Lewis         | 1972     | The Development and Evaluation of an Occupational Inventory    | Journal of Educational Measurement     | 9          | 151-153     | [DOI](https://doi.org/10.1111/J.1745-3984.1972.TB00772.X) |\n",
    "\n",
    "### Taxonomy\n",
    "```\n",
    "- Factor\n",
    "    |__ Adjective\n",
    "        |__ Synonym\n",
    "        |__ Verb\n",
    "        |__ Noun\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d931fe8d-537d-48d1-9f8a-79670ef29866",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 1: Create Dataset** <a class=\"anchor\" id=\"OCEAN_page_1\"></a>\n",
    "\n",
    "Data Preparation and Cleaning: Ensure the dataset is cleaned and preprocessed properly. Handle missing values, duplicates, and outliers.\n",
    "\n",
    "[Back to Top](#OCEAN_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a0f54b8-c3c4-4a36-be3a-24aa55a53d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Factor</th>\n",
       "      <th>Adjective</th>\n",
       "      <th>Synonym</th>\n",
       "      <th>Verb</th>\n",
       "      <th>Noun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Realistic</td>\n",
       "      <td>Practical</td>\n",
       "      <td>Useful</td>\n",
       "      <td>Use</td>\n",
       "      <td>Practicality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Realistic</td>\n",
       "      <td>Practical</td>\n",
       "      <td>Functional</td>\n",
       "      <td>Apply</td>\n",
       "      <td>Usefulness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Realistic</td>\n",
       "      <td>Practical</td>\n",
       "      <td>Sensible</td>\n",
       "      <td>Utilize</td>\n",
       "      <td>Functionality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Realistic</td>\n",
       "      <td>Practical</td>\n",
       "      <td>Workable</td>\n",
       "      <td>Implement</td>\n",
       "      <td>Sensibility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Realistic</td>\n",
       "      <td>Physical</td>\n",
       "      <td>Bodily</td>\n",
       "      <td>Touch</td>\n",
       "      <td>Physicality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Factor  Adjective     Synonym       Verb           Noun\n",
       "0  Realistic  Practical      Useful        Use   Practicality\n",
       "1  Realistic  Practical  Functional      Apply     Usefulness\n",
       "2  Realistic  Practical    Sensible    Utilize  Functionality\n",
       "3  Realistic  Practical    Workable  Implement    Sensibility\n",
       "4  Realistic   Physical      Bodily      Touch    Physicality"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# RIASEC dataset \n",
    "riasec_dataset = {\n",
    "    'Realistic': {\n",
    "        'Practical': {\n",
    "            'Synonyms': ['Useful', 'Functional', 'Sensible', 'Workable'],\n",
    "            'Verbs': ['Use', 'Apply', 'Utilize', 'Implement'],\n",
    "            'Nouns': ['Practicality', 'Usefulness', 'Functionality', 'Sensibility']\n",
    "        },\n",
    "        'Physical': {\n",
    "            'Synonyms': ['Bodily', 'Corporeal', 'Tangible', 'Material'],\n",
    "            'Verbs': ['Touch', 'Move', 'Lift', 'Manipulate'],\n",
    "            'Nouns': ['Physicality', 'Tangibility', 'Material', 'Body']\n",
    "        },\n",
    "        'Hands-on': {\n",
    "            'Synonyms': ['Practical', 'Manual', 'Tangible', 'Direct'],\n",
    "            'Verbs': ['Handle', 'Work', 'Operate', 'Manage'],\n",
    "            'Nouns': ['Manual work', 'Practicality', 'Tangible work', 'Directness']\n",
    "        },\n",
    "        'Concrete': {\n",
    "            'Synonyms': ['Tangible', 'Material', 'Real', 'Actual'],\n",
    "            'Verbs': ['Build', 'Construct', 'Create', 'Form'],\n",
    "            'Nouns': ['Reality', 'Materiality', 'Concreteness', 'Actuality']\n",
    "        },\n",
    "        'Natural': {\n",
    "            'Synonyms': ['Organic', 'Physical', 'Biological', 'Life'],\n",
    "            'Verbs': ['Grow', 'Harvest', 'Nurture', 'Cultivate'],\n",
    "            'Nouns': ['Nature', 'Biology', 'Life', 'Organic material']\n",
    "        }\n",
    "    },\n",
    "    'Investigative': {\n",
    "        'Analytical': {\n",
    "            'Synonyms': ['Logical', 'Systematic', 'Rational', 'Objective'],\n",
    "            'Verbs': ['Analyze', 'Examine', 'Investigate', 'Review'],\n",
    "            'Nouns': ['Analysis', 'Logic', 'Systematic review', 'Rationality']\n",
    "        },\n",
    "        'Intellectual': {\n",
    "            'Synonyms': ['Cerebral', 'Academic', 'Cultured', 'Educated'],\n",
    "            'Verbs': ['Study', 'Learn', 'Read', 'Research'],\n",
    "            'Nouns': ['Intellect', 'Education', 'Academic knowledge', 'Learning']\n",
    "        },\n",
    "        'Inquisitive': {\n",
    "            'Synonyms': ['Curious', 'Questioning', 'Probing', 'Inquiring'],\n",
    "            'Verbs': ['Inquire', 'Question', 'Probe', 'Explore'],\n",
    "            'Nouns': ['Curiosity', 'Inquiry', 'Exploration', 'Probing']\n",
    "        },\n",
    "        'Scientific': {\n",
    "            'Synonyms': ['Systematic', 'Precise', 'Accurate', 'Methodical'],\n",
    "            'Verbs': ['Experiment', 'Measure', 'Test', 'Calculate'],\n",
    "            'Nouns': ['Precision', 'Accuracy', 'Method', 'System']\n",
    "        },\n",
    "        'Complex': {\n",
    "            'Synonyms': ['Complicated', 'Intricate', 'Involved', 'Detailed'],\n",
    "            'Verbs': ['Complicate', 'Detail', 'Involve', 'Entangle'],\n",
    "            'Nouns': ['Complexity', 'Intricacy', 'Detail', 'Involvement']\n",
    "        }\n",
    "    },\n",
    "    'Artistic': {\n",
    "        'Creative': {\n",
    "            'Synonyms': ['Inventive', 'Innovative', 'Imaginative', 'Original'],\n",
    "            'Verbs': ['Invent', 'Innovate', 'Imagine', 'Create'],\n",
    "            'Nouns': ['Creativity', 'Innovation', 'Invention', 'Imagination']\n",
    "        },\n",
    "        'Expressive': {\n",
    "            'Synonyms': ['Emotional', 'Demonstrative', 'Animated', 'Vivid'],\n",
    "            'Verbs': ['Express', 'Demonstrate', 'Animate', 'Show'],\n",
    "            'Nouns': ['Expression', 'Demonstration', 'Animation', 'Vividity']\n",
    "        },\n",
    "        'Open-minded': {\n",
    "            'Synonyms': ['Receptive', 'Unbiased', 'Accepting', 'Tolerant'],\n",
    "            'Verbs': ['Accept', 'Tolerate', 'Consider', 'Receive'],\n",
    "            'Nouns': ['Open-mindedness', 'Receptiveness', 'Tolerance', 'Acceptance']\n",
    "        },\n",
    "        'Independent': {\n",
    "            'Synonyms': ['Autonomous', 'Self-governing', 'Free', 'Self-reliant'],\n",
    "            'Verbs': ['Lead', 'Self-govern', 'Manage', 'Direct'],\n",
    "            'Nouns': ['Autonomy', 'Self-governance', 'Independence', 'Leadership']\n",
    "        },\n",
    "        'Impulsive': {\n",
    "            'Synonyms': ['Spontaneous', 'Unpredictable', 'Capricious', 'Erratic'],\n",
    "            'Verbs': ['Act spontaneously', 'React', 'Improvise', 'Rush'],\n",
    "            'Nouns': ['Impulsiveness', 'Spontaneity', 'Unpredictability', 'Improvisation']\n",
    "        }\n",
    "    },\n",
    "    'Social': {\n",
    "        'Cooperative': {\n",
    "            'Synonyms': ['Collaborative', 'Team', 'Joint', 'United'],\n",
    "            'Verbs': ['Cooperate', 'Collaborate', 'Unite', 'Work together'],\n",
    "            'Nouns': ['Cooperation', 'Collaboration', 'Unity', 'Team']\n",
    "        },\n",
    "        'Friendly': {\n",
    "            'Synonyms': ['Amiable', 'Affable', 'Cordial', 'Kind'],\n",
    "            'Verbs': ['Greet', 'Smile', 'Welcome', 'Befriend'],\n",
    "            'Nouns': ['Friendship', 'Kindness', 'Amiability', 'Affability']\n",
    "        },\n",
    "        'Helpful': {\n",
    "            'Synonyms': ['Supportive', 'Assisting', 'Beneficial', 'Useful'],\n",
    "            'Verbs': ['Help', 'Support', 'Assist', 'Benefit'],\n",
    "            'Nouns': ['Helpfulness', 'Support', 'Assistance', 'Benefit']\n",
    "        },\n",
    "        'Empathetic': {\n",
    "            'Synonyms': ['Compassionate', 'Sympathetic', 'Understanding', 'Caring'],\n",
    "            'Verbs': ['Empathize', 'Understand', 'Care', 'Feel'],\n",
    "            'Nouns': ['Empathy', 'Compassion', 'Sympathy', 'Understanding']\n",
    "        },\n",
    "        'Patient': {\n",
    "            'Synonyms': ['Tolerant', 'Forbearing', 'Enduring', 'Long-suffering'],\n",
    "            'Verbs': ['Wait', 'Tolerate', 'Endure', 'Forbear'],\n",
    "            'Nouns': ['Patience', 'Tolerance', 'Endurance', 'Forbearance']\n",
    "        }\n",
    "    },\n",
    "    'Enterprising': {\n",
    "        'Persuasive': {\n",
    "            'Synonyms': ['Influential', 'Convincing', 'Cogent', 'Coaxing'],\n",
    "            'Verbs': ['Persuade', 'Influence', 'Convince', 'Coax'],\n",
    "            'Nouns': ['Persuasion', 'Influence', 'Conviction', 'Coaxing']\n",
    "        },\n",
    "        'Ambitious': {\n",
    "            'Synonyms': ['Driven', 'Aspiring', 'Motivated', 'Determined'],\n",
    "            'Verbs': ['Aspire', 'Achieve', 'Pursue', 'Aim'],\n",
    "            'Nouns': ['Ambition', 'Drive', 'Aspiration', 'Motivation']\n",
    "        },\n",
    "        'Extroverted': {\n",
    "            'Synonyms': ['Outgoing', 'Sociable', 'Gregarious', 'Unreserved'],\n",
    "            'Verbs': ['Socialize', 'Connect', 'Communicate', 'Engage'],\n",
    "            'Nouns': ['Extroversion', 'Sociability', 'Communication', 'Engagement']\n",
    "        },\n",
    "        'Energetic': {\n",
    "            'Synonyms': ['Vigorous', 'Active', 'Dynamic', 'Vital'],\n",
    "            'Verbs': ['Activate', 'Energize', 'Move', 'Stimulate'],\n",
    "            'Nouns': ['Energy', 'Vigor', 'Activity', 'Vitality']\n",
    "        },\n",
    "        'Risk-taking': {\n",
    "            'Synonyms': ['Adventurous', 'Daring', 'Bold', 'Courageous'],\n",
    "            'Verbs': ['Risk', 'Dare', 'Boldly act', 'Venture'],\n",
    "            'Nouns': ['Risk', 'Adventure', 'Boldness', 'Courage']\n",
    "        }\n",
    "    },\n",
    "    'Conventional': {\n",
    "        'Organized': {\n",
    "            'Synonyms': ['Systematic', 'Ordered', 'Well-ordered', 'Methodical'],\n",
    "            'Verbs': ['Organize', 'Systematize', 'Arrange', 'Order'],\n",
    "            'Nouns': ['Organization', 'System', 'Order', 'Method']\n",
    "        },\n",
    "        'Detail-oriented': {\n",
    "            'Synonyms': ['Meticulous', 'Precise', 'Thorough', 'Exact'],\n",
    "            'Verbs': ['Detail', 'Precisely manage', 'Thoroughly review', 'Examine'],\n",
    "            'Nouns': ['Detail', 'Precision', 'Thoroughness', 'Exactness']\n",
    "        },\n",
    "        'Efficient': {\n",
    "            'Synonyms': ['Effective', 'Productive', 'Competent', 'Practical'],\n",
    "            'Verbs': ['Produce', 'Optimize', 'Perform', 'Accomplish'],\n",
    "            'Nouns': ['Efficiency', 'Effectiveness', 'Productivity', 'Competence']\n",
    "        },\n",
    "        'Reliable': {\n",
    "            'Synonyms': ['Dependable', 'Trustworthy', 'Steady', 'Stable'],\n",
    "            'Verbs': ['Depend', 'Trust', 'Count on', 'Rely'],\n",
    "            'Nouns': ['Reliability', 'Trustworthiness', 'Stability', 'Dependability']\n",
    "        },\n",
    "        'Conforming': {\n",
    "            'Synonyms': ['Compliant', 'Obedient', 'Submissive', 'Accordant'],\n",
    "            'Verbs': ['Conform', 'Submit', 'Comply', 'Obey'],\n",
    "            'Nouns': ['Conformity', 'Obedience', 'Compliance', 'Submissiveness']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate over each factor\n",
    "for factor, attributes in riasec_dataset.items():\n",
    "    # Iterate over each adjective and its related lists (synonyms, verbs, nouns)\n",
    "    for adjective, details in attributes.items():\n",
    "        synonyms = details.get('Synonyms', [])\n",
    "        verbs = details.get('Verbs', [])\n",
    "        nouns = details.get('Nouns', [])\n",
    "\n",
    "        # Normalize lists to match each other in length\n",
    "        max_len = max(len(synonyms), len(verbs), len(nouns))\n",
    "        synonyms += [''] * (max_len - len(synonyms))\n",
    "        verbs += [''] * (max_len - len(verbs))\n",
    "        nouns += [''] * (max_len - len(nouns))\n",
    "        \n",
    "        # Append each combination to the data\n",
    "        for synonym, verb, noun in zip(synonyms, verbs, nouns):\n",
    "            data.append((factor, adjective, synonym, verb, noun))\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "riasec_df = pd.DataFrame(data, columns=['Factor', 'Adjective', 'Synonym', 'Verb', 'Noun'])\n",
    "\n",
    "# Save to CSV\n",
    "riasec_df.to_csv('../Datasets/riasec.csv', index=False)\n",
    "\n",
    "# Display the first few rows\n",
    "riasec_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c5b327-3d34-439f-8a75-9e9471a0e65e",
   "metadata": {},
   "source": [
    "##  Steps for RIASEC Personality Modeling Workflow \n",
    "\n",
    "1.  **Step 1: Create the Personality Dataset**\n",
    "\n",
    "    * **Purpose:** This initial step involves defining and generating the dataset that represents the (RIASEC) Personality Model .\n",
    "    * **Actions:**\n",
    "        * Define the RIASEC dataset structure (e.g., using a dictionary to represent factors, adjectives, synonyms, etc.).\n",
    "        * Generate the dataset by organizing the data into a Pandas DataFrame.\n",
    "        * Save the dataset to a CSV file.\n",
    "        * Log dataset metadata (e.g., number of rows, factors, data schema) and the dataset file itself as an artifact in MLflow.\n",
    "    * **Importance:** This step creates the raw data that will be used for embedding generation and model training.\n",
    "\n",
    "2.  **Step 2: API Key Handling and Initialization**\n",
    "\n",
    "    * **Purpose:** This criasecical step ensures that your OpenAI API key is securely loaded and the OpenAI client is initialized. This sets the foundation for using the OpenAI API in subsequent steps.\n",
    "    * **Actions:**\n",
    "        * Load the OpenAI API key from a secure location (e.g., a file in the user's home directory).\n",
    "        * Validate the API key (e.g., check for existence, emptiness, and potentially a basic API call).\n",
    "        * Initialize the OpenAI client (`client`).\n",
    "        * Log the API key handling process and its outcome in MLflow.\n",
    "    * **Importance:** This step must succeed for the rest of the workflow that utilizes the OpenAI API (like embedding generation) to function. It's essential to handle potential errors (e.g., file not found, invalid key) gracefully.\n",
    "\n",
    "3.  **Step 3: Test Embedding API**\n",
    "\n",
    "    * **Purpose:** This step verifies that the OpenAI Embedding API is accessible and functioning correctly.\n",
    "    * **Actions:**\n",
    "        * Use the initialized OpenAI client (`client`) to make a test call to the Embedding API (e.g., by embedding a sample text).\n",
    "        * Check the API response for validity.\n",
    "        * Log the API call details and the outcome (success or failure) in MLflow.\n",
    "    * **Importance:** This step ensures that you can successfully generate embeddings before proceeding to the next step.\n",
    "\n",
    "4.  **Step 4: Create Embeddings for the Dataset**\n",
    "\n",
    "    * **Purpose:** This step generates numerical represenriasecions (embeddings) for the text data in the RIASEC dataset using the OpenAI Embedding API.\n",
    "    * **Actions:**\n",
    "        * Load the RIASEC dataset (created in Step 2).\n",
    "        * Use the OpenAI client (`client`) to generate embeddings for the relevant text fields (e.g., combining factor, adjective, synonym, verb, noun).\n",
    "        * Add the generated embeddings as a new column in the Pandas DataFrame.\n",
    "        * Save the DataFrame with embeddings to a new CSV file.\n",
    "        * Log embedding generation parameters (e.g., embedding model used), sriasecistics (e.g., embedding length), and the embeddings file as an artifact in MLflow.\n",
    "    * **Importance:** This step transforms the text data into a numerical format that can be used for machine learning models.\n",
    "\n",
    "5.  **Step 5: Create and Visualize a Label Encoder**\n",
    "\n",
    "    * **Purpose:** This step prepares the categorical labels (personality factors) for model training by encoding them into numerical values and provides a visualization of this encoding.\n",
    "    * **Actions:**\n",
    "        * Load the dataset with embeddings (created in Step 4).\n",
    "        * Initialize a `LabelEncoder` from scikit-learn.\n",
    "        * Fit the `LabelEncoder` to the 'Factor' column to create the mapping between personality factors and numerical codes.\n",
    "        * Transform the 'Factor' column using the fitted `LabelEncoder` to create a new 'Factor_Encoded' column.\n",
    "        * Save the fitted `LabelEncoder` object.\n",
    "        * Generate a visualization (e.g., a bar chart) to show the mapping between original factors and encoded values.\n",
    "        * Save the visualization as an image file.\n",
    "        * Log the label encoder object and the visualization as artifacts in MLflow.\n",
    "        * Log the mapping between original factors and encoded values as a dictionary in MLflow.\n",
    "    * **Importance:** This step prepares the target variable for model training and provides a clear represenriasecion of the encoding.\n",
    "\n",
    "6.  **Step 6: Create our RIASEC Model (Model Training and Evaluation)**\n",
    "\n",
    "    * **Purpose:** This step trains a machine learning model on the generated embeddings to predict personality factors and evaluates its performance.\n",
    "    * **Actions:**\n",
    "        * Load the dataset with embeddings (created in Step 4).\n",
    "        * Load the saved `LabelEncoder` (created in Step 5).\n",
    "        * Prepare the data for model training:\n",
    "            * Extract the embeddings as features (`X`).\n",
    "            * Encode the 'Factor' column using the loaded `LabelEncoder` to get the target variable (`y`).\n",
    "            * Split the data into training and testing sets.\n",
    "        * Initialize a machine learning model (e.g., `RandomForestClassifier`).\n",
    "        * Train the model on the training data.\n",
    "        * Make predictions on the test data.\n",
    "        * Evaluate the model's performance using appropriate metrics (e.g., accuracy, classification report, confusion matrix).\n",
    "        * Generate visualizations of the evaluation results (e.g., confusion matrix plot).\n",
    "        * Save the trained model.\n",
    "        * Log model training parameters (e.g., hyperparameters), evaluation metrics, visualizations, and the trained model as artifacts in MLflow.\n",
    "    * **Importance:** This step is the core of the machine learning process, where the model learns to predict personality factors from the embeddings.\n",
    "\n",
    "7.  **Step 7: Model Testing (Inference on New Data)**\n",
    "\n",
    "    * **Purpose:** This step demonstrates how to use the trained model to predict personality factors for new, unseen text inputs.\n",
    "    * **Actions:**\n",
    "        * Load the trained model (saved in Step 6).\n",
    "        * Load the saved `LabelEncoder` (created in Step 5).\n",
    "        * Define a function that:\n",
    "            * Takes new text as input.\n",
    "            * Generates an embedding for the new text using the OpenAI API.\n",
    "            * Uses the loaded model to predict the personality factor.\n",
    "            * Uses the loaded `LabelEncoder` to decode the numerical prediction back to the original factor name.\n",
    "        * Provide example new text inputs.\n",
    "        * Use the function to predict personality factors for the example texts.\n",
    "        * Print the predictions.\n",
    "        * Log the test inputs and predictions in MLflow.\n",
    "    * **Importance:** This step demonstrates the practical application of the trained model for making predictions on new data.\n",
    "\n",
    "8.  **Step 8: Model Application, Visualization, and Analysis**\n",
    "\n",
    "    * **Purpose:** This step provides additional visualization and analysis of the data and model.\n",
    "    * **Actions:**\n",
    "        * Load the dataset with embeddings (created in Step 4).\n",
    "        * Apply PCA for dimensionality reduction and visualization of the embeddings.\n",
    "        * Generate and log PCA plots to visualize the embedding distribution.\n",
    "        * Perform K-Means clustering on the embeddings to identify potential groupings or clusters of similar personality traits.\n",
    "        * Add cluster labels to the dataset and save the clustered data.\n",
    "        * Log clustering parameters (e.g., number of clusters) and the clustered data as artifacts in MLflow.\n",
    "    * **Importance:** This step offers valuable insights into the data and model:\n",
    "        * PCA visualization helps understand the distribution of embeddings.\n",
    "        * Clustering can reveal underlying patterns in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b2a39-e66d-4a46-8f62-ad88cd36ce87",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 2: API key setup** <a class=\"anchor\" id=\"riasec_page_2\"></a>\n",
    "\n",
    "[Back to Top](#riasec_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a790191a-5760-45d1-a325-0cb2dcff5582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API key file found at: /Users/jsr/openai_api_key.txt\n",
      "üîë API key read successfully.\n",
      "ü§ñ OpenAI API client initialized.\n",
      "‚úÖ OpenAI API key verified successfully with a basic API call.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import mlflow\n",
    "\n",
    "# Start an MLFlow run for API key setup\n",
    "with mlflow.start_run(run_name=\"API Key Handling and Initialization\") as run:\n",
    "    try:\n",
    "        # Log the environment setup process\n",
    "        mlflow.log_param(\"Step\", \"API Key Handling and Initialization\")\n",
    "\n",
    "        # Define the path to your API key file\n",
    "        api_key_file_path = os.path.expanduser('~/openai_api_key.txt')\n",
    "        mlflow.log_param(\"API Key File Path\", api_key_file_path)\n",
    "\n",
    "        # Evaluation: Check if the API key file exists\n",
    "        if not os.path.exists(api_key_file_path):\n",
    "            error_message = f\"API key file not found at: {api_key_file_path}. Please ensure the file exists.\"\n",
    "            mlflow.log_param(\"API Key Sriasecus\", \"Error: File not found\")\n",
    "            mlflow.log_param(\"Error\", error_message)\n",
    "            raise FileNotFoundError(error_message)\n",
    "        else:\n",
    "            mlflow.log_param(\"API Key File Existence\", \"Confirmed\")\n",
    "            print(f\"‚úÖ API key file found at: {api_key_file_path}\")\n",
    "\n",
    "        # Read the API key from the file\n",
    "        with open(api_key_file_path, 'r') as file:\n",
    "            api_key = file.read().strip()\n",
    "\n",
    "        # Evaluation: Check if the read API key is empty\n",
    "        if not api_key:\n",
    "            error_message = f\"API key file at: {api_key_file_path} is empty. Please ensure your API key is in the file.\"\n",
    "            mlflow.log_param(\"API Key Sriasecus\", \"Error: Empty file\")\n",
    "            mlflow.log_param(\"Error\", error_message)\n",
    "            raise ValueError(error_message)\n",
    "        else:\n",
    "            mlflow.log_param(\"API Key Sriasecus\", \"Read successfully\")\n",
    "            mlflow.log_param(\"API Key Length\", len(api_key)) # Log the length as a basic sanity check\n",
    "            print(\"üîë API key read successfully.\")\n",
    "\n",
    "        # Set up your OpenAI API key\n",
    "        openai.api_key = api_key\n",
    "        client = openai.OpenAI(api_key=api_key)\n",
    "        mlflow.log_param(\"OpenAI API Client\", \"Initialized successfully\")\n",
    "        print(\"ü§ñ OpenAI API client initialized.\")\n",
    "\n",
    "        # Evaluation: Attempt a basic API call to verify the key (optional, but recommended for immediate feedback)\n",
    "        try:\n",
    "            response = client.models.list()  # Removed the 'limit' argument\n",
    "            mlflow.log_param(\"API Key Verification\", \"Successful (models list)\")\n",
    "            print(\"‚úÖ OpenAI API key verified successfully with a basic API call.\")\n",
    "        except openai.AuthenticationError as auth_error:\n",
    "            mlflow.log_param(\"API Key Verification\", \"Failed (AuthenticationError)\")\n",
    "            mlflow.log_param(\"Error\", str(auth_error))\n",
    "            raise openai.AuthenticationError(f\"OpenAI API key authentication failed: {auth_error}\")\n",
    "        except openai.OpenAIError as general_error:\n",
    "            mlflow.log_param(\"API Key Verification\", \"Failed (OpenAIError)\")\n",
    "            mlflow.log_param(\"Error\", str(general_error))\n",
    "            print(f\"‚ö†Ô∏è Warning: OpenAI API client initialized, but a test call failed with: {general_error}. Further API calls might fail.\")\n",
    "            mlflow.log_param(\"API Key Verification Warning\", str(general_error))\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"FileNotFoundError\")\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        raise\n",
    "    except ValueError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"ValueError\")\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        raise\n",
    "    except openai.AuthenticationError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"AuthenticationError\")\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        raise\n",
    "    except openai.OpenAIError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"OpenAIError\")\n",
    "        print(f\"‚ö†Ô∏è Warning during API initialization: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        # Log the error if any other unexpected issue occurs\n",
    "        mlflow.log_param(\"Error Type\", type(e).__name__)\n",
    "        mlflow.log_param(\"Error\", str(e))\n",
    "        print(f\"‚ùå An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        # End the MLFlow run\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d949ba3-7cf4-4bda-9e56-6a4f43cb8882",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 3: Test Embedding** <a class=\"anchor\" id=\"riasec_page_2\"></a>\n",
    "\n",
    "[Back to Top](#riasec_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8da8f526-a61f-4805-9d71-2a20383e45f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI client found and ready.\n",
      "üìù Testing embedding for text: 'The quick brown fox jumps over the lazy dog.'\n",
      "‚úÖ Embedding model 'text-embedding-3-small' is available.\n",
      "Embedding length: 1536\n",
      "Embedding snippet: [-0.01842353865504265, -0.00725775770843029, 0.0036669441033154726, -0.0542047917842865, -0.022724902257323265, 0.03694858402013779, 0.02903103083372116, 0.023866858333349228, 0.011229223571717739, -0.020618630573153496]\n",
      "‚úÖ Embedding API test successful.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import mlflow\n",
    "\n",
    "# Function to test the OpenAI Embedding API\n",
    "def test_openai_embedding_api():\n",
    "    with mlflow.start_run(run_name=\"Test Embedding API\") as run:\n",
    "        try:\n",
    "            # Log the step name\n",
    "            mlflow.log_param(\"Step\", \"Test Embedding API\")\n",
    "\n",
    "            # Evaluation: Check if the OpenAI client is initialized\n",
    "            if 'client' not in globals() or not isinstance(client, openai.OpenAI):\n",
    "                error_message = \"OpenAI client is not initialized. Ensure the API key setup step was executed successfully.\"\n",
    "                mlflow.log_param(\"API Client Sriasecus\", \"Not Initialized\")\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                raise RuntimeError(error_message)\n",
    "            else:\n",
    "                mlflow.log_param(\"API Client Sriasecus\", \"Initialized\")\n",
    "                print(\"‚úÖ OpenAI client found and ready.\")\n",
    "\n",
    "            # Example text to embed\n",
    "            text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "            mlflow.log_param(\"Test Text\", text)\n",
    "            print(f\"üìù Testing embedding for text: '{text}'\")\n",
    "\n",
    "            # Evaluation: Check if the specified embedding model is available (optional, but good practice)\n",
    "            embedding_model = \"text-embedding-3-small\"\n",
    "            mlflow.log_param(\"Embedding Model\", embedding_model)\n",
    "            try:\n",
    "                model_info = client.models.retrieve(embedding_model)\n",
    "                mlflow.log_param(\"Embedding Model Availability\", \"Confirmed\")\n",
    "                print(f\"‚úÖ Embedding model '{embedding_model}' is available.\")\n",
    "            except openai.NotFoundError:\n",
    "                error_message = f\"Embedding model '{embedding_model}' not found. Please check the model name.\"\n",
    "                mlflow.log_param(\"Embedding Model Availability\", \"Not Found\")\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                raise ValueError(error_message)\n",
    "            except Exception as e:\n",
    "                error_message = f\"Error checking embedding model availability: {e}\"\n",
    "                mlflow.log_param(\"Embedding Model Availability Check Error\", str(e))\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                print(f\"‚ö†Ô∏è Warning: Error checking model availability: {e}. Proceeding with embedding request.\")\n",
    "\n",
    "            # Request to generate embeddings\n",
    "            response = client.embeddings.create(\n",
    "                input=[text],  # The input should be a list of strings\n",
    "                model=embedding_model\n",
    "            )\n",
    "\n",
    "            # Evaluation: Check if the embedding response contains data\n",
    "            if not response.data:\n",
    "                error_message = \"Embedding API response does not contain any data.\"\n",
    "                mlflow.log_param(\"Embedding API Response Sriasecus\", \"No Data\")\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                raise ValueError(error_message)\n",
    "            else:\n",
    "                mlflow.log_param(\"Embedding API Response Sriasecus\", \"Data Received\")\n",
    "\n",
    "            # Extract the embedding\n",
    "            embedding = response.data[0].embedding\n",
    "\n",
    "            # Evaluation: Check if the extracted embedding is not empty\n",
    "            if not embedding:\n",
    "                error_message = \"Extracted embedding is empty.\"\n",
    "                mlflow.log_param(\"Embedding Extraction Sriasecus\", \"Empty Embedding\")\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                raise ValueError(error_message)\n",
    "            else:\n",
    "                mlflow.log_param(\"Embedding Extraction Sriasecus\", \"Success\")\n",
    "\n",
    "            # Log the embedding length and a snippet\n",
    "            embedding_length = len(embedding)\n",
    "            mlflow.log_param(\"Embedding Length\", embedding_length)\n",
    "            mlflow.log_param(\"Embedding Snippet\", embedding[:10])\n",
    "\n",
    "            # Print the embedding length and a snippet\n",
    "            print(f\"Embedding length: {embedding_length}\")\n",
    "            print(f\"Embedding snippet: {embedding[:10]}\")  # Print the first 10 elements of the embedding\n",
    "\n",
    "            print(\"‚úÖ Embedding API test successful.\")\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            mlflow.log_param(\"Error Type\", \"RuntimeError\")\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            raise\n",
    "        except ValueError as e:\n",
    "            mlflow.log_param(\"Error Type\", \"ValueError\")\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            raise\n",
    "        except openai.NotFoundError as e:\n",
    "            mlflow.log_param(\"Error Type\", \"NotFoundError\")\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            raise\n",
    "        except openai.OpenAIError as e:\n",
    "            mlflow.log_param(\"Error Type\", \"OpenAIError\")\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"‚ùå OpenAI API error: {e}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            # Log the error if any other unexpected issue occurs\n",
    "            mlflow.log_param(\"Error Type\", type(e).__name__)\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"‚ùå An unexpected error occurred: {e}\")\n",
    "            raise\n",
    "\n",
    "        finally:\n",
    "            # End the MLFlow run\n",
    "            mlflow.end_run()\n",
    "\n",
    "# Test the OpenAI Embedding API\n",
    "test_openai_embedding_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c144305-f45d-4bd8-bb64-b5873d8b1029",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 4: Create RIASEC Embeddings** <a class=\"anchor\" id=\"riasec_page_3\"></a>\n",
    "\n",
    "[Back to Top](#riasec_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fbcfbc8-c245-4b72-b1c0-37c5cc8f57ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI client initialized.\n",
      "‚úÖ Dataset loaded: ../Datasets/riasec.csv (120 rows)\n",
      "‚è≥ Started embeddings at 2025-05-25 17:07:12.228446\n",
      "‚úÖ Finished embeddings at 2025-05-25 17:08:07.998520 (took 0:00:55.770074)\n",
      "üíæ Embeddings saved to ../Embeddings/riasec_embeddings.csv\n",
      "\n",
      "Sample rows:\n",
      "      Factor  Adjective     Synonym       Verb           Noun  \\\n",
      "0  Realistic  Practical      Useful        Use   Practicality   \n",
      "1  Realistic  Practical  Functional      Apply     Usefulness   \n",
      "2  Realistic  Practical    Sensible    Utilize  Functionality   \n",
      "3  Realistic  Practical    Workable  Implement    Sensibility   \n",
      "4  Realistic   Physical      Bodily      Touch    Physicality   \n",
      "\n",
      "                                           Embedding  \n",
      "0  [-0.0020023477263748646, 0.02196861431002617, ...  \n",
      "1  [-0.025902386754751205, 0.03974475711584091, -...  \n",
      "2  [0.012764849700033665, 0.04409533366560936, -0...  \n",
      "3  [0.030506348237395287, 0.04848475754261017, -0...  \n",
      "4  [0.013816334307193756, 0.06057988479733467, -0...  \n",
      "üèÉ View run Generate RIASEC Embeddings at: http://127.0.0.1:5000/#/experiments/0/runs/1a856d29b4c54125906f662063d23ba9\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Helper to read API key\n",
    "def get_openai_api_key_from_file(filepath='~/openai_api_key.txt'):\n",
    "    filepath = os.path.expanduser(filepath)\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            api_key = f.read().strip()\n",
    "        if not api_key:\n",
    "            raise ValueError(f\"API key file at '{filepath}' is empty.\")\n",
    "        return api_key\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"API key file not found at '{filepath}'.\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error reading API key from file '{filepath}': {e}\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "try:\n",
    "    openai_api_key = get_openai_api_key_from_file()\n",
    "    client = OpenAI(api_key=openai_api_key)\n",
    "    print(\"‚úÖ OpenAI client initialized.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing OpenAI client: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Load RIASEC dataset ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "dataset_path = '../Datasets/riasec.csv'\n",
    "try:\n",
    "    riasec_df = pd.read_csv(dataset_path)\n",
    "    print(f\"‚úÖ Dataset loaded: {dataset_path} ({riasec_df.shape[0]} rows)\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"Dataset not found at {dataset_path}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Embedding helper ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    try:\n",
    "        resp = client.embeddings.create(input=[text], model=model)\n",
    "        return resp.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating embedding for '{text}': {e}\")\n",
    "        raise\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Generate & log embeddings ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"Generate RIASEC Embeddings\") as run:\n",
    "    mlflow.log_param(\"model\", \"text-embedding-3-small\")\n",
    "    mlflow.log_param(\"dataset\", dataset_path)\n",
    "    start = datetime.now()\n",
    "    mlflow.log_param(\"start_time\", str(start))\n",
    "    print(f\"‚è≥ Started embeddings at {start}\")\n",
    "\n",
    "    if riasec_df.empty:\n",
    "        raise ValueError(\"Loaded dataset is empty.\")\n",
    "\n",
    "    # Build prompt string from each row‚Äôs columns\n",
    "    riasec_df['Embedding'] = riasec_df.apply(\n",
    "        lambda r: get_embedding(\n",
    "            f\"{r['Factor']} {r['Adjective']} {r['Synonym']} {r['Verb']} {r['Noun']}\"\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    end = datetime.now()\n",
    "    mlflow.log_param(\"end_time\", str(end))\n",
    "    print(f\"‚úÖ Finished embeddings at {end} (took {end - start})\")\n",
    "\n",
    "    # Save and log embeddings CSV\n",
    "    out_path = '../Embeddings/riasec_embeddings.csv'\n",
    "    riasec_df[['Factor','Adjective','Synonym','Verb','Noun','Embedding']].to_csv(out_path, index=False)\n",
    "    mlflow.log_artifact(out_path, artifact_path=\"embeddings\")\n",
    "    print(f\"üíæ Embeddings saved to {out_path}\")\n",
    "\n",
    "    # Log run statistics\n",
    "    mlflow.log_param(\"num_rows\", riasec_df.shape[0])\n",
    "    mlflow.log_param(\"num_columns\", riasec_df.shape[1])\n",
    "    mlflow.log_param(\"embedding_length\", len(riasec_df['Embedding'].iloc[0]))\n",
    "\n",
    "    print(\"\\nSample rows:\")\n",
    "    print(riasec_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34b9502-e9f9-4b20-bbb4-813e3e5dd54a",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 5: Create Label Embeddings** <a class=\"anchor\" id=\"riasec_page_3\"></a>\n",
    "\n",
    "[Back to Top](#riasec_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddfe5c0b-fda2-439c-9348-ac797b5eb29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/25 17:08:17 INFO mlflow.tracking.fluent: Experiment with name 'RIASEC' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings dataset loaded: ../Embeddings/riasec_embeddings.csv (120 rows)\n",
      "‚úÖ Encoded 6 unique RIASEC factors\n",
      "üíæ Label encoder saved to: ../Models/riasec_label_encoder.pkl\n",
      "\n",
      "Factor ‚Üí Encoded preview:\n",
      "           Factor  Factor_Encoded\n",
      "0       Artistic               0\n",
      "1   Conventional               1\n",
      "2   Enterprising               2\n",
      "3  Investigative               3\n",
      "4      Realistic               4\n",
      "5         Social               5\n",
      "\n",
      "Full mapping:\n",
      "  Artistic ‚Üí 0\n",
      "  Conventional ‚Üí 1\n",
      "  Enterprising ‚Üí 2\n",
      "  Investigative ‚Üí 3\n",
      "  Realistic ‚Üí 4\n",
      "  Social ‚Üí 5\n",
      "‚úÖ Plot saved to /Users/jsr/Downloads/GitHub/Personality-Trait-Models/Notebooks/riasec_label_encoder_mapping.png\n",
      "üèÉ View run RIASEC: Label Encoding & Visualization at: http://127.0.0.1:5000/#/experiments/779342951677359838/runs/a64bb694f13c452daaa3a8f76addb2de\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/779342951677359838\n",
      "‚úÖ RIASEC label encoding & visualization complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"RIASEC\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Load embeddings dataset ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "embeddings_csv_path = '../Embeddings/riasec_embeddings.csv'\n",
    "try:\n",
    "    df = pd.read_csv(embeddings_csv_path)\n",
    "    print(f\"‚úÖ Embeddings dataset loaded: {embeddings_csv_path} ({len(df)} rows)\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: Embeddings dataset not found at: {embeddings_csv_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Fit LabelEncoder on the RIASEC Factor column ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "label_encoder = LabelEncoder()\n",
    "df['Factor_Encoded'] = label_encoder.fit_transform(df['Factor'])\n",
    "print(f\"‚úÖ Encoded {len(label_encoder.classes_)} unique RIASEC factors\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Save the encoder to disk ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "os.makedirs(\"../Models\", exist_ok=True)\n",
    "label_encoder_path = \"../Models/riasec_label_encoder.pkl\"\n",
    "joblib.dump(label_encoder, label_encoder_path)\n",
    "print(f\"üíæ Label encoder saved to: {label_encoder_path}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Visualization helper ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def visualize_label_encoder(le, artifact_path=\"visualization\"):\n",
    "    classes = le.classes_\n",
    "    codes   = le.transform(classes)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.barplot(x=classes, y=codes)\n",
    "    plt.xlabel(\"RIASEC Factor\")\n",
    "    plt.ylabel(\"Encoded Value\")\n",
    "    plt.title(\"RIASEC Factors ‚Üí Encoded Mapping\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    out_file = \"riasec_label_encoder_mapping.png\"\n",
    "    plt.savefig(out_file)\n",
    "    plt.close()\n",
    "    print(f\"‚úÖ Plot saved to {os.path.abspath(out_file)}\")\n",
    "    mlflow.log_artifact(out_file, artifact_path=artifact_path)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 5) Log in MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"RIASEC: Label Encoding & Visualization\"):\n",
    "    # parameters\n",
    "    mlflow.log_param(\"step\", \"label_encoding\")\n",
    "    mlflow.log_param(\"embeddings_csv\", embeddings_csv_path)\n",
    "    mlflow.log_param(\"num_rows\", df.shape[0])\n",
    "    mlflow.log_param(\"num_unique_factors\", len(label_encoder.classes_))\n",
    "    mlflow.log_artifact(label_encoder_path, artifact_path=\"label_encoder\")\n",
    "\n",
    "    # preview mapping\n",
    "    preview = (\n",
    "        df[['Factor', 'Factor_Encoded']]\n",
    "        .drop_duplicates()\n",
    "        .sort_values('Factor_Encoded')\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    print(\"\\nFactor ‚Üí Encoded preview:\\n\", preview)\n",
    "\n",
    "    # full mapping dict\n",
    "    mapping = {f: c for f, c in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))}\n",
    "    print(\"\\nFull mapping:\")\n",
    "    for f, c in mapping.items():\n",
    "        print(f\"  {f} ‚Üí {c}\")\n",
    "    mlflow.log_dict(mapping, \"label_encoder/mapping.json\")\n",
    "\n",
    "    # generate & log chart\n",
    "    visualize_label_encoder(label_encoder)\n",
    "\n",
    "print(\"‚úÖ RIASEC label encoding & visualization complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a5fde5-2c9a-46dc-998a-ca01c356e80e",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 6: Create Model** <a class=\"anchor\" id=\"riasec_page_3\"></a>\n",
    "\n",
    "[Back to Top](#riasec_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc4b4c49-a90c-4b4e-9235-6a2036f6cb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings dataset loaded from: ../Embeddings/riasec_embeddings.csv\n",
      "‚úÖ Label encoder loaded from: ../Models/riasec_label_encoder.pkl\n",
      "Train samples: 72, Test samples: 48\n",
      "‚è≥ Training started at 2025-05-25 17:09:20.352534\n",
      "‚úÖ Training finished at 2025-05-25 17:09:20.440656 (Duration: 0:00:00.088122)\n",
      "üîç Test accuracy: 1.0000\n",
      "üìä Classification report saved to riasec_classification_report.csv\n",
      "üìä Confusion matrix saved to riasec_confusion_matrix.csv\n",
      "üñºÔ∏è Saved confusion matrix plot to riasec_confusion_matrix.png\n",
      "üíæ Trained model saved to ../Models/riasec_rf_model.pkl\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     Artistic       1.00      1.00      1.00         8\n",
      " Conventional       1.00      1.00      1.00         8\n",
      " Enterprising       1.00      1.00      1.00         8\n",
      "Investigative       1.00      1.00      1.00         8\n",
      "    Realistic       1.00      1.00      1.00         8\n",
      "       Social       1.00      1.00      1.00         8\n",
      "\n",
      "     accuracy                           1.00        48\n",
      "    macro avg       1.00      1.00      1.00        48\n",
      " weighted avg       1.00      1.00      1.00        48\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "                Artistic  Conventional  Enterprising  Investigative  Realistic  \\\n",
      "Artistic              8             0             0              0          0   \n",
      "Conventional          0             8             0              0          0   \n",
      "Enterprising          0             0             8              0          0   \n",
      "Investigative         0             0             0              8          0   \n",
      "Realistic             0             0             0              0          8   \n",
      "Social                0             0             0              0          0   \n",
      "\n",
      "               Social  \n",
      "Artistic            0  \n",
      "Conventional        0  \n",
      "Enterprising        0  \n",
      "Investigative       0  \n",
      "Realistic           0  \n",
      "Social              8  \n",
      "üèÉ View run RIASEC_RF_Training at: http://127.0.0.1:5000/#/experiments/779342951677359838/runs/44d6d782de93448dbdce27d5ac3b1f5a\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/779342951677359838\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"RIASEC\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Load embeddings dataset ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "embeddings_csv_path = '../Embeddings/riasec_embeddings.csv'\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        embeddings_csv_path,\n",
    "        converters={'Embedding': lambda s: np.array(eval(s)) if isinstance(s, str) else np.array(s)}\n",
    "    )\n",
    "    print(f\"‚úÖ Embeddings dataset loaded from: {embeddings_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: Embeddings dataset not found at: {embeddings_csv_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Load the pre-fitted label encoder ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "label_encoder_path = \"../Models/riasec_label_encoder.pkl\"\n",
    "try:\n",
    "    label_encoder = joblib.load(label_encoder_path)\n",
    "    print(f\"‚úÖ Label encoder loaded from: {label_encoder_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: Label encoder not found at: {label_encoder_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Prepare features and labels ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df['Embedding'].values)      # (n_samples, embedding_dim)\n",
    "y = df['Factor'].values                   # RIASEC factor labels\n",
    "y_encoded = label_encoder.transform(y)    # numeric labels\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Split into train/test ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "counts = pd.Series(y_encoded).value_counts()\n",
    "stratify_param = y_encoded if counts.min() >= 2 else None\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded,\n",
    "    test_size=0.4,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=stratify_param\n",
    ")\n",
    "print(f\"Train samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
    "if stratify_param is None:\n",
    "    print(\"‚ö†Ô∏è  Skipped stratification because at least one class has only 1 sample.\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 5) Start MLflow run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"RIASEC_RF_Training\") as run:\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_param(\"model_type\", \"RandomForestClassifier\")\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"test_size\", 0.4)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_artifact(label_encoder_path, artifact_path=\"label_encoder\")\n",
    "\n",
    "    start_ts = datetime.now()\n",
    "    mlflow.log_param(\"start_time\", str(start_ts))\n",
    "    print(f\"‚è≥ Training started at {start_ts}\")\n",
    "\n",
    "    # Train\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    end_ts = datetime.now()\n",
    "    mlflow.log_param(\"end_time\", str(end_ts))\n",
    "    print(f\"‚úÖ Training finished at {end_ts} (Duration: {end_ts - start_ts})\")\n",
    "\n",
    "    # Predict & evaluate\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    print(f\"üîç Test accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Only keep labels actually present in the test set\n",
    "    present = np.unique(np.concatenate([y_test, y_pred]))\n",
    "    names   = [label_encoder.classes_[i] for i in present]\n",
    "\n",
    "    # Classification report with zero‚Äêdivision handling\n",
    "    report = classification_report(\n",
    "        y_test, y_pred,\n",
    "        labels=present,\n",
    "        target_names=names,\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_path = \"riasec_classification_report.csv\"\n",
    "    report_df.to_csv(report_path, index=True)\n",
    "    mlflow.log_artifact(report_path, artifact_path=\"metrics\")\n",
    "    print(f\"üìä Classification report saved to {report_path}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=present)\n",
    "    cm_df = pd.DataFrame(cm, index=names, columns=names)\n",
    "    cm_csv = \"riasec_confusion_matrix.csv\"\n",
    "    cm_df.to_csv(cm_csv, index=True)\n",
    "    mlflow.log_artifact(cm_csv, artifact_path=\"metrics\")\n",
    "    print(f\"üìä Confusion matrix saved to {cm_csv}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"RIASEC RandomForest Confusion Matrix\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.tight_layout()\n",
    "    cm_img = \"riasec_confusion_matrix.png\"\n",
    "    plt.savefig(cm_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cm_img, artifact_path=\"metrics\")\n",
    "    print(f\"üñºÔ∏è Saved confusion matrix plot to {cm_img}\")\n",
    "\n",
    "    # Save trained model\n",
    "    os.makedirs(\"../Models\", exist_ok=True)\n",
    "    model_path = \"../Models/riasec_rf_model.pkl\"\n",
    "    joblib.dump(clf, model_path)\n",
    "    mlflow.log_artifact(model_path, artifact_path=\"models\")\n",
    "    print(f\"üíæ Trained model saved to {model_path}\")\n",
    "\n",
    "    # Final printout\n",
    "    print(\"\\nClassification Report:\\n\",\n",
    "          classification_report(y_test, y_pred, labels=present, target_names=names, zero_division=0))\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3656c2b1-5d3d-489d-9759-ed219e20d2b5",
   "metadata": {},
   "source": [
    "This block of code is a comprehensive step-by-step process focusing specifically on:\n",
    "1. **Data Loading and Preprocessing**: Parsing and preparing embeddings from a CSV file for machine learning.\n",
    "2. **Model Training**: Using a RandomForestClassifier to train on the embeddings.\n",
    "3. **Model Evaluation**: Calculating and logging metrics such as accuracy, alongside detailed classification reports and confusion matrices.\n",
    "4. **Visualization and Logging**: Visualizing the confusion matrix and logging both the visual represenriasecion and numerical data as artifacts in MLflow.\n",
    "5. **Model Persistence**: Saving the trained model for future use or deployment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b586cb-65eb-4f24-9726-c7b61611182c",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 7: Evaluate Model** <a class=\"anchor\" id=\"riasec_page_3\"></a>\n",
    "\n",
    "[Back to Top](#riasec_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bbc78ca-7e53-4ab5-8c7c-c2d2848d4367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded embeddings from: ../Embeddings/riasec_embeddings.csv\n",
      "‚úÖ Label encoder loaded from: ../Models/riasec_label_encoder.pkl\n",
      "‚úÖ Model loaded from: ../Models/riasec_rf_model.pkl\n",
      "Train size: 72, Test size: 48\n",
      "üîç Test accuracy: 1.0000\n",
      "üìä Saved classification report: riasec_evaluation_classification_report.csv\n",
      "üìä Saved confusion matrix CSV: riasec_evaluation_confusion_matrix.csv\n",
      "üñºÔ∏è Saved confusion matrix plot: riasec_evaluation_confusion_matrix.png\n",
      "üèÉ View run RIASEC_Model_Evaluation at: http://127.0.0.1:5000/#/experiments/779342951677359838/runs/fa6691e7be1a4c82af30e8efc9159b85\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/779342951677359838\n",
      "‚úÖ RIASEC model evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import mlflow\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"RIASEC\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Paths ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "EMBEDDINGS_CSV     = '../Embeddings/riasec_embeddings.csv'\n",
    "LABEL_ENCODER_PKL  = '../Models/riasec_label_encoder.pkl'\n",
    "MODEL_PKL          = '../Models/riasec_rf_model.pkl'\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Load embeddings with safe parsing ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        EMBEDDINGS_CSV,\n",
    "        converters={'Embedding': lambda s: np.array(ast.literal_eval(s)) if isinstance(s, str) else np.array(s)}\n",
    "    )\n",
    "    print(f\"‚úÖ Loaded embeddings from: {EMBEDDINGS_CSV}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Error loading embeddings: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Load artifacts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    label_encoder = joblib.load(LABEL_ENCODER_PKL)\n",
    "    print(f\"‚úÖ Label encoder loaded from: {LABEL_ENCODER_PKL}\")\n",
    "    clf = joblib.load(MODEL_PKL)\n",
    "    print(f\"‚úÖ Model loaded from: {MODEL_PKL}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Artifact missing: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Prepare features & labels ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df['Embedding'].values)\n",
    "y = df['Factor'].values\n",
    "y_encoded = label_encoder.transform(y)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Train/test split (optional stratify) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "counts = pd.Series(y_encoded).value_counts()\n",
    "stratify_param = y_encoded if counts.min() >= 2 else None\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded,\n",
    "    test_size=0.4,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=stratify_param\n",
    ")\n",
    "print(f\"Train size: {len(y_train)}, Test size: {len(y_test)}\")\n",
    "if stratify_param is None:\n",
    "    print(\"‚ö†Ô∏è  Skipped stratification‚Äîsome class has only one sample\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 5) Evaluate under MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"RIASEC_Model_Evaluation\"):\n",
    "    mlflow.log_param(\"step\", \"evaluate_model\")\n",
    "    mlflow.log_param(\"test_samples\", len(y_test))\n",
    "    mlflow.log_artifact(LABEL_ENCODER_PKL, artifact_path=\"label_encoder\")\n",
    "    mlflow.log_artifact(MODEL_PKL, artifact_path=\"model\")\n",
    "    mlflow.log_param(\"start_time\", str(datetime.now()))\n",
    "\n",
    "    # Predict\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Accuracy\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    print(f\"üîç Test accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Only keep labels actually seen\n",
    "    present = np.unique(np.concatenate([y_test, y_pred]))\n",
    "    names   = [label_encoder.classes_[i] for i in present]\n",
    "\n",
    "    # Classification report\n",
    "    report_dict = classification_report(\n",
    "        y_test, y_pred,\n",
    "        labels=present,\n",
    "        target_names=names,\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "    report_df = pd.DataFrame(report_dict).transpose()\n",
    "    report_csv = \"riasec_evaluation_classification_report.csv\"\n",
    "    report_df.to_csv(report_csv, index=True)\n",
    "    mlflow.log_artifact(report_csv, artifact_path=\"evaluation\")\n",
    "    print(f\"üìä Saved classification report: {report_csv}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=present)\n",
    "    cm_df = pd.DataFrame(cm, index=names, columns=names)\n",
    "    cm_csv = \"riasec_evaluation_confusion_matrix.csv\"\n",
    "    cm_df.to_csv(cm_csv, index=True)\n",
    "    mlflow.log_artifact(cm_csv, artifact_path=\"evaluation\")\n",
    "    print(f\"üìä Saved confusion matrix CSV: {cm_csv}\")\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"RIASEC Confusion Matrix (Test Set)\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.tight_layout()\n",
    "    cm_img = \"riasec_evaluation_confusion_matrix.png\"\n",
    "    plt.savefig(cm_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cm_img, artifact_path=\"evaluation\")\n",
    "    print(f\"üñºÔ∏è Saved confusion matrix plot: {cm_img}\")\n",
    "\n",
    "    mlflow.log_param(\"end_time\", str(datetime.now()))\n",
    "\n",
    "print(\"‚úÖ RIASEC model evaluation complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af80057-6c04-4228-ae9b-ed84b87fa9a6",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 8: Test and Evaluate Model** <a class=\"anchor\" id=\"riasec_page_3\"></a>\n",
    "\n",
    "[Back to Top](#riasec_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe70d8f9-a9eb-4908-bbf9-db62ee23023b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inference on New Data ---\n",
      "1. ‚ÄúI love going to parties and meeting new people.‚Ä¶‚Äù ‚Üí Predicted Factor: Enterprising\n",
      "2. ‚ÄúI prefer staying home with a good book.‚Ä¶‚Äù ‚Üí Predicted Factor: Conventional\n",
      "3. ‚ÄúI often feel anxious and worried.‚Ä¶‚Äù ‚Üí Predicted Factor: Social\n",
      "4. ‚ÄúI am generally calm and relaxed.‚Ä¶‚Äù ‚Üí Predicted Factor: Social\n",
      "5. ‚ÄúI enjoy taking risks and trying new things.‚Ä¶‚Äù ‚Üí Predicted Factor: Artistic\n",
      "üèÉ View run RIASEC_Inference_New_Data at: http://127.0.0.1:5000/#/experiments/779342951677359838/runs/d209740336084278967fc2b72c28a68e\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/779342951677359838\n",
      "‚úÖ Inference run complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import numpy as np\n",
    "import joblib\n",
    "import mlflow\n",
    "from openai import OpenAI, OpenAIError\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"RIASEC\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Initialize OpenAI client ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def _get_api_key_from_file(path=\"~/openai_api_key.txt\"):\n",
    "    p = os.path.expanduser(path)\n",
    "    with open(p, \"r\") as f:\n",
    "        key = f.read().strip()\n",
    "    if not key:\n",
    "        raise ValueError(f\"No API key found in {p}\")\n",
    "    return key\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\") or _get_api_key_from_file()\n",
    "client  = OpenAI(api_key=api_key)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Paths ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "ENCODER_PKL = \"../Models/riasec_label_encoder.pkl\"\n",
    "MODEL_PKL   = \"../Models/riasec_rf_model.pkl\"\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Embedding helper ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def get_embedding(text: str, model: str = \"text-embedding-3-small\") -> list:\n",
    "    try:\n",
    "        resp = client.embeddings.create(input=[text], model=model)\n",
    "        return resp.data[0].embedding\n",
    "    except OpenAIError as e:\n",
    "        mlflow.log_param(\"openai_error\", str(e))\n",
    "        raise\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Inference run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"RIASEC_Inference_New_Data\"):\n",
    "    # log start\n",
    "    mlflow.log_param(\"step\", \"inference\")\n",
    "    mlflow.log_param(\"start_time\", str(datetime.now(timezone.utc)))\n",
    "\n",
    "    # record artifacts\n",
    "    mlflow.log_artifact(ENCODER_PKL, artifact_path=\"artifacts\")\n",
    "    mlflow.log_artifact(MODEL_PKL,   artifact_path=\"artifacts\")\n",
    "\n",
    "    # load\n",
    "    label_encoder = joblib.load(ENCODER_PKL)\n",
    "    mlflow.log_param(\"label_encoder_loaded\", True)\n",
    "    clf = joblib.load(MODEL_PKL)\n",
    "    mlflow.log_param(\"model_loaded\", True)\n",
    "\n",
    "    # prediction helper\n",
    "    def predict_factor(text: str) -> str:\n",
    "        emb = get_embedding(text)\n",
    "        code = clf.predict([emb])[0]\n",
    "        return label_encoder.inverse_transform([code])[0]\n",
    "\n",
    "    # test examples\n",
    "    test_texts = [\n",
    "        \"I love going to parties and meeting new people.\",\n",
    "        \"I prefer staying home with a good book.\",\n",
    "        \"I often feel anxious and worried.\",\n",
    "        \"I am generally calm and relaxed.\",\n",
    "        \"I enjoy taking risks and trying new things.\"\n",
    "    ]\n",
    "    mlflow.log_param(\"n_test_texts\", len(test_texts))\n",
    "\n",
    "    print(\"\\n--- Inference on New Data ---\")\n",
    "    for i, txt in enumerate(test_texts, 1):\n",
    "        try:\n",
    "            pred = predict_factor(txt)\n",
    "            print(f\"{i}. ‚Äú{txt[:50]}‚Ä¶‚Äù ‚Üí Predicted Factor: {pred}\")\n",
    "            mlflow.log_param(f\"text_{i}\", txt)\n",
    "            mlflow.log_param(f\"prediction_{i}\", pred)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error on text {i}: {e}\")\n",
    "            mlflow.log_param(f\"error_{i}\", str(e))\n",
    "\n",
    "    # log end\n",
    "    mlflow.log_param(\"end_time\", str(datetime.now(timezone.utc)))\n",
    "\n",
    "print(\"‚úÖ Inference run complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dc0d50-5e9f-4b73-bb5f-f8e64b2c1f62",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 9: Visualize and Evaluate Model** <a class=\"anchor\" id=\"riasec_page_3\"></a>\n",
    "\n",
    "[Back to Top](#riasec_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02e69b18-6364-4067-98b8-4c144511dee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded embeddings from: ../Embeddings/riasec_embeddings.csv\n",
      "‚è≥ Run started at 2025-05-25 17:16:49.950463\n",
      "üîç In-sample accuracy: 1.0000\n",
      "‚úÖ Run finished at 2025-05-25 17:16:52.850563 (Duration: 0:00:02.900100)\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     Artistic       1.00      1.00      1.00        20\n",
      " Conventional       1.00      1.00      1.00        20\n",
      " Enterprising       1.00      1.00      1.00        20\n",
      "Investigative       1.00      1.00      1.00        20\n",
      "    Realistic       1.00      1.00      1.00        20\n",
      "       Social       1.00      1.00      1.00        20\n",
      "\n",
      "     accuracy                           1.00       120\n",
      "    macro avg       1.00      1.00      1.00       120\n",
      " weighted avg       1.00      1.00      1.00       120\n",
      "\n",
      "üèÉ View run RIASEC_Visualization_and_Eval at: http://127.0.0.1:5000/#/experiments/779342951677359838/runs/b5df9ee1cbbc46eb8d859db2f0de26e9\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/779342951677359838\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup MLflow & Environment ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"RIASEC\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Load embeddings with safe parsing ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "embeddings_csv_path = '../Embeddings/riasec_embeddings.csv'\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        embeddings_csv_path,\n",
    "        converters={'Embedding': lambda s: np.array(ast.literal_eval(s)) if isinstance(s, str) else np.array(s)}\n",
    "    )\n",
    "    print(f\"‚úÖ Loaded embeddings from: {embeddings_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå File not found: {embeddings_csv_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Prepare features and labels ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df['Embedding'].values)    # shape (n_samples, emb_dim)\n",
    "y = df['Factor'].values                  # RIASEC factors\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Start MLflow run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"RIASEC_Visualization_and_Eval\"):\n",
    "    mlflow.log_param(\"step\", \"visualize_and_evaluate\")\n",
    "    mlflow.log_param(\"dataset\", embeddings_csv_path)\n",
    "    start_ts = datetime.now()\n",
    "    mlflow.log_param(\"start_time\", str(start_ts))\n",
    "    print(f\"‚è≥ Run started at {start_ts}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 4) Train a RandomForest on full data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X, y_encoded)\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 4a) Infer signature & prepare input example ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    signature = infer_signature(X, clf.predict(X))\n",
    "    input_example = pd.DataFrame(\n",
    "        [X[0]],\n",
    "        columns=[f\"emb_{i}\" for i in range(X.shape[1])]\n",
    "    )\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 4b) Log model with signature and example ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    mlflow.sklearn.log_model(\n",
    "        clf,\n",
    "        artifact_path=\"riasec_rf_model\",\n",
    "        signature=signature,\n",
    "        input_example=input_example\n",
    "    )\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 5) In-sample evaluation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    y_pred = clf.predict(X)\n",
    "    acc = accuracy_score(y_encoded, y_pred)\n",
    "    mlflow.log_metric(\"in_sample_accuracy\", acc)\n",
    "    print(f\"üîç In-sample accuracy: {acc:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(y_encoded, y_pred)\n",
    "    cm_df = pd.DataFrame(cm, index=le.classes_, columns=le.classes_)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"In-Sample Confusion Matrix\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.tight_layout()\n",
    "    cm_img = \"riasec_confusion_matrix.png\"\n",
    "    plt.savefig(cm_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cm_img, artifact_path=\"evaluation\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 6) PCA visualization ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    scatter = plt.scatter(X_pca[:,0], X_pca[:,1], c=y_encoded, cmap='viridis', alpha=0.7)\n",
    "    handles, _ = scatter.legend_elements()\n",
    "    plt.legend(handles, le.classes_, title=\"Factor\")\n",
    "    plt.title(\"PCA of RIASEC Embeddings\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.tight_layout()\n",
    "    pca_img = \"riasec_pca.png\"\n",
    "    plt.savefig(pca_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(pca_img, artifact_path=\"visualization\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 7) K-Means clustering ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    n_clusters = 6\n",
    "    mlflow.log_param(\"n_clusters\", n_clusters)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X)\n",
    "    df['Cluster'] = clusters\n",
    "    clustered_csv = \"riasec_clustered_embeddings.csv\"\n",
    "    df.to_csv(clustered_csv, index=False)\n",
    "    mlflow.log_artifact(clustered_csv, artifact_path=\"clustered_data\")\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    scatter = plt.scatter(X_pca[:,0], X_pca[:,1], c=clusters, cmap='tab10', alpha=0.7)\n",
    "    plt.title(\"K-Means Clusters of RIASEC Embeddings\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.tight_layout()\n",
    "    cluster_img = \"riasec_clusters.png\"\n",
    "    plt.savefig(cluster_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cluster_img, artifact_path=\"visualization\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 8) Log end time ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    end_ts = datetime.now()\n",
    "    mlflow.log_param(\"end_time\", str(end_ts))\n",
    "    print(f\"‚úÖ Run finished at {end_ts} (Duration: {end_ts - start_ts})\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 9) Print final classification report ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    report = classification_report(y_encoded, y_pred, target_names=le.classes_, zero_division=0)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d6c46-cbed-44b1-acd1-f36a71195fca",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 10: Save Visualization and Evaluation of Model** <a class=\"anchor\" id=\"riasec_page_3\"></a>\n",
    "\n",
    "[Back to Top](#riasec_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b7e7cb8-ba04-4b99-b982-7dde60729478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded embeddings from: ../Embeddings/riasec_embeddings.csv\n",
      "‚úÖ LabelEncoder loaded from: ../Models/riasec_label_encoder.pkl\n",
      "‚úÖ RandomForest model loaded from: ../Models/riasec_rf_model.pkl\n",
      "‚è≥ Run started at 2025-05-25 17:17:55.076219\n",
      "‚úÖ PCA plot saved: riasec_pca.png\n",
      "‚úÖ Clustered data saved: ../Embeddings/riasec_clustered_embeddings.csv\n",
      "‚úÖ Cluster plot saved: riasec_clusters.png\n",
      "‚úÖ Run finished at 2025-05-25 17:17:55.229850 (Duration: 0:00:00.153631)\n",
      "üèÉ View run RIASEC_PCA_and_Clustering at: http://127.0.0.1:5000/#/experiments/779342951677359838/runs/7d56496f0441428f858dda0b1ce3953c\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/779342951677359838\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import joblib\n",
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"RIASEC\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Paths ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "EMBEDDINGS_CSV    = '../Embeddings/riasec_embeddings.csv'\n",
    "LABEL_ENCODER_PKL = '../Models/riasec_label_encoder.pkl'\n",
    "RF_MODEL_PKL      = '../Models/riasec_rf_model.pkl'\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Load embeddings with safe parsing ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        EMBEDDINGS_CSV,\n",
    "        converters={'Embedding': lambda s: np.array(ast.literal_eval(s)) if isinstance(s, str) else np.array(s)}\n",
    "    )\n",
    "    print(f\"‚úÖ Loaded embeddings from: {EMBEDDINGS_CSV}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Embeddings CSV not found: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Load artifacts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    label_encoder = joblib.load(LABEL_ENCODER_PKL)\n",
    "    print(f\"‚úÖ LabelEncoder loaded from: {LABEL_ENCODER_PKL}\")\n",
    "    rf_model       = joblib.load(RF_MODEL_PKL)\n",
    "    print(f\"‚úÖ RandomForest model loaded from: {RF_MODEL_PKL}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Artifact missing: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Prepare data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df['Embedding'].values)\n",
    "y = df['Factor'].values\n",
    "y_encoded = label_encoder.transform(y)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 5) Begin MLflow run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"RIASEC_PCA_and_Clustering\"):\n",
    "    mlflow.log_param(\"step\", \"PCA_and_KMeans\")\n",
    "    mlflow.log_param(\"embeddings_csv\", EMBEDDINGS_CSV)\n",
    "    start_ts = datetime.now()\n",
    "    mlflow.log_param(\"start_time\", str(start_ts))\n",
    "    print(f\"‚è≥ Run started at {start_ts}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 6) PCA visualization ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    scatter = plt.scatter(X_pca[:,0], X_pca[:,1], c=y_encoded, cmap='viridis', alpha=0.7)\n",
    "    handles, _ = scatter.legend_elements()\n",
    "    plt.legend(handles, label_encoder.classes_, title=\"RIASEC Factor\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.title(\"PCA of RIASEC Embeddings\")\n",
    "    plt.tight_layout()\n",
    "    pca_img = \"riasec_pca.png\"\n",
    "    plt.savefig(pca_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(pca_img, artifact_path=\"visualization\")\n",
    "    print(f\"‚úÖ PCA plot saved: {pca_img}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 7) K-Means clustering ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    n_clusters = 6\n",
    "    mlflow.log_param(\"n_clusters\", n_clusters)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X)\n",
    "    df['Cluster'] = clusters\n",
    "\n",
    "    clustered_csv = '../Embeddings/riasec_clustered_embeddings.csv'\n",
    "    os.makedirs(os.path.dirname(clustered_csv), exist_ok=True)\n",
    "    df.to_csv(clustered_csv, index=False)\n",
    "    mlflow.log_artifact(clustered_csv, artifact_path=\"clustered_data\")\n",
    "    print(f\"‚úÖ Clustered data saved: {clustered_csv}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    scatter = plt.scatter(X_pca[:,0], X_pca[:,1], c=clusters, cmap='tab10', alpha=0.7)\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.title(\"K-Means Clusters of RIASEC Embeddings\")\n",
    "    plt.tight_layout()\n",
    "    cluster_img = \"riasec_clusters.png\"\n",
    "    plt.savefig(cluster_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cluster_img, artifact_path=\"visualization\")\n",
    "    print(f\"‚úÖ Cluster plot saved: {cluster_img}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 8) End run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    end_ts = datetime.now()\n",
    "    mlflow.log_param(\"end_time\", str(end_ts))\n",
    "    print(f\"‚úÖ Run finished at {end_ts} (Duration: {end_ts - start_ts})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013ba63c-ce13-4667-a5d9-a799ab883b97",
   "metadata": {},
   "source": [
    "This block of code integrates several stages that not only include training but also applying the model to new data and exploring the data through clustering:\n",
    "1. **Data Loading and Feature Parsing**: Similar to Block 1, with an additional step of displaying the parsed data.\n",
    "2. **Model Creation and Logging**: Training a RandomForestClassifier and logging the model directly with MLflow for possibly immediate deployment.\n",
    "3. **Model Evaluation and Reporting**: Assessing model performance with metrics and detailed reports, and logging these evaluations.\n",
    "4. **Clustering Analysis**: Utilizing KMeans to perform clustering on the embeddings, which adds an exploratory data analysis component.\n",
    "5. **Model Application on New Data**: Demonstrating a practical application of the trained model to predict factors for new text inputs.\n",
    "6. **End-to-End Experiment Tracking**: From the beginning of the run to its completion, tracking all parameters, artifacts, and outcomes, emphasizing a full-cycle view of the modeling process.\n",
    "\n",
    "This provides a broader overview of how a model can be developed and applied within a workflow that includes prediction and clustering alongside the fundamental steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f3cfce-24bd-4f6c-a748-54b1fe39d107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5916893-8b0f-450f-9ce6-09015901f5eb",
   "metadata": {},
   "source": [
    "The results show that the RandomForestClassifier model trained on the dataset of embeddings has achieved an accuracy of 1.0 on the test set, which means it has correctly classified all the test samples. Here is the breakdown of the evaluation:\n",
    "\n",
    "### Accuracy:\n",
    "- **1.0**: The model has 100% accuracy, meaning it correctly classified every instance in the test set.\n",
    "\n",
    "### Classification Report:\n",
    "- **Precision, Recall, and F1-score** for each class (0 through 4) are all 1.00.\n",
    "- **Support** indicates the number of actual occurrences of each class in the test set.\n",
    "\n",
    "### Interpreriasecion:\n",
    "- **Precision**: This is the ratio of true positive predictions to the total predicted positives. A precision of 1.0 means that all instances predicted as a specific class were actually of that class.\n",
    "- **Recall**: This is the ratio of true positive predictions to the total actual positives. A recall of 1.0 means that all actual instances of a specific class were correctly predicted.\n",
    "- **F1-score**: This is the harmonic mean of precision and recall. An F1-score of 1.0 indicates perfect precision and recall.\n",
    "- **Support**: This indicates the number of true instances for each label in the test set. \n",
    "\n",
    "### Considerations:\n",
    "1. **Model Overfitting**: The perfect score could indicate overfitting, especially if the test set is small or not represenriasecive of unseen data.\n",
    "2. **Test Set Size**: The test set has only 24 samples, which is relatively small. It's important to ensure that the test set is large enough and represenriasecive to get a reliable estimate of model performance.\n",
    "3. **Data Leakage**: Double-check that there's no data leakage, meaning that no information from the test set was used during training.\n",
    "4. **Cross-Validation**: To better assess the model's performance, consider using cross-validation to ensure the model performs well across different subsets of the data.\n",
    "\n",
    "### Next Steps:\n",
    "- **Cross-validation**: Implement cross-validation to get a more robust evaluation of model performance.\n",
    "- **Larger Test Set**: If possible, increase the size of the test set to ensure the performance metrics are reliable.\n",
    "- **Feature Analysis**: Examine feature importance scores from the RandomForestClassifier to understand which parts of the embeddings contribute most to the predictions.\n",
    "\n",
    "### Updated Code for Cross-Validation:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(clf, X, y_encoded, cv=5)  # 5-fold cross-validation\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean cross-validation score: {np.mean(cv_scores)}\")\n",
    "```\n",
    "\n",
    "We added this cross-validation step will help us verify that the model generalizes well and is not just performing well on a small or potentially non-represenriasecive test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16fac8dd-46d3-4595-99f0-f15b83e244a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂ Class counts (encoded ‚Üí factor):\n",
      "  0 (Artistic): 20 samples\n",
      "  1 (Conventional): 20 samples\n",
      "  2 (Enterprising): 20 samples\n",
      "  3 (Investigative): 20 samples\n",
      "  4 (Realistic): 20 samples\n",
      "  5 (Social): 20 samples\n",
      "‚ñ∂ Using LeaveOneOut CV (120 splits)\n",
      "‚ñ∂ Leave-One-Out accuracy scores (first 10): [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]‚Ä¶\n",
      "‚ñ∂ Mean LOO accuracy: 1.0000\n",
      "‚ñ∂ Std  LOO accuracy: 0.0000\n",
      "üèÉ View run RIASEC_LOO_CV at: http://127.0.0.1:5000/#/experiments/779342951677359838/runs/e025264a218f408f992f76d072291238\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/779342951677359838\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import mlflow\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# (Assumes MLFLOW_TRACKING_URI & experiment already set elsewhere)\n",
    "mlflow.set_experiment(\"RIASEC\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Load embeddings ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "embeddings_csv = '../Embeddings/riasec_embeddings.csv'\n",
    "df = pd.read_csv(\n",
    "    embeddings_csv,\n",
    "    converters={'Embedding': lambda s: np.array(eval(s)) if isinstance(s, str) else np.array(s)}\n",
    ")\n",
    "X = np.stack(df['Embedding'].values)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Load label encoder & model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "label_encoder = joblib.load('../Models/riasec_label_encoder.pkl')\n",
    "clf           = joblib.load('../Models/riasec_rf_model.pkl')\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Prepare labels ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "y = df['Factor'].values\n",
    "y_encoded = label_encoder.transform(y)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Inspect class distribution ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "dist = pd.Series(y_encoded).value_counts().sort_index()\n",
    "print(\"‚ñ∂ Class counts (encoded ‚Üí factor):\")\n",
    "for code, cnt in dist.items():\n",
    "    print(f\"  {code} ({label_encoder.inverse_transform([code])[0]}): {cnt} samples\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 5) Leave-One-Out CV ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "loo = LeaveOneOut()\n",
    "print(f\"‚ñ∂ Using LeaveOneOut CV ({loo.get_n_splits(X)} splits)\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 6) Run CV and log in MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"RIASEC_LOO_CV\"):\n",
    "    mlflow.log_param(\"cv_method\", \"LeaveOneOut\")\n",
    "    mlflow.log_param(\"n_splits\", loo.get_n_splits(X))\n",
    "\n",
    "    cv_scores = cross_val_score(\n",
    "        clf, X, y_encoded,\n",
    "        cv=loo,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 7) Summarize & print ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    mean_acc = cv_scores.mean()\n",
    "    std_acc  = cv_scores.std()\n",
    "    print(f\"‚ñ∂ Leave-One-Out accuracy scores (first 10): {cv_scores[:10]}‚Ä¶\")\n",
    "    print(f\"‚ñ∂ Mean LOO accuracy: {mean_acc:.4f}\")\n",
    "    print(f\"‚ñ∂ Std  LOO accuracy: {std_acc:.4f}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 8) Log metrics ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    mlflow.log_metric(\"loo_mean_accuracy\", mean_acc)\n",
    "    mlflow.log_metric(\"loo_std_accuracy\", std_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adf2f5ea-3181-4f0f-8a62-c95784cac78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded embeddings.\n",
      "‚úÖ Loaded existing RandomForest model.\n",
      "Domains: ['Person', 'Type', 'Workplace Priorities']\n",
      "Train/test sizes: 18/13\n",
      "‚úÖ Trained new RandomForest on Domain target.\n",
      "Test accuracy (Domain): 0.846\n",
      "‚úÖ Confusion matrix saved to domain_cm.png\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "              Person       0.00      0.00      0.00         2\n",
      "                Type       0.78      1.00      0.88         7\n",
      "Workplace Priorities       1.00      1.00      1.00         4\n",
      "\n",
      "            accuracy                           0.85        13\n",
      "           macro avg       0.59      0.67      0.62        13\n",
      "        weighted avg       0.73      0.85      0.78        13\n",
      "\n",
      "\n",
      "5-fold CV accuracy: [1.    0.833 0.833 1.    1.   ]\n",
      "Mean CV acc: 0.933 ¬± 0.082\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Load embeddings ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "df = pd.read_csv(\n",
    "    '../Embeddings/riasec_embeddings.csv',\n",
    "    converters={'Embedding': lambda s: np.array(eval(s)) if isinstance(s, str) else np.array(s)}\n",
    ")\n",
    "print(\"‚úÖ Loaded embeddings.\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Load the original RF model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "rf = joblib.load(\"../Models/riasec_rf_model.pkl\")\n",
    "print(\"‚úÖ Loaded existing RandomForest model.\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Prepare features & Domain labels ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df['Embedding'].values)\n",
    "y_dom = df['Domain'].values\n",
    "le_dom = LabelEncoder()\n",
    "y = le_dom.fit_transform(y_dom)\n",
    "print(\"Domains:\", list(le_dom.classes_))\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Train/test split (stratified on Domain) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Train/test sizes: {X_train.shape[0]}/{X_test.shape[0]}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 5) Train a fresh RF on Domain ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"‚úÖ Trained new RandomForest on Domain target.\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 6) Evaluate on hold-out set ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test accuracy (Domain): {acc:.3f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=le_dom.classes_, columns=le_dom.classes_)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix (Domain)\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"domain_cm.png\")\n",
    "plt.close()\n",
    "print(\"‚úÖ Confusion matrix saved to domain_cm.png\")\n",
    "\n",
    "# Classification report with zero_division=0\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    target_names=le_dom.classes_,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 7) Stratified 5-fold CV on Domain ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(clf, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"\\n5-fold CV accuracy: {cv_scores.round(3)}\")\n",
    "print(f\"Mean CV acc: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d8667c-30e8-4db0-8fca-03ccb53d773e",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 11: Test Model Directly** <a class=\"anchor\" id=\"riasec_page_3\"></a>\n",
    "\n",
    "[Back to Top](#riasec_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d8b6c39-c12d-4076-95e4-692d7a89371d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 120 rows from ../Embeddings/riasec_embeddings.csv\n",
      "‚úÖ Loaded label encoder and RandomForest model.\n",
      "\n",
      "--- RIASEC Model Predictions on New Examples ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realistic (Hands-On)\n",
      "  Input: \"Build Construct Operate Handle\"\n",
      "  ‚Üí Predicted Factor: Realistic\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigative (Analytical)\n",
      "  Input: \"Analyze Investigate Research Evaluate\"\n",
      "  ‚Üí Predicted Factor: Investigative\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artistic (Creative)\n",
      "  Input: \"Invent Imagine Create Express\"\n",
      "  ‚Üí Predicted Factor: Artistic\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social (Supportive)\n",
      "  Input: \"Empathize Help Collaborate Guide\"\n",
      "  ‚Üí Predicted Factor: Social\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enterprising (Persuasion)\n",
      "  Input: \"Persuade Lead Convince Negotiate\"\n",
      "  ‚Üí Predicted Factor: Enterprising\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conventional (Organized)\n",
      "  Input: \"Organize Systematize Detail Plan\"\n",
      "  ‚Üí Predicted Factor: Conventional\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup OpenAI client ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "\n",
    "def get_openai_api_key_from_file(filepath='~/openai_api_key.txt'):\n",
    "    filepath = os.path.expanduser(filepath)\n",
    "    with open(filepath, 'r') as f:\n",
    "        key = f.read().strip()\n",
    "    if not key:\n",
    "        raise ValueError(f\"No API key found in {filepath}\")\n",
    "    return key\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\") or get_openai_api_key_from_file()\n",
    "client  = OpenAI(api_key=api_key)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Load RIASEC embeddings ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "embeddings_csv = '../Embeddings/riasec_embeddings.csv'\n",
    "df = pd.read_csv(\n",
    "    embeddings_csv,\n",
    "    converters={'Embedding': lambda s: np.array(ast.literal_eval(s)) if isinstance(s, str) else np.array(s)}\n",
    ")\n",
    "print(f\"‚úÖ Loaded {len(df)} rows from {embeddings_csv}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Prepare feature matrix ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df['Embedding'].values)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Load pretrained artifacts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "label_encoder = joblib.load('../Models/riasec_label_encoder.pkl')\n",
    "clf           = joblib.load('../Models/riasec_rf_model.pkl')\n",
    "print(\"‚úÖ Loaded label encoder and RandomForest model.\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def get_embedding(text: str, model=\"text-embedding-3-small\") -> list:\n",
    "    resp = client.embeddings.create(input=[text], model=model)\n",
    "    return resp.data[0].embedding\n",
    "\n",
    "def predict_factor(text: str) -> str:\n",
    "    emb    = get_embedding(text)\n",
    "    code   = clf.predict([emb])[0]\n",
    "    factor = label_encoder.inverse_transform([code])[0]\n",
    "    return factor\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Test on meaningful RIASEC examples ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "test_texts = {\n",
    "    \"Realistic (Hands-On)\":      \"Build Construct Operate Handle\",\n",
    "    \"Investigative (Analytical)\": \"Analyze Investigate Research Evaluate\",\n",
    "    \"Artistic (Creative)\":        \"Invent Imagine Create Express\",\n",
    "    \"Social (Supportive)\":        \"Empathize Help Collaborate Guide\",\n",
    "    \"Enterprising (Persuasion)\":  \"Persuade Lead Convince Negotiate\",\n",
    "    \"Conventional (Organized)\":   \"Organize Systematize Detail Plan\"\n",
    "}\n",
    "\n",
    "print(\"\\n--- RIASEC Model Predictions on New Examples ---\")\n",
    "for label, sample in test_texts.items():\n",
    "    try:\n",
    "        pred = predict_factor(sample)\n",
    "        print(\n",
    "            f\"{label}\\n\"\n",
    "            f\"  Input: \\\"{sample}\\\"\\n\"\n",
    "            f\"  ‚Üí Predicted Factor: {pred}\\n\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing '{label}': {e}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab54c21-ee36-4c0e-b9c4-445b11fa65ed",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 12: Test Neo4j Connection** <a class=\"anchor\" id=\"RIASEC_page_4\"></a>\n",
    "\n",
    "\n",
    "[Back to Top](#RIASEC_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce3fd307-5fcf-46d7-867d-78ecd5a83887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://localhost:7474/browser/\" target=\"_blank\">üîó Open Neo4j Bolt Connection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Define Neo4j Browser URL\n",
    "neo4j_browser_url = \"http://localhost:7474/browser/\"\n",
    "\n",
    "# Create a clickable link\n",
    "html_code = f'<a href=\"{neo4j_browser_url}\" target=\"_blank\">üîó Open Neo4j Bolt Connection</a>'\n",
    "\n",
    "# Display the clickable link in Jupyter Notebook\n",
    "display(HTML(html_code))\n",
    "\n",
    "# Open the Neo4j Browser in a new tab automatically\n",
    "webbrowser.open_new_tab(neo4j_browser_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a12796f0-11cb-40cb-8c48-e9e20760ed42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bolt port 7687 is reachable!\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "HOST = \"localhost\"\n",
    "PORT = 7687\n",
    "\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "result = sock.connect_ex((HOST, PORT))\n",
    "\n",
    "if result == 0:\n",
    "    print(f\"‚úÖ Bolt port {PORT} is reachable!\")\n",
    "else:\n",
    "    print(f\"‚ùå Bolt port {PORT} is NOT reachable!\")\n",
    "\n",
    "sock.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3abeb19a-7681-4c01-bb52-3b567513142a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Python Connection Failed: Unknown protocol 'neo4j'\n"
     ]
    }
   ],
   "source": [
    "from py2neo import Graph\n",
    "import mlflow\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ End any active MLflow run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Original URI (using neo4j://) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "raw_uri      = \"neo4j://localhost:7687\"\n",
    "NEO4J_USER   = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"mypassword\"\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Rewrite to bolt:// for py2neo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if raw_uri.startswith(\"neo4j://\"):\n",
    "    uri = \"bolt://\" + raw_uri[len(\"neo4j://\"):]\n",
    "else:\n",
    "    uri = raw_uri\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Attempt connection ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    graph = Graph(uri, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    # run a simple test query\n",
    "    message = graph.run(\"RETURN 'Connection successful!' AS message\").evaluate()\n",
    "    print(\"‚úÖ Python Connected Successfully:\", message)\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Python Connection Failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1142a99b-5cc2-4917-b423-5b8d52a45c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Connecting to Bolt URI: bolt://localhost:7687\n",
      "‚ùå Connection failed: Unknown protocol 'neo4j'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown protocol 'neo4j'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 4) Attempt connection\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[43mGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbolt_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpwd\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     greeting \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETURN \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124müéâ Bolt connection successful!\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m AS msg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ\u001b[39m\u001b[38;5;124m\"\u001b[39m, greeting)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/database.py:288\u001b[0m, in \u001b[0;36mGraph.__init__\u001b[0;34m(self, profile, name, **settings)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, profile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings):\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice \u001b[38;5;241m=\u001b[39m \u001b[43mGraphService\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m=\u001b[39m Schema(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/database.py:119\u001b[0m, in \u001b[0;36mGraphService.__init__\u001b[0;34m(self, profile, **settings)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connector_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m profile\u001b[38;5;241m.\u001b[39mrouting:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Ensures credentials are checked on construction\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     connector_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connector \u001b[38;5;241m=\u001b[39m \u001b[43mConnector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconnector_settings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graphs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/client/__init__.py:948\u001b[0m, in \u001b[0;36mConnector.__init__\u001b[0;34m(self, profile, user_agent, init_size, max_size, max_age, routing_refresh_ttl)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, profile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_agent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    946\u001b[0m              max_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_age\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, routing_refresh_ttl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile \u001b[38;5;241m=\u001b[39m ServiceProfile(profile)\n\u001b[0;32m--> 948\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_routers \u001b[38;5;241m=\u001b[39m [\u001b[43mConnectionProfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_agent \u001b[38;5;241m=\u001b[39m user_agent\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server_agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:176\u001b[0m, in \u001b[0;36mConnectionProfile.__init__\u001b[0;34m(self, profile, **settings)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__password \u001b[38;5;241m=\u001b[39m DEFAULT_PASSWORD\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__address \u001b[38;5;241m=\u001b[39m Address\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_env_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:220\u001b[0m, in \u001b[0;36mConnectionProfile._apply_env_vars\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply_env_vars\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m NEO4J_URI:\n\u001b[0;32m--> 220\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNEO4J_URI\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m NEO4J_AUTH:\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_settings(auth\u001b[38;5;241m=\u001b[39mNEO4J_AUTH)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:232\u001b[0m, in \u001b[0;36mConnectionProfile._apply_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    230\u001b[0m parsed \u001b[38;5;241m=\u001b[39m urlsplit(uri)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_scheme\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheme\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mnetloc:\n\u001b[1;32m    234\u001b[0m     settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m parsed\u001b[38;5;241m.\u001b[39mnetloc\u001b[38;5;241m.\u001b[39mpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:249\u001b[0m, in \u001b[0;36mConnectionProfile._apply_scheme\u001b[0;34m(self, scheme)\u001b[0m\n\u001b[1;32m    247\u001b[0m     protocol, _, ext \u001b[38;5;241m=\u001b[39m scheme\u001b[38;5;241m.\u001b[39mpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_settings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_settings(protocol\u001b[38;5;241m=\u001b[39mprotocol, secure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:266\u001b[0m, in \u001b[0;36mConnectionProfile._apply_settings\u001b[0;34m(self, uri, scheme, protocol, secure, verify, address, host, port, port_number, auth, user, password, **other)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_scheme(scheme)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol:\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_protocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m secure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__secure \u001b[38;5;241m=\u001b[39m secure\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:297\u001b[0m, in \u001b[0;36mConnectionProfile._apply_protocol\u001b[0;34m(self, protocol)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply_protocol\u001b[39m(\u001b[38;5;28mself\u001b[39m, protocol):\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbolt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown protocol \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m protocol)\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__protocol \u001b[38;5;241m=\u001b[39m protocol\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown protocol 'neo4j'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from py2neo import Graph\n",
    "import mlflow\n",
    "\n",
    "# 1) Tear down any active MLflow run\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "# 2) Load env\n",
    "load_dotenv(override=True)\n",
    "raw_uri = os.getenv(\"NEO4J_URI\", \"\")\n",
    "user    = os.getenv(\"NEO4J_USERNAME\")\n",
    "pwd     = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "if not raw_uri:\n",
    "    raise RuntimeError(\"‚ùå NEO4J_URI is not set in .env\")\n",
    "if not user or not pwd:\n",
    "    raise RuntimeError(\"‚ùå NEO4J_USERNAME or NEO4J_PASSWORD not set in .env\")\n",
    "\n",
    "# 3) Rewrite protocol\n",
    "if raw_uri.startswith(\"neo4j://\"):\n",
    "    bolt_uri = \"bolt://\" + raw_uri[len(\"neo4j://\"):]\n",
    "else:\n",
    "    bolt_uri = raw_uri\n",
    "\n",
    "print(f\"üîç Connecting to Bolt URI: {bolt_uri}\")\n",
    "\n",
    "# 4) Attempt connection\n",
    "try:\n",
    "    graph = Graph(bolt_uri, auth=(user, pwd))\n",
    "    greeting = graph.run(\"RETURN 'üéâ Bolt connection successful!' AS msg\").evaluate()\n",
    "    print(\"‚úÖ\", greeting)\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Connection failed:\", e)\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54f9b222-dd9d-4205-b4ab-3221085fbe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection failed: Unknown protocol 'neo4j'\n",
      "üèÉ View run Test Neo4j Connection at: http://127.0.0.1:5000/#/experiments/886681214121108750/runs/8f80dd79628a4cda85587faa4064eb8b\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/886681214121108750\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from py2neo import Graph\n",
    "import mlflow\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Load environment ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv()\n",
    "raw_uri       = os.getenv(\"NEO4J_URI\", \"\")\n",
    "NEO4J_USER    = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD= os.getenv(\"NEO4J_PASSWORD\")\n",
    "MLFLOW_URI    = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Fix URI for py2neo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if raw_uri.startswith(\"neo4j://\"):\n",
    "    bolt_uri = \"bolt://\" + raw_uri[len(\"neo4j://\"):]\n",
    "else:\n",
    "    bolt_uri = raw_uri\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Configure MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "mlflow.set_experiment(\"RIASEC\")\n",
    "\n",
    "def test_neo4j_connection(uri, user, pwd):\n",
    "    graph = Graph(uri, auth=(user, pwd))\n",
    "    return graph.run(\"RETURN 'Connection successful!' AS greeting\").evaluate()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Run the connection test under MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"Test Neo4j Connection\"):\n",
    "    mlflow.log_param(\"Test\", \"Neo4j Connection\")\n",
    "    \n",
    "    try:\n",
    "        result = test_neo4j_connection(bolt_uri, NEO4J_USER, NEO4J_PASSWORD)\n",
    "    except Exception as e:\n",
    "        result = f\"Connection failed: {e}\"\n",
    "    \n",
    "    mlflow.log_param(\"Connection Result\", result)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0ce307e-9ad1-4891-9f4f-8966af9ce07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Test & Clear Neo4j at: http://127.0.0.1:5000/#/experiments/616263351584470447/runs/dba3a670164f4a5a916cafc8a2cc1914\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/616263351584470447\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown protocol 'neo4j'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# ‚îÄ‚îÄ‚îÄ Test & Clear Neo4j inside an MLflow run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run(run_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest & Clear Neo4j\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# 1) Test connection\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtest_neo4j_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNEO4J_URI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNEO4J_USER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNEO4J_PASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection Test\u001b[39m\u001b[38;5;124m\"\u001b[39m, result)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müîó Connection test result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 26\u001b[0m, in \u001b[0;36mtest_neo4j_connection\u001b[0;34m(uri, user, password)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtest_neo4j_connection\u001b[39m(uri, user, password):\n\u001b[0;32m---> 26\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[43mGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETURN \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConnection successful!\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m AS greeting\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/database.py:288\u001b[0m, in \u001b[0;36mGraph.__init__\u001b[0;34m(self, profile, name, **settings)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, profile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings):\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice \u001b[38;5;241m=\u001b[39m \u001b[43mGraphService\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m=\u001b[39m Schema(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/database.py:119\u001b[0m, in \u001b[0;36mGraphService.__init__\u001b[0;34m(self, profile, **settings)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connector_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m profile\u001b[38;5;241m.\u001b[39mrouting:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Ensures credentials are checked on construction\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     connector_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connector \u001b[38;5;241m=\u001b[39m \u001b[43mConnector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconnector_settings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graphs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/client/__init__.py:948\u001b[0m, in \u001b[0;36mConnector.__init__\u001b[0;34m(self, profile, user_agent, init_size, max_size, max_age, routing_refresh_ttl)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, profile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_agent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    946\u001b[0m              max_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_age\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, routing_refresh_ttl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile \u001b[38;5;241m=\u001b[39m ServiceProfile(profile)\n\u001b[0;32m--> 948\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_routers \u001b[38;5;241m=\u001b[39m [\u001b[43mConnectionProfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_agent \u001b[38;5;241m=\u001b[39m user_agent\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server_agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:176\u001b[0m, in \u001b[0;36mConnectionProfile.__init__\u001b[0;34m(self, profile, **settings)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__password \u001b[38;5;241m=\u001b[39m DEFAULT_PASSWORD\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__address \u001b[38;5;241m=\u001b[39m Address\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_env_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:220\u001b[0m, in \u001b[0;36mConnectionProfile._apply_env_vars\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply_env_vars\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m NEO4J_URI:\n\u001b[0;32m--> 220\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNEO4J_URI\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m NEO4J_AUTH:\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_settings(auth\u001b[38;5;241m=\u001b[39mNEO4J_AUTH)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:232\u001b[0m, in \u001b[0;36mConnectionProfile._apply_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    230\u001b[0m parsed \u001b[38;5;241m=\u001b[39m urlsplit(uri)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_scheme\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheme\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mnetloc:\n\u001b[1;32m    234\u001b[0m     settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m parsed\u001b[38;5;241m.\u001b[39mnetloc\u001b[38;5;241m.\u001b[39mpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:249\u001b[0m, in \u001b[0;36mConnectionProfile._apply_scheme\u001b[0;34m(self, scheme)\u001b[0m\n\u001b[1;32m    247\u001b[0m     protocol, _, ext \u001b[38;5;241m=\u001b[39m scheme\u001b[38;5;241m.\u001b[39mpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_settings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_settings(protocol\u001b[38;5;241m=\u001b[39mprotocol, secure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:266\u001b[0m, in \u001b[0;36mConnectionProfile._apply_settings\u001b[0;34m(self, uri, scheme, protocol, secure, verify, address, host, port, port_number, auth, user, password, **other)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_scheme(scheme)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol:\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_protocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m secure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__secure \u001b[38;5;241m=\u001b[39m secure\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:297\u001b[0m, in \u001b[0;36mConnectionProfile._apply_protocol\u001b[0;34m(self, protocol)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply_protocol\u001b[39m(\u001b[38;5;28mself\u001b[39m, protocol):\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbolt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown protocol \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m protocol)\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__protocol \u001b[38;5;241m=\u001b[39m protocol\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown protocol 'neo4j'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from py2neo import Graph\n",
    "import mlflow\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Load environment variables ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Neo4j connection settings ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "raw_uri    = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASS = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "# Normalize URI: use bolt:// if someone set neo4j://\n",
    "if raw_uri and raw_uri.startswith(\"neo4j://\"):\n",
    "    NEO4J_URI = raw_uri.replace(\"neo4j://\", \"bolt://\", 1)\n",
    "else:\n",
    "    NEO4J_URI = raw_uri\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ MLflow tracking setup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(\"MCMI\")\n",
    "\n",
    "def test_neo4j_connection(uri, user, password):\n",
    "    graph = Graph(uri, auth=(user, password))\n",
    "    return graph.run(\"RETURN 'Connection successful!' AS greeting\").evaluate()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Test & Clear Neo4j inside an MLflow run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"Test & Clear Neo4j\"):\n",
    "    # 1) Test connection\n",
    "    result = test_neo4j_connection(NEO4J_URI, NEO4J_USER, NEO4J_PASS)\n",
    "    mlflow.log_param(\"Connection Test\", result)\n",
    "    print(f\"üîó Connection test result: {result}\")\n",
    "\n",
    "    # 2) Clear the entire database\n",
    "    graph = Graph(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASS))\n",
    "    graph.delete_all()\n",
    "    mlflow.log_param(\"Database Cleared\", True)\n",
    "    print(\"üóëÔ∏è  All nodes and relationships have been deleted.\")\n",
    "\n",
    "    # 3) Confirm it's empty\n",
    "    remaining = graph.run(\"MATCH (n) RETURN count(n) AS nodes\").evaluate()\n",
    "    mlflow.log_param(\"Remaining Nodes\", remaining)\n",
    "    print(f\"üìä Remaining node count after clear: {remaining}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a2d41d-2f56-4b50-b4b1-77ebcd2c7279",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 13: Create RIASEC Schema in Neo4j** <a class=\"anchor\" id=\"RIASEC_page_4\"></a>\n",
    "\n",
    "\n",
    "[Back to Top](#RIASEC_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "957e5833-d44d-401d-8df7-0b430efac4f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown protocol 'neo4j'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSet NEO4J_URI, NEO4J_USERNAME & NEO4J_PASSWORD in .env\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# ‚îÄ‚îÄ‚îÄ 2) Connect & clear ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbolt_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mNEO4J_USER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNEO4J_PASS\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müîó Connected to Neo4j via \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbolt_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m graph\u001b[38;5;241m.\u001b[39mdelete_all()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/database.py:288\u001b[0m, in \u001b[0;36mGraph.__init__\u001b[0;34m(self, profile, name, **settings)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, profile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings):\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice \u001b[38;5;241m=\u001b[39m \u001b[43mGraphService\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m=\u001b[39m Schema(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/database.py:119\u001b[0m, in \u001b[0;36mGraphService.__init__\u001b[0;34m(self, profile, **settings)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connector_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m profile\u001b[38;5;241m.\u001b[39mrouting:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Ensures credentials are checked on construction\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     connector_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connector \u001b[38;5;241m=\u001b[39m \u001b[43mConnector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconnector_settings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graphs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/client/__init__.py:948\u001b[0m, in \u001b[0;36mConnector.__init__\u001b[0;34m(self, profile, user_agent, init_size, max_size, max_age, routing_refresh_ttl)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, profile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_agent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    946\u001b[0m              max_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_age\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, routing_refresh_ttl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile \u001b[38;5;241m=\u001b[39m ServiceProfile(profile)\n\u001b[0;32m--> 948\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_routers \u001b[38;5;241m=\u001b[39m [\u001b[43mConnectionProfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_agent \u001b[38;5;241m=\u001b[39m user_agent\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server_agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:176\u001b[0m, in \u001b[0;36mConnectionProfile.__init__\u001b[0;34m(self, profile, **settings)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__password \u001b[38;5;241m=\u001b[39m DEFAULT_PASSWORD\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__address \u001b[38;5;241m=\u001b[39m Address\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_env_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:220\u001b[0m, in \u001b[0;36mConnectionProfile._apply_env_vars\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply_env_vars\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m NEO4J_URI:\n\u001b[0;32m--> 220\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNEO4J_URI\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m NEO4J_AUTH:\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_settings(auth\u001b[38;5;241m=\u001b[39mNEO4J_AUTH)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:232\u001b[0m, in \u001b[0;36mConnectionProfile._apply_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    230\u001b[0m parsed \u001b[38;5;241m=\u001b[39m urlsplit(uri)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_scheme\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheme\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mnetloc:\n\u001b[1;32m    234\u001b[0m     settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m parsed\u001b[38;5;241m.\u001b[39mnetloc\u001b[38;5;241m.\u001b[39mpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:249\u001b[0m, in \u001b[0;36mConnectionProfile._apply_scheme\u001b[0;34m(self, scheme)\u001b[0m\n\u001b[1;32m    247\u001b[0m     protocol, _, ext \u001b[38;5;241m=\u001b[39m scheme\u001b[38;5;241m.\u001b[39mpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_settings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_settings(protocol\u001b[38;5;241m=\u001b[39mprotocol, secure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:266\u001b[0m, in \u001b[0;36mConnectionProfile._apply_settings\u001b[0;34m(self, uri, scheme, protocol, secure, verify, address, host, port, port_number, auth, user, password, **other)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_scheme(scheme)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol:\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_protocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m secure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__secure \u001b[38;5;241m=\u001b[39m secure\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:297\u001b[0m, in \u001b[0;36mConnectionProfile._apply_protocol\u001b[0;34m(self, protocol)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply_protocol\u001b[39m(\u001b[38;5;28mself\u001b[39m, protocol):\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbolt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown protocol \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m protocol)\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__protocol \u001b[38;5;241m=\u001b[39m protocol\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown protocol 'neo4j'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from py2neo import Graph\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Load environment & fix URI ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "raw_uri = os.getenv(\"NEO4J_URI\", \"\")\n",
    "# py2neo expects bolt://\n",
    "if raw_uri.startswith(\"neo4j://\"):\n",
    "    bolt_uri = \"bolt://\" + raw_uri[len(\"neo4j://\"):]\n",
    "else:\n",
    "    bolt_uri = raw_uri\n",
    "\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASS = os.getenv(\"NEO4J_PASSWORD\")\n",
    "if not all([bolt_uri, NEO4J_USER, NEO4J_PASS]):\n",
    "    raise RuntimeError(\"Set NEO4J_URI, NEO4J_USERNAME & NEO4J_PASSWORD in .env\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Connect & clear ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "graph = Graph(bolt_uri, auth=(NEO4J_USER, NEO4J_PASS))\n",
    "print(f\"üîó Connected to Neo4j via {bolt_uri}\")\n",
    "graph.delete_all()\n",
    "print(\"üóëÔ∏è  Cleared all existing nodes & relationships\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Load the RIASEC flattened CSV ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "csv_path = os.path.join(\"..\", \"Datasets\", \"riasec.csv\")\n",
    "riasec_df = pd.read_csv(csv_path)\n",
    "print(f\"‚úÖ Loaded {len(riasec_df)} rows from {csv_path}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Build the taxonomy in Neo4j ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "for _, row in riasec_df.iterrows():\n",
    "    factor    = row['Factor']\n",
    "    adjective = row['Adjective']\n",
    "    synonym   = row['Synonym']\n",
    "    verb      = row['Verb']\n",
    "    noun      = row['Noun']\n",
    "\n",
    "    # Skip if missing\n",
    "    if not factor or not adjective:\n",
    "        continue\n",
    "\n",
    "    # Merge the high-level nodes\n",
    "    graph.run(\"MERGE (f:RIASEC_Factor {name: $factor})\", factor=factor)\n",
    "    graph.run(\"MERGE (a:RIASEC_Adjective {name: $adjective})\", adjective=adjective)\n",
    "\n",
    "    # Merge the leaves\n",
    "    if synonym:\n",
    "        graph.run(\"MERGE (s:RIASEC_Synonym {name: $synonym})\", synonym=synonym)\n",
    "    if verb:\n",
    "        graph.run(\"MERGE (v:RIASEC_Verb {name: $verb})\",    verb=verb)\n",
    "    if noun:\n",
    "        graph.run(\"MERGE (n:RIASEC_Noun {name: $noun})\",    noun=noun)\n",
    "\n",
    "    # Create relationships\n",
    "    graph.run(\n",
    "        \"\"\"\n",
    "        MATCH (f:RIASEC_Factor {name:$factor}), (a:RIASEC_Adjective {name:$adjective})\n",
    "        MERGE (f)-[:RIASEC_HAS_ADJECTIVE]->(a)\n",
    "        \"\"\",\n",
    "        factor=factor, adjective=adjective\n",
    "    )\n",
    "    if synonym:\n",
    "        graph.run(\n",
    "            \"\"\"\n",
    "            MATCH (a:RIASEC_Adjective {name:$adjective}), (s:RIASEC_Synonym {name:$synonym})\n",
    "            MERGE (a)-[:RIASEC_HAS_SYNONYM]->(s)\n",
    "            \"\"\",\n",
    "            adjective=adjective, synonym=synonym\n",
    "        )\n",
    "    if verb:\n",
    "        graph.run(\n",
    "            \"\"\"\n",
    "            MATCH (a:RIASEC_Adjective {name:$adjective}), (v:RIASEC_Verb {name:$verb})\n",
    "            MERGE (a)-[:RIASEC_HAS_VERB]->(v)\n",
    "            \"\"\",\n",
    "            adjective=adjective, verb=verb\n",
    "        )\n",
    "    if noun:\n",
    "        graph.run(\n",
    "            \"\"\"\n",
    "            MATCH (a:RIASEC_Adjective {name:$adjective}), (n:RIASEC_Noun {name:$noun})\n",
    "            MERGE (a)-[:RIASEC_HAS_NOUN]->(n)\n",
    "            \"\"\",\n",
    "            adjective=adjective, noun=noun\n",
    "        )\n",
    "\n",
    "print(\"üéâ Completed building the RIASEC taxonomy graph in Neo4j.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14d5d0e-5256-4f3b-94b6-6655bb4ac1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from py2neo import Graph\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Load env & set up connection ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv()\n",
    "raw = os.getenv(\"NEO4J_URI\", \"\")\n",
    "if raw.startswith(\"neo4j://\"):\n",
    "    bolt_uri = \"bolt://\" + raw[len(\"neo4j://\"):]\n",
    "else:\n",
    "    bolt_uri = raw\n",
    "\n",
    "user = os.getenv(\"NEO4J_USERNAME\")\n",
    "pwd  = os.getenv(\"NEO4J_PASSWORD\")\n",
    "if not all([bolt_uri, user, pwd]):\n",
    "    raise RuntimeError(\"Make sure NEO4J_URI, NEO4J_USERNAME & NEO4J_PASSWORD are set\")\n",
    "\n",
    "graph = Graph(bolt_uri, auth=(user, pwd))\n",
    "print(\"üîó Connected to Neo4j via\", bolt_uri)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Load your DiSC dataset ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "csv_path = \"../Datasets/riasec.csv\"\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"{csv_path} not found\")\n",
    "\n",
    "riasec_df = pd.read_csv(\n",
    "    csv_path,\n",
    "    converters={'Embedding': lambda s: ast.literal_eval(s) if isinstance(s, str) else s}\n",
    ")\n",
    "print(f\"‚úÖ Loaded {len(riasec_df)} rows from {csv_path}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Clear the database ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "graph.delete_all()\n",
    "print(\"üóëÔ∏è  Cleared all existing nodes & relationships\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Function to build the graph ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def create_riasec_graph(g: Graph, df: pd.DataFrame):\n",
    "    for _, row in df.iterrows():\n",
    "        domain      = row['Domain']\n",
    "        subcat      = row['Subcategory']\n",
    "        factor      = row['Factor']\n",
    "        adjective   = row['Adjective']\n",
    "        synonym     = row['Synonym']\n",
    "        verb        = row['Verb']\n",
    "        noun        = row['Noun']\n",
    "\n",
    "        # 1) MERGE each node\n",
    "        g.run(\"MERGE (D:Domain {name:$domain})\",      domain=domain)\n",
    "        g.run(\"MERGE (S:Subcategory {name:$subcat})\", subcat=subcat)\n",
    "        g.run(\"MERGE (F:Factor      {name:$factor})\", factor=factor)\n",
    "        g.run(\"MERGE (A:Adjective   {name:$adjective})\", adjective=adjective)\n",
    "\n",
    "        # 2) Link them\n",
    "        g.run(\"\"\"\n",
    "            MATCH (D:Domain{name:$domain}), (S:Subcategory{name:$subcat})\n",
    "            MERGE (D)-[:HAS_SUBCATEGORY]->(S)\n",
    "        \"\"\", domain=domain, subcat=subcat)\n",
    "\n",
    "        g.run(\"\"\"\n",
    "            MATCH (S:Subcategory{name:$subcat}), (F:Factor{name:$factor})\n",
    "            MERGE (S)-[:HAS_FACTOR]->(F)\n",
    "        \"\"\", subcat=subcat, factor=factor)\n",
    "\n",
    "        g.run(\"\"\"\n",
    "            MATCH (F:Factor{name:$factor}), (A:Adjective{name:$adjective})\n",
    "            MERGE (F)-[:HAS_ADJECTIVE]->(A)\n",
    "        \"\"\", factor=factor, adjective=adjective)\n",
    "\n",
    "        # 3) Under Adjective, add Synonym, Verb, Noun\n",
    "        if synonym:\n",
    "            g.run(\"MERGE (Y:Synonym {name:$synonym})\", synonym=synonym)\n",
    "            g.run(\"\"\"\n",
    "                MATCH (A:Adjective{name:$adjective}), (Y:Synonym{name:$synonym})\n",
    "                MERGE (A)-[:HAS_SYNONYM]->(Y)\n",
    "            \"\"\", adjective=adjective, synonym=synonym)\n",
    "\n",
    "        if verb:\n",
    "            g.run(\"MERGE (V:Verb {name:$verb})\", verb=verb)\n",
    "            g.run(\"\"\"\n",
    "                MATCH (A:Adjective{name:$adjective}), (V:Verb{name:$verb})\n",
    "                MERGE (A)-[:HAS_VERB]->(V)\n",
    "            \"\"\", adjective=adjective, verb=verb)\n",
    "\n",
    "        if noun:\n",
    "            g.run(\"MERGE (N:Noun {name:$noun})\", noun=noun)\n",
    "            g.run(\"\"\"\n",
    "                MATCH (A:Adjective{name:$adjective}), (N:Noun{name:$noun})\n",
    "                MERGE (A)-[:HAS_NOUN]->(N)\n",
    "            \"\"\", adjective=adjective, noun=noun)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Build it! ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "create_riasec_graph(graph, riasec_df)\n",
    "print(\"üéâ Completed building the DiSC taxonomy graph in Neo4j.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5da5e04-52b0-432d-9324-ba465af1865b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "746cc0fc-8e2f-4f59-b0e8-75b663e2802b",
   "metadata": {},
   "source": [
    "```cypher\n",
    "MATCH p=(d:Domain)-[:HAS_SUBCATEGORY]->(s:Subcategory)\n",
    "         -[:HAS_FACTOR]->(f:Factor)\n",
    "         -[:HAS_ADJECTIVE]->(a:Adjective)\n",
    "OPTIONAL MATCH leaf=(a)-[:HAS_SYNONYM|HAS_VERB|HAS_NOUN]->(x)\n",
    "RETURN p, leaf\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a55358-91a2-4b3f-8bc7-e22d822b975e",
   "metadata": {},
   "source": [
    "## Process for Building the RIASEC Personality Model\n",
    "\n",
    "1. **Data Preparation**\n",
    "\n",
    "   * Define taxonomy (`Factor \\to Adjective \\to Synonym/Verb/Noun`).\n",
    "   * Normalize lists and flatten to CSV (`riasec.csv`).\n",
    "\n",
    "2. **Embedding Generation**\n",
    "\n",
    "   * Load `riasec.csv` into pandas.\n",
    "   * Initialize OpenAI client and MLflow.\n",
    "   * Generate embeddings via `client.embeddings.create(...)` for full text prompt.\n",
    "   * Save `riasec_embeddings.csv` with `Embedding` column.\n",
    "\n",
    "3. **Label Encoding**\n",
    "\n",
    "   * Load embeddings CSV.\n",
    "   * Fit `LabelEncoder` on `Factor` column.\n",
    "   * Save encoder (`riasec_label_encoder.pkl`).\n",
    "   * Visualize mapping with bar chart and log to MLflow.\n",
    "\n",
    "4. **Model Training**\n",
    "\n",
    "   * Load embeddings and label encoder.\n",
    "   * Split into train/test (stratify when possible).\n",
    "   * Train `RandomForestClassifier`.\n",
    "   * Log metrics, artifacts, and model to MLflow.\n",
    "\n",
    "5. **Model Evaluation**\n",
    "\n",
    "   * Reload model and encoder.\n",
    "   * Split and predict on test set.\n",
    "   * Compute accuracy, classification report, confusion matrix.\n",
    "   * Log evaluation artifacts to MLflow.\n",
    "   * Perform cross-validation (LOO if class imbalance).\n",
    "\n",
    "6. **Inference on New Data**\n",
    "\n",
    "   * Load model & encoder.\n",
    "   * Define `predict_factor(text)` helper that requests embedding and predicts.\n",
    "   * Test on meaningful example sentences.\n",
    "   * Log predictions to MLflow.\n",
    "\n",
    "7. **Visualization & Clustering**\n",
    "\n",
    "   * Train RF on full dataset.\n",
    "   * In‚Äësample evaluation & plot confusion matrix.\n",
    "   * PCA into 2D & scatter by encoded class.\n",
    "   * K‚ÄëMeans clustering on embeddings, save `riasec_clustered_embeddings.csv`.\n",
    "   * Plot clusters in PCA space.\n",
    "\n",
    "8. **Neo4j Graph Construction**\n",
    "\n",
    "   * Clear existing graph: `MATCH (n) DETACH DELETE n`.\n",
    "   * Ingest `riasec.csv`, create nodes for Factor, Adjective, Synonym, Verb, Noun.\n",
    "   * Create `:RELATES_TO` relationships following taxonomy hierarchy.\n",
    "\n",
    "9. **Cypher Query to View Graph**\n",
    "\n",
    "   ```cypher\n",
    "   MATCH p = (f:Factor)-[:HAS_ADJECTIVE]->(a:Adjective)\n",
    "             -[:HAS_SYNONYM|HAS_VERB|HAS_NOUN]->(x)\n",
    "   RETURN p LIMIT 100\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## BibTeX Entries (`references.bib`)\n",
    "\n",
    "```bibtex\n",
    "@article{Holland1959,\n",
    "  author    = {Holland, John L.},\n",
    "  title     = {A Theory of Vocational Choice},\n",
    "  journal   = {Journal of Counseling Psychology},\n",
    "  year      = {1959},\n",
    "  volume    = {6},\n",
    "  number    = {1},\n",
    "  pages     = {35--47},\n",
    "  doi       = {10.1037/h0040767},\n",
    "}\n",
    "\n",
    "@book{Holland1973,\n",
    "  author    = {Holland, John L.},\n",
    "  title     = {Making Vocational Choices: A Theory of Careers},\n",
    "  publisher = {Prentice-Hall},\n",
    "  year      = {1973},\n",
    "}\n",
    "\n",
    "@article{GatiMeir1982,\n",
    "  author    = {Gati, Itamar and Meir, Eliyahu I.},\n",
    "  title     = {Congruence and Consistency Derived from the Circular and the Hierarchical Models as Predictors of Occupational Choice Satisfaction},\n",
    "  journal   = {Journal of Vocational Behavior},\n",
    "  year      = {1982},\n",
    "  volume    = {20},\n",
    "  pages     = {354--365},\n",
    "  doi       = {10.1016/0001-8791(82)90022-7},\n",
    "}\n",
    "\n",
    "@article{OsipowAshbyWall1966,\n",
    "  author    = {Osipow, Samuel H. and Ashby, John and Wall, Harry},\n",
    "  title     = {Personality Types and Vocational Choice: A Test of Holland's Theory},\n",
    "  journal   = {The Personnel and Guidance Journal},\n",
    "  year      = {1966},\n",
    "  volume    = {45},\n",
    "  number    = {1},\n",
    "  pages     = {37--42},\n",
    "  doi       = {10.1002/j.2164-4918.1966.tb03063.x},\n",
    "}\n",
    "\n",
    "@article{Nauta2010,\n",
    "  author    = {Nauta, Margaret M.},\n",
    "  title     = {The Development, Evolution, and Status of Holland's Theory of Vocational Personalities: Reflections and Future Directions for Counseling Psychology},\n",
    "  journal   = {Journal of Counseling Psychology},\n",
    "  year      = {2010},\n",
    "  volume    = {57},\n",
    "  number    = {1},\n",
    "  pages     = {11--22},\n",
    "  doi       = {10.1037/a0018213},\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9073f9-01c9-4778-b64e-8ce2fd50a6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (personality-models-env)",
   "language": "python",
   "name": "personality-models-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
