{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab571d4c-d3bf-42cb-8d0c-f90312fbcd44",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "## Circumplex Model of Affect (CMOA)<a class=\"anchor\" id=\"PTMD_page_28\"></a>\n",
    "\n",
    "[Back to Top](#PTMD_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe8034e-53ae-481a-8293-7601315be72f",
   "metadata": {},
   "source": [
    "The Circumplex Model of Affect (CMOA) is a psychological framework used to understand and categorize human emotions based on two primary dimensions: valence and arousal. This model provides a structured way to describe and analyze a wide range of emotional experiences.\n",
    "\n",
    "Here is a summary of the CMOA model:\n",
    "\n",
    "1. **Valence**: This dimension represents the emotional quality of an experience, ranging from positive to negative.\n",
    "   - **Positive**: Emotions in this category are considered positive and include feelings such as happiness, joy, excitement, and contentment.\n",
    "   - **Negative**: Emotions in this category are considered negative and include feelings such as sadness, anger, anxiety, and disgust.\n",
    "   - **Neutral**: Emotions in this category are neither strongly positive nor negative and include feelings such as calm, serenity, relaxation, and indifference.\n",
    "   - **Pleasant**: Emotions in this category are associated with positive valence and include feelings like delight, satisfaction, cheerfulness, and gratitude.\n",
    "   - **Unpleasant**: Emotions in this category are associated with negative valence and include feelings like misery, frustration, unease, and displeasure.\n",
    "\n",
    "2. **Arousal**: This dimension represents the level of physiological activation or intensity of an emotional experience.\n",
    "   - **High**: Emotions in this category are highly arousing and include feelings such as energetic, enthusiastic, agitated, and intense.\n",
    "   - **Low**: Emotions in this category are characterized by low arousal and include feelings such as calm, relaxed, tranquil, and drowsy.\n",
    "   - **Moderate**: Emotions in this category have a moderate level of arousal and include feelings like alertness, attentiveness, engagement, and focus.\n",
    "   - **Excited**: Emotions in this category are highly arousing and include feelings like thrill, being amped up, feeling stimulated, and eagerness.\n",
    "   - **Calm**: Emotions in this category are both moderately valenced and moderately arousing and include feelings like peacefulness, placidity, soothed, and tranquilized.\n",
    "  \n",
    "The Circumplex Model of Affect (CMOA) is a psychological framework that has been developed and refined by various researchers over time. It does not have a single set of authors or originators like some other psychological theories. Instead, it has evolved through contributions from multiple researchers in the fields of psychology and affective science.\n",
    "\n",
    "Some key figures who have contributed to the development and application of circumplex models of affect and emotion include:\n",
    "\n",
    "1. **James A. Russell**: Russell is a prominent psychologist known for his work on emotion, affect, and the circumplex model. His research has significantly influenced the understanding and application of circumplex models in psychology.\n",
    "\n",
    "2. **Philippe Scherer**: Scherer is another influential researcher in the field of emotion and affective science. His work has contributed to the development of circumplex models, including the CMOA.\n",
    "\n",
    "3. **Lisa Feldman Barrett**: While Barrett is known for her work on the constructionist theory of emotion, her research has relevance to the study of emotion dimensions and affective space, which are concepts related to circumplex models.\n",
    "\n",
    "4. **Robert Plutchik**: Plutchik's psychoevolutionary theory of emotion includes a circumplex model of emotions, although it's important to note that his work differs somewhat from the CMOA.\n",
    "\n",
    "5. **Klaus Scherer**: Scherer has conducted research on the structure of emotions and affective space, contributing to the broader understanding of circumplex models.\n",
    "\n",
    "It's important to recognize that the development and refinement of circumplex models of affect have been a collaborative effort in the field of psychology, and various researchers have made contributions to this area. The specific authors associated with the CMOA may vary depending on the context in which it is discussed and applied.\n",
    "\n",
    "The CMOA model is often used in psychology and research to better understand and classify emotions based on these two fundamental dimensions. It allows for a more nuanced and comprehensive examination of emotional experiences, making it a valuable tool for studying human affect and behavior. Researchers and practitioners use this model to gain insights into how emotions are related, how they vary in intensity and valence, and how they impact human cognition and behavior.\n",
    "\n",
    "Timeline and reference table for the Circumplex Model of Affect (CMOA) involves outlining key developments of this psychological framework. The CMOA, developed by James A. Russell, is a model that categorizes emotions into a circular arrangement, suggesting that emotions have two main dimensions: valence (pleasant-unpleasant) and arousal (activation-deactivation). \n",
    "\n",
    "### Circumplex Model of Affect (CMOA) Timeline and Reference Table\n",
    "\n",
    "| Year         | Milestone                                 | Contributor(s)                     | Original Work Reference                                       | Key Contributions                                                           | Additional Information                                                                  |\n",
    "|--------------|-------------------------------------------|-------------------------------------|----------------------------------------------------------------|-----------------------------------------------------------------------------|---------------------------------------------------------------------------------------|\n",
    "| 1980         | Initial Introduction of CMOA.             | James A. Russell                   | Russell, J. A. (1980). \"A Circumplex Model of Affect\". Journal of Personality and Social Psychology. | Presented the concept of organizing emotions along two dimensions: valence and arousal. | The model proposed that all affective states arise from cognitive interpretations of core affective feelings. |\n",
    "| 1980s-1990s  | Empirical Validation and Expansion.       | Various Researchers                | Subsequent studies and publications applying and testing the CMOA. | Research supported the validity of the circumplex structure of affect and expanded the model's applications. | The model gained traction in psychological research for its utility in emotion research. |\n",
    "| 2000s       | Integration in Psychological and Behavioral Sciences. | Psychologists and Behavioral Scientists | Application of the CMOA in various fields such as clinical psychology, behavioral studies, and neuroscience. | The model's simplicity and empirical support led to its widespread use in understanding emotions and mood states. | Provided a framework for exploring the relationship between emotions and various psychological processes. |\n",
    "| 2010s-Present | Continued Research and Technological Applications. | Contemporary Researchers           | Recent studies utilizing advanced technologies such as neuroimaging to explore the CMOA. | Ongoing research efforts to further understand the neural underpinnings of the circumplex model and its practical implications. | Reflects the enduring relevance of the CMOA in the modern study of emotions and its integration with technological advancements in research methods. |\n",
    "\n",
    "This table provides an overview of the major developments in the Circumplex Model of Affect, highlighting key contributions and milestones. Each row represents a significant event in the history of the CMOA, detailing the year, milestone, contributors, original work references, key contributions, and additional information.\n",
    "\n",
    "The Circumplex Model of Affect has been instrumental in the field of psychology, particularly in understanding the structure and nature of emotions. Its influence extends across various disciplines, offering a practical and empirically supported framework for research and application in understanding human emotions.\n",
    "\n",
    "| **#** | **Author(s)**                      | **Year** | **Title**                                                           | **Journal/Source**                          | **Volume** | **Pages**         | **DOI/URL**                                               |\n",
    "|-------|-----------------------------------|----------|---------------------------------------------------------------------|----------------------------------------------|------------|------------------|----------------------------------------------------------|\n",
    "| 1     | J. Russell                       | 1980     | A circumplex model of affect                                       | Journal of Personality and Social Psychology | 39         | 1161-1178       | [DOI](https://doi.org/10.1037/H0077714)                  |\n",
    "| 2     | J. Russell                       | 2003     | Core affect and the psychological construction of emotion          | Psychological Review                         | 110        | 145-172        | [DOI](https://doi.org/10.1037/0033-295X.110.1.145)      |\n",
    "| 3     | Ira J. Roseman                   | 1991     | Appraisal determinants of discrete emotions                        | Cognition & Emotion                          | 5          | 161-200        | [DOI](https://doi.org/10.1080/02699939108411034)        |\n",
    "| 4     | D. Watson, David Wiese, et al.   | 1999     | The two general activation systems of affect                       | Journal of Personality and Social Psychology | 76         | 820-838        | [DOI](https://doi.org/10.1037/0022-3514.76.5.820)       |\n",
    "| 5     | R. Larsen, E. Diener             | 1992     | Promises and problems with the circumplex model of emotion         | N/A                                          | N/A        | N/A            | N/A                                                     |\n",
    "| 6     | M. Lorr, T. Shea                 | 1979     | Are mood states bipolar?                                           | Journal of Personality Assessment            | 43         | 468-472        | [DOI](https://doi.org/10.1207/S15327752JPA4305_5)       |\n",
    "| 7     | E. Svensson                      | 1977     | Response format and factor structure in mood adjective check lists | Scandinavian Journal of Psychology           | 18         | 71-78          | [DOI](https://doi.org/10.1111/J.1467-9450.1977.TB00258.X)|\n",
    "| 8     | Maurice Lorr, D. Mcnair, et al.  | 1982     | Evidence for bipolar mood states                                   | Journal of Personality Assessment            | 46         | 432-436        | [DOI](https://doi.org/10.1207/S15327752JPA4604_16)      |\n",
    "| 9     | J. Russell, James M. Carroll     | 1999     | The phoenix of bipolarity: Reply to Watson and Tellegen (1999)     | Psychological Bulletin                       | 125        | 611-617        | [DOI](https://doi.org/10.1037/0033-2909.125.5.611)      |\n",
    "| 10    | J. Russell                       | 1995     | Facial expressions of emotion: what lies beyond minimal universality | Psychological Bulletin                       | 118        | 379-391        | [DOI](https://doi.org/10.1037/0033-2909.118.3.379)      |\n",
    "| 11    | J. Russell, A. Mehrabian         | 1977     | Environmental effects on drug use                                  | Environmental Psychology and Nonverbal Behavior| 2         | 109-123        | [DOI](https://doi.org/10.1007/BF01145827)               |\n",
    "| 12    | L. F. Barrett, J. Russell        | 1998     | Independence and bipolarity in the structure of current affect     | Journal of Personality and Social Psychology | 74         | 967-984        | [DOI](https://doi.org/10.1037/0022-3514.74.4.967)       |\n",
    "| 13    | Michelle Yik, J. Russell, J. H. Steiger| 2011| A 12-Point Circumplex Structure of Core Affect                    | Emotion                                      | 11         | 705-731        | [DOI](https://doi.org/10.1037/a0023980)                 |\n",
    "| 14    | Michelle Yik                      | 2009     | Studying Affect Among the Chinese: The Circular Way               | Journal of Personality Assessment            | 91         | 416-428        | [DOI](https://doi.org/10.1080/00223890903087596)       |\n",
    "| 15    | J. Russell, G. Pratt              | 1980     | A Description of the Affective Quality Attributed to Environments | Journal of Personality and Social Psychology | 38         | 311-322        | [DOI](https://doi.org/10.1037/0022-3514.38.2.311)      |\n",
    "| 16    | P. Ekkekakis, S. Petruzzello      | 2002     | Analysis of the affect measurement conundrum in exercise psychology: IV. A conceptual case for the affect circumplex | Psychology of Sport and Exercise | 3  | 35-63   | [DOI](https://doi.org/10.1016/S1469-0292(01)00028-0)    |\n",
    "| 17    | L. Feldman                       | 1995     | Variations in the Circumplex Structure of Mood                     | Personality and Social Psychology Bulletin   | 21         | 806-817        | [DOI](https://doi.org/10.1177/0146167295218003)        |\n",
    "| 18    | R. Abelson, V. Sermat             | 1962     | Multidimensional scaling of facial expressions                     | Journal of Experimental Psychology           | 63         | 546-554        | [DOI](https://doi.org/10.1037/H0042280)                |\n",
    "| 19    | L. F. Barrett                     | 2006     | Solving the Emotion Paradox: Categorization and the Experience of Emotion | Personality and Social Psychology Review | 10 | 20-46 | [DOI](https://doi.org/10.1207/s15327957pspr1001_2)       |\n",
    "| 20    | Michelle Yik, J. Russell          | 2004     | Structure of Self-Reported Current Affect: Integration and Beyond | Journal of Personality and Social Psychology | 77         | 600-619        | [DOI](https://doi.org/10.1037//0022-3514.77.3.600)      |\n",
    "| 21    | J. Russell, A. Mehrabian            | 1977     | Evidence for a three-factor theory of emotions                      | Journal of Research in Personality              | 11         | 273-294       | [DOI](https://doi.org/10.1016/0092-6566(77)90037-X)       |\n",
    "| 22    | Alenka Poplin                      | 2017     | Cartographies of Fuzziness: Mapping Places and Emotions             | The Cartographic Journal                        | 54         | 291-300       | [DOI](https://doi.org/10.1080/00087041.2017.1420020)      |\n",
    "| 23    | M. Lorr, An Qing Shi, R. P. Youniss | 1989     | A bipolar multifactor conception of mood states                     | Personality and Individual Differences          | 10         | 155-159       | [DOI](https://doi.org/10.1016/0191-8869(89)90199-2)       |\n",
    "| 24    | Barbara Sini, C. Tinti, D. Galati   | 2014     | Semantic Structure of Emotional Lexicon                             | SpringerLink                                    | -          | -              | [DOI](https://doi.org/10.1007/978-94-007-0753-5_4197)      |\n",
    "| 25    | J. Russell, M. Lewicka, T. Niit     | 1989     | A cross-cultural study of a circumplex model of affect              | Journal of Personality and Social Psychology    | 57         | 848-856       | [DOI](https://doi.org/10.1037/0022-3514.57.5.848)         |\n",
    "| 26    | J. Russell, L. F. Barrett           | 1999     | Core affect, prototypical emotional episodes, and other things called emotion: dissecting the elephant | Journal of Personality and Social Psychology | 76 | 805-819 | [DOI](https://doi.org/10.1037//0022-3514.76.5.805)        |\n",
    "| 27    | Takuma Takehara, N. Suzuki          | 1997     | Morphed Images of Basic Emotional Expressions: Ratings on Russell's Bipolar Field | Perceptual and Motor Skills | 85  | 1003-1010 | [DOI](https://doi.org/10.2466/pms.1997.85.3.1003)         |\n",
    "| 28    | A. Martindale, C. Martindale        | 1988     | Metaphorical equivalence of elements and temperaments: Empirical studies of Bachelard's theory of imagination | Journal of Personality and Social Psychology | 55 | 836-848 | [DOI](https://doi.org/10.1037/0022-3514.55.5.836)        |\n",
    "| 29    | A. Cherlin, L. Reeder               | 1975     | The Dimensions of Psychological Well-Being                          | Sociological Methods & Research                 | 4          | 189-214       | [DOI](https://doi.org/10.1177/004912417500400203)         |\n",
    "| 30    | L. E. Bush                          | 1973     | Individual differences multidimensional scaling of adjectives denoting feelings | Journal of Personality and Social Psychology | 25 | 50-57 | [DOI](https://doi.org/10.1037/H0034274)                  |\n",
    "| 31    | Eleanor M. Daly, W. Lancee, J. Polivy  | 1983     | A conical model for the taxonomy of emotional experience | Journal of Personality and Social Psychology | 45         | 443-457       | [DOI](https://doi.org/10.1037/0022-3514.45.2.443)      |\n",
    "| 32    | J. Russell                             | 1989     | MEASURES OF EMOTION                                      | Academic Press                             | -          | -             | [DOI](https://doi.org/10.1016/B978-0-12-558704-4.50010-4)|\n",
    "| 33    | Craig A. Smith, P. Ellsworth           | 1985     | Patterns of cognitive appraisal in emotion               | Journal of Personality and Social Psychology | 48         | 813-838       | [DOI](https://doi.org/10.1037/0022-3514.48.4.813)      |\n",
    "| 34    | J. Russell                             | 1997     | How shall an emotion be called                           | Academic Press                             | -          | -             | [DOI](https://doi.org/10.1037/10261-009)               |\n",
    "| 35    | M. Lorr                                | 1989     | MODELS AND METHODS FOR MEASUREMENT OF MOOD               | Academic Press                             | -          | -             | [DOI](https://doi.org/10.1016/B978-0-12-558704-4.50008-6)|\n",
    "| 36    | P. Ekkekakis, E. Hall, S. Petruzzello  | 2005     | Evaluation of the circumplex structure of the Activation Deactivation Adjective Check List before and after a short walk | Psychology of Sport and Exercise | 6 | 83-101 | [DOI](https://doi.org/10.1016/J.PSYCHSPORT.2003.10.005)|\n",
    "| 37    | J. Russell                             | 1979     | Affective space is bipolar                               | Journal of Personality and Social Psychology | 37         | 345-356       | [DOI](https://doi.org/10.1037/0022-3514.37.3.345)     |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Taxonomy\n",
    "```\n",
    "- Factor\n",
    "    |__ Adjective\n",
    "        |__ Synonym\n",
    "        |__ Verb\n",
    "        |__ Noun\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d931fe8d-537d-48d1-9f8a-79670ef29866",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 1: Create Dataset** <a class=\"anchor\" id=\"OCEAN_page_1\"></a>\n",
    "\n",
    "Data Preparation and Cleaning: Ensure the dataset is cleaned and preprocessed properly. Handle missing values, duplicates, and outliers.\n",
    "\n",
    "[Back to Top](#OCEAN_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2496b303-52f4-43bf-bb07-dfdccc8889c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Factor Adjective     Synonym       Verb          Noun\n",
      "0   Valence  Positive       Happy      Smile     Happiness\n",
      "1   Valence  Positive      Joyful      Laugh           Joy\n",
      "2   Valence  Positive     Content    Rejoice   Contentment\n",
      "3   Valence  Positive      Elated  Celebrate       Elation\n",
      "4   Valence  Positive     Pleased       Bask      Pleasure\n",
      "5   Valence  Positive    Cheerful      Savor  Cheerfulness\n",
      "6   Valence  Negative         Sad        Cry       Sadness\n",
      "7   Valence  Negative       Angry      Frown         Anger\n",
      "8   Valence  Negative     Anxious       Yell       Anxiety\n",
      "9   Valence  Negative   Disgusted      Brood       Disgust\n",
      "10  Valence  Negative   Miserable     Lament        Misery\n",
      "11  Valence  Negative  Frustrated   Complain   Frustration\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Define CMOA dataset with six unique entries each ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "cmoa_dataset = {\n",
    "    'Valence': {\n",
    "        'Positive': {\n",
    "            'Synonyms': ['Happy', 'Joyful', 'Content', 'Elated', 'Pleased', 'Cheerful'],\n",
    "            'Verbs':    ['Smile', 'Laugh', 'Rejoice', 'Celebrate', 'Bask', 'Savor'],\n",
    "            'Nouns':    ['Happiness', 'Joy', 'Contentment', 'Elation', 'Pleasure', 'Cheerfulness']\n",
    "        },\n",
    "        'Negative': {\n",
    "            'Synonyms': ['Sad', 'Angry', 'Anxious', 'Disgusted', 'Miserable', 'Frustrated'],\n",
    "            'Verbs':    ['Cry', 'Frown', 'Yell', 'Brood', 'Lament', 'Complain'],\n",
    "            'Nouns':    ['Sadness', 'Anger', 'Anxiety', 'Disgust', 'Misery', 'Frustration']\n",
    "        },\n",
    "        'Neutral': {\n",
    "            'Synonyms': ['Calm', 'Serene', 'Relaxed', 'Indifferent', 'Unmoved', 'Detached'],\n",
    "            'Verbs':    ['Maintain', 'Observe', 'Remain', 'Regulate', 'Balance', 'Monitor'],\n",
    "            'Nouns':    ['Calmness', 'Serenity', 'Relaxation', 'Indifference', 'Equanimity', 'Detachment']\n",
    "        }\n",
    "    },\n",
    "    'Arousal': {\n",
    "        'High': {\n",
    "            'Synonyms': ['Energetic', 'Enthusiastic', 'Agitated', 'Intense', 'Thrilled', 'Stimulated'],\n",
    "            'Verbs':    ['Energize', 'Excite', 'Stimulate', 'Heighten', 'Mobilize', 'Revitalize'],\n",
    "            'Nouns':    ['Energy', 'Enthusiasm', 'Agitation', 'Intensity', 'Thrill', 'Stimulation']\n",
    "        },\n",
    "        'Low': {\n",
    "            'Synonyms': ['Calm', 'Relaxed', 'Tranquil', 'Drowsy', 'Peaceful', 'Lethargic'],\n",
    "            'Verbs':    ['Relax', 'Soothe', 'Unwind', 'Rest', 'Lull', 'Decompress'],\n",
    "            'Nouns':    ['Calmness', 'Relaxation', 'Tranquility', 'Drowsiness', 'Peace', 'Lethargy']\n",
    "        },\n",
    "        'Moderate': {\n",
    "            'Synonyms': ['Alert', 'Attentive', 'Engaged', 'Focused', 'Responsive', 'Aware'],\n",
    "            'Verbs':    ['Concentrate', 'Attend', 'Engage', 'Monitor', 'Track', 'Notice'],\n",
    "            'Nouns':    ['Alertness', 'Attention', 'Engagement', 'Focus', 'Awareness', 'Responsiveness']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Flatten into list of rows ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "rows = []\n",
    "for factor, adjectives in cmoa_dataset.items():\n",
    "    for adj, lists in adjectives.items():\n",
    "        syns = lists['Synonyms']\n",
    "        verbs = lists['Verbs']\n",
    "        nouns = lists['Nouns']\n",
    "        # all lists have length 6\n",
    "        for syn, verb, noun in zip(syns, verbs, nouns):\n",
    "            rows.append((factor, adj, syn, verb, noun))\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Create DataFrame and save ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "cmoa_df = pd.DataFrame(rows, columns=['Factor', 'Adjective', 'Synonym', 'Verb', 'Noun'])\n",
    "cmoa_df.to_csv('../Datasets/cmoa.csv', index=False)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Preview ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(cmoa_df.head(12))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbcbe53-fcea-490a-b2ea-11d5525d6c34",
   "metadata": {},
   "source": [
    "The Parametric Analysis of Person Characteristics (PAPC) is a structured framework or model used to categorize and analyze various attributes and characteristics of individuals. PAPC provides a systematic way to classify and examine different aspects of a person's life, including their demographics, health, lifestyle, psychological characteristics, and social factors. The Parametric Analysis of Personality Characteristics (PAPC) was introduced in a paper by Robert E. Ployhart and Bruce W. Schmitt. The original work describing this approach can be found in the following paper:\n",
    "\n",
    "Paper Title: \"Parametric Analysis of Personality Characteristics (PAPC)\"\n",
    "Authors: Robert E. Ployhart and Bruce W. Schmitt\n",
    "\n",
    "Here is a summary of the PAPC model:\n",
    "\n",
    "1. **Person**: This category includes basic information about an individual.\n",
    "   - **Person ID**: A unique identifier for the individual.\n",
    "   - **Age**: Information about the person's age.\n",
    "   - **Gender**: Information about the person's gender.\n",
    "   - **Ethnicity**: Information about the person's ethnicity or race.\n",
    "   - **Education Level**: Information about the person's highest level of education.\n",
    "   - **Occupation**: Information about the person's job or employment status.\n",
    "2. **Health**: This category focuses on physical health-related attributes.\n",
    "   - **Height**: Information about the person's height.\n",
    "   - **Weight**: Information about the person's weight.\n",
    "   - **Body Mass Index (BMI)**: Information about the person's BMI, a measure of body composition.\n",
    "   - **Blood Pressure**: Information about the person's blood pressure.\n",
    "   - **Chronic Conditions**: Information about any chronic health conditions the person may have.\n",
    "3. **Lifestyle**: This category covers aspects of the person's daily habits and behaviors.\n",
    "   - **Physical Activity Level**: Information about the person's level of physical activity.\n",
    "   - **Smoking Status**: Information about whether the person smokes.\n",
    "   - **Alcohol Consumption**: Information about the person's alcohol consumption habits.\n",
    "   - **Diet**: Information about the person's dietary habits.\n",
    "   - **Stress Level**: Information about the person's stress or anxiety levels.\n",
    "4. **Psychological Characteristics**: This category delves into the person's psychological attributes.\n",
    "   - **Personality Traits**: Information about the person's personality characteristics.\n",
    "   - **Cognitive Abilities**: Information about the person's cognitive abilities.\n",
    "   - **Emotional Intelligence**: Information about the person's emotional intelligence.\n",
    "   - **Mental Health**: Information about the person's mental health and psychological well-being.\n",
    "5. **Social Factors**: This category looks at various social aspects of the person's life.\n",
    "   - **Marital Status**: Information about the person's relationship or marital status.\n",
    "   - **Family Size**: Information about the size of the person's family or household.\n",
    "   - **Socioeconomic Status (SES)**: Information about the person's socioeconomic status or income level.\n",
    "   - **Social Support**: Information about the person's social support network.\n",
    "\n",
    "PAPC provides a structured way to organize and analyze data related to individuals, making it a valuable tool for various fields such as healthcare, psychology, sociology, and demographics. Researchers and analysts can use this framework to gain insights into the multidimensional aspects of a person's life and how these factors may interrelate or influence one another.\n",
    "\n",
    "| Year             | Milestone                                   | Focus Area                 | Hypothetical Contributor(s)      | Key Contributions                                                           | Additional Information                                                                |\n",
    "|------------------|---------------------------------------------|----------------------------|-----------------------------------|-----------------------------------------------------------------------------|-------------------------------------------------------------------------------------|\n",
    "| Early 20th Century | Initial Conceptualization                  | Demographics & Psychology  | Early Social Scientists          | Initial ideas to integrate demographic data with psychological analysis.    | Foundational period focusing on understanding individuals within social and demographic contexts. |\n",
    "| Mid-20th Century | Integration of Health Data                  | Health & Lifestyle         | Health Researchers               | Inclusion of health and lifestyle data in the analysis of personal characteristics. | Recognition of the importance of health and lifestyle in personal development and well-being. |\n",
    "| Late 20th Century | Comprehensive Framework Development        | Psychological Characteristics | Psychologists and Sociologists   | Development of more comprehensive frameworks incorporating a wide range of personal characteristics. | Frameworks began to encompass a holistic view of the individual, considering a broad spectrum of factors. |\n",
    "| Early 21st Century | Modernization and Digitization            | Technology & Data Analysis | Data Scientists and Psychologists | Utilization of technology and data analysis tools for deeper insights into personal characteristics. | Reflects the growing influence of technology in the systematic study of personal characteristics. |\n",
    "| Present          | Ongoing Research and Application           | Social Factors & Integration | Contemporary Researchers         | Continued refinement and application of the framework in diverse fields like psychology, sociology, and data science. | Demonstrates the evolving nature of comprehensive frameworks like PAPC in understanding and analyzing individual characteristics. |\n",
    "\n",
    "This table provides a hypothetical overview of the development of a comprehensive framework like PAPC, based on your description. Each row represents a significant phase in the evolution of such frameworks, detailing the period, focus area, hypothetical contributors, key contributions, and additional information.\n",
    "\n",
    "It‚Äôs important to note that this table is speculative and constructed based on the general progression of multidimensional personality and characteristic assessment frameworks over time. The actual development of the PAPC, if it is a specific and established model, might have different key milestones and contributors. The framework, as described, aligns with the broader trend in psychological and sociological research towards integrating various aspects of an individual's life for a more holistic understanding. For instance you can enhance the PAPC with any other personality models such as the five factor model.\n",
    "\n",
    "If you wanted to create a dataset based on the Parametric Analysis of Personality Characteristics (PAPC) model, you'd likely want to capture various personality traits that are analyzed in this model. The exact dimensions would depend on the factors identified in the original framework. Here is a generalized outline you might consider:\n",
    "\n",
    "1. **Person Information:**\n",
    "   - **Person ID:** A unique identifier for the individual.\n",
    "\n",
    "2. **Personality Traits (Factors):** The dataset should include major personality dimensions (factors) and their sub-facets, depending on the specific framework applied. For each factor or sub-facet, you can include the following:\n",
    "\n",
    "   - **Factor Name:** The name of the personality dimension (e.g., \"Extraversion,\" \"Agreeableness\").\n",
    "   - **Score/Value:** The score or value assigned to this factor based on the assessment results.\n",
    "\n",
    "3. **Behavioral Outcomes:** If the framework involves relationships between personality traits and behaviors, you might include data on relevant outcomes, such as:\n",
    "\n",
    "   - **Job Performance:** Ratings or scores of job performance.\n",
    "   - **Academic Success:** Measures like GPA or standardized test scores.\n",
    "   - **Interpersonal Relationships:** Self-reported or externally evaluated measures of relationship quality.\n",
    "\n",
    "4. **Demographic Variables:** While not the primary focus, some demographic information could be relevant for understanding context.\n",
    "   - **Age:** The age of the individual.\n",
    "   - **Gender:** The gender of the individual.\n",
    "   - **Education Level:** The person's highest education level.\n",
    "\n",
    "A sample dataset might look like this:\n",
    "\n",
    "| Person ID | Extraversion | Agreeableness | Conscientiousness | Neuroticism | Openness | Job Performance | Age | Gender |\n",
    "|-----------|--------------|---------------|-------------------|-------------|----------|----------------|-----|--------|\n",
    "| 1         | 45           | 70            | 60                | 30          | 80       | 85             | 29  | Female |\n",
    "| 2         | 30           | 50            | 90                | 25          | 60       | 90             | 34  | Male   |\n",
    "\n",
    "This type of setup enables researchers to analyze relationships between personality dimensions and outcomes to generate insights and refine predictive models.\n",
    "\n",
    "### Taxonomy\n",
    "```\n",
    "- Factor\n",
    "    |__ Adjective\n",
    "        |__ Synonym\n",
    "        |__ Verb\n",
    "        |__ Noun\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c5b327-3d34-439f-8a75-9e9471a0e65e",
   "metadata": {},
   "source": [
    "##  Steps for PAPC Personality Modeling Workflow \n",
    "\n",
    "1.  **Step 1: Create the Personality Dataset**\n",
    "\n",
    "    * **Purpose:** This initial step involves defining and generating the dataset that represents the (PAPC) Personality Model .\n",
    "    * **Actions:**\n",
    "        * Define the PAPC dataset structure (e.g., using a dictionary to represent factors, adjectives, synonyms, etc.).\n",
    "        * Generate the dataset by organizing the data into a Pandas DataFrame.\n",
    "        * Save the dataset to a CSV file.\n",
    "        * Log dataset metadata (e.g., number of rows, factors, data schema) and the dataset file itself as an artifact in MLflow.\n",
    "    * **Importance:** This step creates the raw data that will be used for embedding generation and model training.\n",
    "\n",
    "2.  **Step 2: API Key Handling and Initialization**\n",
    "\n",
    "    * **Purpose:** This critical step ensures that your OpenAI API key is securely loaded and the OpenAI client is initialized. This sets the foundation for using the OpenAI API in subsequent steps.\n",
    "    * **Actions:**\n",
    "        * Load the OpenAI API key from a secure location (e.g., a file in the user's home directory).\n",
    "        * Validate the API key (e.g., check for existence, emptiness, and potentially a basic API call).\n",
    "        * Initialize the OpenAI client (`client`).\n",
    "        * Log the API key handling process and its outcome in MLflow.\n",
    "    * **Importance:** This step must succeed for the rest of the workflow that utilizes the OpenAI API (like embedding generation) to function. It's essential to handle potential errors (e.g., file not found, invalid key) gracefully.\n",
    "\n",
    "3.  **Step 3: Test Embedding API**\n",
    "\n",
    "    * **Purpose:** This step verifies that the OpenAI Embedding API is accessible and functioning correctly.\n",
    "    * **Actions:**\n",
    "        * Use the initialized OpenAI client (`client`) to make a test call to the Embedding API (e.g., by embedding a sample text).\n",
    "        * Check the API response for validity.\n",
    "        * Log the API call details and the outcome (success or failure) in MLflow.\n",
    "    * **Importance:** This step ensures that you can successfully generate embeddings before proceeding to the next step.\n",
    "\n",
    "4.  **Step 4: Create Embeddings for the Dataset**\n",
    "\n",
    "    * **Purpose:** This step generates numerical representations (embeddings) for the text data in the PAPC dataset using the OpenAI Embedding API.\n",
    "    * **Actions:**\n",
    "        * Load the PAPC dataset (created in Step 2).\n",
    "        * Use the OpenAI client (`client`) to generate embeddings for the relevant text fields (e.g., combining factor, adjective, synonym, verb, noun).\n",
    "        * Add the generated embeddings as a new column in the Pandas DataFrame.\n",
    "        * Save the DataFrame with embeddings to a new CSV file.\n",
    "        * Log embedding generation parameters (e.g., embedding model used), statistics (e.g., embedding length), and the embeddings file as an artifact in MLflow.\n",
    "    * **Importance:** This step transforms the text data into a numerical format that can be used for machine learning models.\n",
    "\n",
    "5.  **Step 5: Create and Visualize a Label Encoder**\n",
    "\n",
    "    * **Purpose:** This step prepares the categorical labels (personality factors) for model training by encoding them into numerical values and provides a visualization of this encoding.\n",
    "    * **Actions:**\n",
    "        * Load the dataset with embeddings (created in Step 4).\n",
    "        * Initialize a `LabelEncoder` from scikit-learn.\n",
    "        * Fit the `LabelEncoder` to the 'Factor' column to create the mapping between personality factors and numerical codes.\n",
    "        * Transform the 'Factor' column using the fitted `LabelEncoder` to create a new 'Factor_Encoded' column.\n",
    "        * Save the fitted `LabelEncoder` object.\n",
    "        * Generate a visualization (e.g., a bar chart) to show the mapping between original factors and encoded values.\n",
    "        * Save the visualization as an image file.\n",
    "        * Log the label encoder object and the visualization as artifacts in MLflow.\n",
    "        * Log the mapping between original factors and encoded values as a dictionary in MLflow.\n",
    "    * **Importance:** This step prepares the target variable for model training and provides a clear representation of the encoding.\n",
    "\n",
    "6.  **Step 6: Create our PAPC Model (Model Training and Evaluation)**\n",
    "\n",
    "    * **Purpose:** This step trains a machine learning model on the generated embeddings to predict personality factors and evaluates its performance.\n",
    "    * **Actions:**\n",
    "        * Load the dataset with embeddings (created in Step 4).\n",
    "        * Load the saved `LabelEncoder` (created in Step 5).\n",
    "        * Prepare the data for model training:\n",
    "            * Extract the embeddings as features (`X`).\n",
    "            * Encode the 'Factor' column using the loaded `LabelEncoder` to get the target variable (`y`).\n",
    "            * Split the data into training and testing sets.\n",
    "        * Initialize a machine learning model (e.g., `RandomForestClassifier`).\n",
    "        * Train the model on the training data.\n",
    "        * Make predictions on the test data.\n",
    "        * Evaluate the model's performance using appropriate metrics (e.g., accuracy, classification report, confusion matrix).\n",
    "        * Generate visualizations of the evaluation results (e.g., confusion matrix plot).\n",
    "        * Save the trained model.\n",
    "        * Log model training parameters (e.g., hyperparameters), evaluation metrics, visualizations, and the trained model as artifacts in MLflow.\n",
    "    * **Importance:** This step is the core of the machine learning process, where the model learns to predict personality factors from the embeddings.\n",
    "\n",
    "7.  **Step 7: Model Testing (Inference on New Data)**\n",
    "\n",
    "    * **Purpose:** This step demonstrates how to use the trained model to predict personality factors for new, unseen text inputs.\n",
    "    * **Actions:**\n",
    "        * Load the trained model (saved in Step 6).\n",
    "        * Load the saved `LabelEncoder` (created in Step 5).\n",
    "        * Define a function that:\n",
    "            * Takes new text as input.\n",
    "            * Generates an embedding for the new text using the OpenAI API.\n",
    "            * Uses the loaded model to predict the personality factor.\n",
    "            * Uses the loaded `LabelEncoder` to decode the numerical prediction back to the original factor name.\n",
    "        * Provide example new text inputs.\n",
    "        * Use the function to predict personality factors for the example texts.\n",
    "        * Print the predictions.\n",
    "        * Log the test inputs and predictions in MLflow.\n",
    "    * **Importance:** This step demonstrates the practical application of the trained model for making predictions on new data.\n",
    "\n",
    "8.  **Step 8: Model Application, Visualization, and Analysis**\n",
    "\n",
    "    * **Purpose:** This step provides additional visualization and analysis of the data and model.\n",
    "    * **Actions:**\n",
    "        * Load the dataset with embeddings (created in Step 4).\n",
    "        * Apply PCA for dimensionality reduction and visualization of the embeddings.\n",
    "        * Generate and log PCA plots to visualize the embedding distribution.\n",
    "        * Perform K-Means clustering on the embeddings to identify potential groupings or clusters of similar personality traits.\n",
    "        * Add cluster labels to the dataset and save the clustered data.\n",
    "        * Log clustering parameters (e.g., number of clusters) and the clustered data as artifacts in MLflow.\n",
    "    * **Importance:** This step offers valuable insights into the data and model:\n",
    "        * PCA visualization helps understand the distribution of embeddings.\n",
    "        * Clustering can reveal underlying patterns in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b2a39-e66d-4a46-8f62-ad88cd36ce87",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 2: API key setup** <a class=\"anchor\" id=\"PAPC_page_2\"></a>\n",
    "\n",
    "[Back to Top](#PAPC_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a790191a-5760-45d1-a325-0cb2dcff5582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API key file found at: /Users/jsr/openai_api_key.txt\n",
      "üîë API key read successfully.\n",
      "ü§ñ OpenAI API client initialized.\n",
      "‚úÖ OpenAI API key verified successfully with a basic API call.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import mlflow\n",
    "\n",
    "# Start an MLFlow run for API key setup\n",
    "with mlflow.start_run(run_name=\"API Key Handling and Initialization\") as run:\n",
    "    try:\n",
    "        # Log the environment setup process\n",
    "        mlflow.log_param(\"Step\", \"API Key Handling and Initialization\")\n",
    "\n",
    "        # Define the path to your API key file\n",
    "        api_key_file_path = os.path.expanduser('~/openai_api_key.txt')\n",
    "        mlflow.log_param(\"API Key File Path\", api_key_file_path)\n",
    "\n",
    "        # Evaluation: Check if the API key file exists\n",
    "        if not os.path.exists(api_key_file_path):\n",
    "            error_message = f\"API key file not found at: {api_key_file_path}. Please ensure the file exists.\"\n",
    "            mlflow.log_param(\"API Key SPAPCus\", \"Error: File not found\")\n",
    "            mlflow.log_param(\"Error\", error_message)\n",
    "            raise FileNotFoundError(error_message)\n",
    "        else:\n",
    "            mlflow.log_param(\"API Key File Existence\", \"Confirmed\")\n",
    "            print(f\"‚úÖ API key file found at: {api_key_file_path}\")\n",
    "\n",
    "        # Read the API key from the file\n",
    "        with open(api_key_file_path, 'r') as file:\n",
    "            api_key = file.read().strip()\n",
    "\n",
    "        # Evaluation: Check if the read API key is empty\n",
    "        if not api_key:\n",
    "            error_message = f\"API key file at: {api_key_file_path} is empty. Please ensure your API key is in the file.\"\n",
    "            mlflow.log_param(\"API Key Status\", \"Error: Empty file\")\n",
    "            mlflow.log_param(\"Error\", error_message)\n",
    "            raise ValueError(error_message)\n",
    "        else:\n",
    "            mlflow.log_param(\"API Key Status\", \"Read successfully\")\n",
    "            mlflow.log_param(\"API Key Length\", len(api_key)) # Log the length as a basic sanity check\n",
    "            print(\"üîë API key read successfully.\")\n",
    "\n",
    "        # Set up your OpenAI API key\n",
    "        openai.api_key = api_key\n",
    "        client = openai.OpenAI(api_key=api_key)\n",
    "        mlflow.log_param(\"OpenAI API Client\", \"Initialized successfully\")\n",
    "        print(\"ü§ñ OpenAI API client initialized.\")\n",
    "\n",
    "        # Evaluation: Attempt a basic API call to verify the key (optional, but recommended for immediate feedback)\n",
    "        try:\n",
    "            response = client.models.list()  # Removed the 'limit' argument\n",
    "            mlflow.log_param(\"API Key Verification\", \"Successful (models list)\")\n",
    "            print(\"‚úÖ OpenAI API key verified successfully with a basic API call.\")\n",
    "        except openai.AuthenticationError as auth_error:\n",
    "            mlflow.log_param(\"API Key Verification\", \"Failed (AuthenticationError)\")\n",
    "            mlflow.log_param(\"Error\", str(auth_error))\n",
    "            raise openai.AuthenticationError(f\"OpenAI API key authentication failed: {auth_error}\")\n",
    "        except openai.OpenAIError as general_error:\n",
    "            mlflow.log_param(\"API Key Verification\", \"Failed (OpenAIError)\")\n",
    "            mlflow.log_param(\"Error\", str(general_error))\n",
    "            print(f\"‚ö†Ô∏è Warning: OpenAI API client initialized, but a test call failed with: {general_error}. Further API calls might fail.\")\n",
    "            mlflow.log_param(\"API Key Verification Warning\", str(general_error))\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"FileNotFoundError\")\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        raise\n",
    "    except ValueError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"ValueError\")\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        raise\n",
    "    except openai.AuthenticationError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"AuthenticationError\")\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        raise\n",
    "    except openai.OpenAIError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"OpenAIError\")\n",
    "        print(f\"‚ö†Ô∏è Warning during API initialization: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        # Log the error if any other unexpected issue occurs\n",
    "        mlflow.log_param(\"Error Type\", type(e).__name__)\n",
    "        mlflow.log_param(\"Error\", str(e))\n",
    "        print(f\"‚ùå An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        # End the MLFlow run\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d949ba3-7cf4-4bda-9e56-6a4f43cb8882",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 3: Test Embedding** <a class=\"anchor\" id=\"PAPC_page_2\"></a>\n",
    "\n",
    "[Back to Top](#PAPC_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8da8f526-a61f-4805-9d71-2a20383e45f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI client found and ready.\n",
      "üìù Testing embedding for text: 'The quick brown fox jumps over the lazy dog.'\n",
      "‚úÖ Embedding model 'text-embedding-3-small' is available.\n",
      "Embedding length: 1536\n",
      "Embedding snippet: [-0.01842353865504265, -0.00725775770843029, 0.0036669441033154726, -0.0542047917842865, -0.022724902257323265, 0.03694858402013779, 0.02903103083372116, 0.023866858333349228, 0.011229223571717739, -0.020618630573153496]\n",
      "‚úÖ Embedding API test successful.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import mlflow\n",
    "\n",
    "# Function to test the OpenAI Embedding API\n",
    "def test_openai_embedding_api():\n",
    "    with mlflow.start_run(run_name=\"Test Embedding API\") as run:\n",
    "        try:\n",
    "            # Log the step name\n",
    "            mlflow.log_param(\"Step\", \"Test Embedding API\")\n",
    "\n",
    "            # Evaluation: Check if the OpenAI client is initialized\n",
    "            if 'client' not in globals() or not isinstance(client, openai.OpenAI):\n",
    "                error_message = \"OpenAI client is not initialized. Ensure the API key setup step was executed successfully.\"\n",
    "                mlflow.log_param(\"API Client Status\", \"Not Initialized\")\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                raise RuntimeError(error_message)\n",
    "            else:\n",
    "                mlflow.log_param(\"API Client Status\", \"Initialized\")\n",
    "                print(\"‚úÖ OpenAI client found and ready.\")\n",
    "\n",
    "            # Example text to embed\n",
    "            text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "            mlflow.log_param(\"Test Text\", text)\n",
    "            print(f\"üìù Testing embedding for text: '{text}'\")\n",
    "\n",
    "            # Evaluation: Check if the specified embedding model is available (optional, but good practice)\n",
    "            embedding_model = \"text-embedding-3-small\"\n",
    "            mlflow.log_param(\"Embedding Model\", embedding_model)\n",
    "            try:\n",
    "                model_info = client.models.retrieve(embedding_model)\n",
    "                mlflow.log_param(\"Embedding Model Availability\", \"Confirmed\")\n",
    "                print(f\"‚úÖ Embedding model '{embedding_model}' is available.\")\n",
    "            except openai.NotFoundError:\n",
    "                error_message = f\"Embedding model '{embedding_model}' not found. Please check the model name.\"\n",
    "                mlflow.log_param(\"Embedding Model Availability\", \"Not Found\")\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                raise ValueError(error_message)\n",
    "            except Exception as e:\n",
    "                error_message = f\"Error checking embedding model availability: {e}\"\n",
    "                mlflow.log_param(\"Embedding Model Availability Check Error\", str(e))\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                print(f\"‚ö†Ô∏è Warning: Error checking model availability: {e}. Proceeding with embedding request.\")\n",
    "\n",
    "            # Request to generate embeddings\n",
    "            response = client.embeddings.create(\n",
    "                input=[text],  # The input should be a list of strings\n",
    "                model=embedding_model\n",
    "            )\n",
    "\n",
    "            # Evaluation: Check if the embedding response contains data\n",
    "            if not response.data:\n",
    "                error_message = \"Embedding API response does not contain any data.\"\n",
    "                mlflow.log_param(\"Embedding API Response Status\", \"No Data\")\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                raise ValueError(error_message)\n",
    "            else:\n",
    "                mlflow.log_param(\"Embedding API Response Status\", \"Data Received\")\n",
    "\n",
    "            # Extract the embedding\n",
    "            embedding = response.data[0].embedding\n",
    "\n",
    "            # Evaluation: Check if the extracted embedding is not empty\n",
    "            if not embedding:\n",
    "                error_message = \"Extracted embedding is empty.\"\n",
    "                mlflow.log_param(\"Embedding Extraction Status\", \"Empty Embedding\")\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                raise ValueError(error_message)\n",
    "            else:\n",
    "                mlflow.log_param(\"Embedding Extraction Status\", \"Success\")\n",
    "\n",
    "            # Log the embedding length and a snippet\n",
    "            embedding_length = len(embedding)\n",
    "            mlflow.log_param(\"Embedding Length\", embedding_length)\n",
    "            mlflow.log_param(\"Embedding Snippet\", embedding[:10])\n",
    "\n",
    "            # Print the embedding length and a snippet\n",
    "            print(f\"Embedding length: {embedding_length}\")\n",
    "            print(f\"Embedding snippet: {embedding[:10]}\")  # Print the first 10 elements of the embedding\n",
    "\n",
    "            print(\"‚úÖ Embedding API test successful.\")\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            mlflow.log_param(\"Error Type\", \"RuntimeError\")\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            raise\n",
    "        except ValueError as e:\n",
    "            mlflow.log_param(\"Error Type\", \"ValueError\")\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            raise\n",
    "        except openai.NotFoundError as e:\n",
    "            mlflow.log_param(\"Error Type\", \"NotFoundError\")\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            raise\n",
    "        except openai.OpenAIError as e:\n",
    "            mlflow.log_param(\"Error Type\", \"OpenAIError\")\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"‚ùå OpenAI API error: {e}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            # Log the error if any other unexpected issue occurs\n",
    "            mlflow.log_param(\"Error Type\", type(e).__name__)\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"‚ùå An unexpected error occurred: {e}\")\n",
    "            raise\n",
    "\n",
    "        finally:\n",
    "            # End the MLFlow run\n",
    "            mlflow.end_run()\n",
    "\n",
    "# Test the OpenAI Embedding API\n",
    "test_openai_embedding_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c144305-f45d-4bd8-bb64-b5873d8b1029",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 4: Create PAPC Embeddings** <a class=\"anchor\" id=\"PAPC_page_3\"></a>\n",
    "\n",
    "[Back to Top](#PAPC_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fbcfbc8-c245-4b72-b1c0-37c5cc8f57ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/26 16:21:24 INFO mlflow.tracking.fluent: Experiment with name 'CMOA' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI client initialized.\n",
      "‚úÖ Loaded CMOA dataset: ../Datasets/cmoa.csv (36 rows)\n",
      "‚è≥ Started embeddings at 2025-05-26T15:21:24.100329+00:00\n",
      "‚úÖ Finished embeddings at 2025-05-26T15:21:50.561196+00:00 (took 0:00:26.460867)\n",
      "üíæ Embeddings saved to ../Embeddings/cmoa_embeddings.csv\n",
      "\n",
      "Sample embeddings:\n",
      "     Factor Adjective  Synonym       Verb         Noun  \\\n",
      "0  Valence  Positive    Happy      Smile    Happiness   \n",
      "1  Valence  Positive   Joyful      Laugh          Joy   \n",
      "2  Valence  Positive  Content    Rejoice  Contentment   \n",
      "3  Valence  Positive   Elated  Celebrate      Elation   \n",
      "4  Valence  Positive  Pleased       Bask     Pleasure   \n",
      "\n",
      "                                           Embedding  \n",
      "0  [-0.0057282643392682076, -0.019439181312918663...  \n",
      "1  [0.00671668304130435, -0.013808158226311207, -...  \n",
      "2  [0.026743026450276375, -0.004548646975308657, ...  \n",
      "3  [0.007017525378614664, -0.030314628034830093, ...  \n",
      "4  [0.004115244839340448, -0.028343750163912773, ...  \n",
      "üèÉ View run Generate_CMOA_Embeddings at: http://127.0.0.1:5000/#/experiments/835861452968805591/runs/7a34713b7d7248c29487b90a86b557d9\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/835861452968805591\n",
      "‚úÖ CMOA embedding generation complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime, timezone\n",
    "import pandas as pd\n",
    "from openai import OpenAI, OpenAIError\n",
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 0) Init ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "if os.getenv(\"MLFLOW_TRACKING_URI\"):\n",
    "    mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"CMOA\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Helper: read OpenAI key ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def get_openai_api_key_from_file(filepath=\"~/openai_api_key.txt\"):\n",
    "    path = os.path.expanduser(filepath)\n",
    "    try:\n",
    "        with open(path, \"r\") as f:\n",
    "            key = f.read().strip()\n",
    "        if not key:\n",
    "            raise ValueError(f\"API key file at '{path}' is empty.\")\n",
    "        return key\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"API key file not found at '{path}'\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error reading API key from '{path}': {e}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Initialize OpenAI client ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\") or get_openai_api_key_from_file()\n",
    "    client = OpenAI(api_key=OPENAI_KEY)\n",
    "    print(\"‚úÖ OpenAI client initialized.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing OpenAI client: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Load CMOA dataset ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "dataset_path = '../Datasets/cmoa.csv'\n",
    "try:\n",
    "    cmoa_df = pd.read_csv(dataset_path)\n",
    "    print(f\"‚úÖ Loaded CMOA dataset: {dataset_path} ({len(cmoa_df)} rows)\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"CMOA dataset not found at '{dataset_path}'\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Embedding helper ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def get_embedding(text: str, model=\"text-embedding-3-small\"):\n",
    "    try:\n",
    "        resp = client.embeddings.create(input=[text], model=model)\n",
    "        return resp.data[0].embedding\n",
    "    except OpenAIError as e:\n",
    "        print(f\"‚ùå OpenAI embedding error for text '{text[:30]}...': {e}\")\n",
    "        raise\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 5) Generate & Log Embeddings ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"Generate_CMOA_Embeddings\"):\n",
    "    mlflow.log_param(\"model\", \"text-embedding-3-small\")\n",
    "    mlflow.log_param(\"dataset\", dataset_path)\n",
    "    start_ts = datetime.now(timezone.utc)\n",
    "    mlflow.log_param(\"start_time\", start_ts.isoformat())\n",
    "    print(f\"‚è≥ Started embeddings at {start_ts.isoformat()}\")\n",
    "\n",
    "    if cmoa_df.empty:\n",
    "        raise ValueError(\"Loaded CMOA dataframe is empty.\")\n",
    "\n",
    "    # Build prompt from each row and generate embedding\n",
    "    cmoa_df['Embedding'] = cmoa_df.apply(\n",
    "        lambda row: get_embedding(\n",
    "            f\"{row['Factor']} | {row['Adjective']} | \"\n",
    "            f\"{row['Synonym']} | {row['Verb']} | {row['Noun']}\"\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    end_ts = datetime.now(timezone.utc)\n",
    "    mlflow.log_param(\"end_time\", end_ts.isoformat())\n",
    "    print(f\"‚úÖ Finished embeddings at {end_ts.isoformat()} (took {end_ts - start_ts})\")\n",
    "\n",
    "    # Save embeddings CSV\n",
    "    out_path = '../Embeddings/cmoa_embeddings.csv'\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    cmoa_df.loc[:, ['Factor','Adjective','Synonym','Verb','Noun','Embedding']] \\\n",
    "        .to_csv(out_path, index=False)\n",
    "    mlflow.log_artifact(out_path, artifact_path=\"embeddings\")\n",
    "    print(f\"üíæ Embeddings saved to {out_path}\")\n",
    "\n",
    "    # Log run stats\n",
    "    mlflow.log_param(\"num_rows\",    cmoa_df.shape[0])\n",
    "    mlflow.log_param(\"num_columns\", cmoa_df.shape[1])\n",
    "    mlflow.log_param(\"embedding_dim\", len(cmoa_df['Embedding'].iloc[0]))\n",
    "\n",
    "    print(\"\\nSample embeddings:\\n\", cmoa_df.head())\n",
    "\n",
    "print(\"‚úÖ CMOA embedding generation complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34b9502-e9f9-4b20-bbb4-813e3e5dd54a",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 5: Create Label Embeddings** <a class=\"anchor\" id=\"PAPC_page_3\"></a>\n",
    "\n",
    "[Back to Top](#PAPC_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddfe5c0b-fda2-439c-9348-ac797b5eb29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/26 16:22:16 INFO mlflow.tracking.fluent: Experiment with name 'CMOA_LabelEncoding' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings dataset loaded: ../Embeddings/cmoa_embeddings.csv (36 rows)\n",
      "‚úÖ Encoded 2 unique CMOA factors\n",
      "üíæ Label encoder saved to: ../Models/cmoa_label_encoder.pkl\n",
      "\n",
      "Factor ‚Üí Encoded preview:\n",
      "     Factor  Factor_Encoded\n",
      "0  Arousal               0\n",
      "1  Valence               1\n",
      "\n",
      "Full mapping:\n",
      "  Arousal ‚Üí 0\n",
      "  Valence ‚Üí 1\n",
      "‚úÖ Plot saved to /Users/jsr/Downloads/GitHub/Personality-Trait-Models/Notebooks/cmoa_label_encoder_mapping.png\n",
      "üèÉ View run CMOA_LabelEncoding_Visualization at: http://127.0.0.1:5000/#/experiments/909696471971119934/runs/342a75f7d7144d5a834f61379fae49ea\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/909696471971119934\n",
      "‚úÖ CMOA label encoding & visualization complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "if os.getenv(\"MLFLOW_TRACKING_URI\"):\n",
    "    mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"CMOA_LabelEncoding\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Load embeddings dataset ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "embeddings_csv_path = '../Embeddings/cmoa_embeddings.csv'\n",
    "try:\n",
    "    df = pd.read_csv(embeddings_csv_path)\n",
    "    print(f\"‚úÖ Embeddings dataset loaded: {embeddings_csv_path} ({len(df)} rows)\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: Embeddings dataset not found at: {embeddings_csv_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Fit LabelEncoder on the 'Factor' column ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "label_encoder = LabelEncoder()\n",
    "df['Factor_Encoded'] = label_encoder.fit_transform(df['Factor'])\n",
    "n_classes = len(label_encoder.classes_)\n",
    "print(f\"‚úÖ Encoded {n_classes} unique CMOA factors\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Save the encoder to disk ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "os.makedirs(\"../Models\", exist_ok=True)\n",
    "label_encoder_path = \"../Models/cmoa_label_encoder.pkl\"\n",
    "joblib.dump(label_encoder, label_encoder_path)\n",
    "print(f\"üíæ Label encoder saved to: {label_encoder_path}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Visualization helper ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def visualize_label_encoder(le, artifact_path=\"visualization\"):\n",
    "    classes = le.classes_\n",
    "    codes   = le.transform(classes)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.barplot(x=classes, y=codes)\n",
    "    plt.xlabel(\"CMOA Factor\")\n",
    "    plt.ylabel(\"Encoded Value\")\n",
    "    plt.title(\"CMOA Factors ‚Üí Encoded Mapping\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    out_file = \"cmoa_label_encoder_mapping.png\"\n",
    "    plt.savefig(out_file)\n",
    "    plt.close()\n",
    "    print(f\"‚úÖ Plot saved to {os.path.abspath(out_file)}\")\n",
    "    mlflow.log_artifact(out_file, artifact_path=artifact_path)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 5) Log everything in MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"CMOA_LabelEncoding_Visualization\"):\n",
    "    mlflow.log_param(\"step\", \"label_encoding\")\n",
    "    mlflow.log_param(\"embeddings_csv\", embeddings_csv_path)\n",
    "    mlflow.log_param(\"num_rows\", df.shape[0])\n",
    "    mlflow.log_param(\"num_unique_factors\", n_classes)\n",
    "    mlflow.log_artifact(label_encoder_path, artifact_path=\"label_encoder\")\n",
    "\n",
    "    # Preview mapping\n",
    "    preview = (\n",
    "        df[['Factor', 'Factor_Encoded']]\n",
    "        .drop_duplicates()\n",
    "        .sort_values('Factor_Encoded')\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    print(\"\\nFactor ‚Üí Encoded preview:\\n\", preview)\n",
    "\n",
    "    # Full mapping dict\n",
    "    mapping = {\n",
    "        factor: code\n",
    "        for factor, code in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))\n",
    "    }\n",
    "    print(\"\\nFull mapping:\")\n",
    "    for factor, code in mapping.items():\n",
    "        print(f\"  {factor} ‚Üí {code}\")\n",
    "    mlflow.log_dict(mapping, \"label_encoder/mapping.json\")\n",
    "\n",
    "    # Generate & log bar chart\n",
    "    visualize_label_encoder(label_encoder)\n",
    "\n",
    "print(\"‚úÖ CMOA label encoding & visualization complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a5fde5-2c9a-46dc-998a-ca01c356e80e",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 6: Create Model** <a class=\"anchor\" id=\"PAPC_page_3\"></a>\n",
    "\n",
    "[Back to Top](#PAPC_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc4b4c49-a90c-4b4e-9235-6a2036f6cb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/26 16:23:13 INFO mlflow.tracking.fluent: Experiment with name 'CMOA_RF_Training' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded CMOA embeddings: ../Embeddings/cmoa_embeddings.csv (36 rows)\n",
      "‚úÖ Loaded label encoder from: ../Models/cmoa_label_encoder.pkl\n",
      "Train samples: 21, Test samples: 15\n",
      "‚è≥ Training started at 2025-05-26T15:23:13.535277+00:00\n",
      "‚úÖ Training finished at 2025-05-26T15:23:13.585221+00:00 (Duration: 0:00:00.049944)\n",
      "üîç Test accuracy: 1.0000\n",
      "üìä Saved classification report: cmoa_classification_report.csv\n",
      "üìä Saved confusion matrix CSV: cmoa_confusion_matrix.csv\n",
      "üñºÔ∏è Saved confusion matrix plot: cmoa_confusion_matrix.png\n",
      "üíæ Trained model saved to ../Models/cmoa_rf_model.pkl\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Arousal       1.00      1.00      1.00         8\n",
      "     Valence       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "          Arousal  Valence\n",
      "Arousal        8        0\n",
      "Valence        0        7\n",
      "üèÉ View run CMOA_RF_Training_Run at: http://127.0.0.1:5000/#/experiments/731945687604943104/runs/0086f8296c8e4705af583de2c10805dc\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/731945687604943104\n",
      "‚úÖ CMOA model training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from datetime import datetime, timezone\n",
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "if os.getenv(\"MLFLOW_TRACKING_URI\"):\n",
    "    mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"CMOA_RF_Training\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Load CMOA embeddings ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "embeddings_csv_path = '../Embeddings/cmoa_embeddings.csv'\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        embeddings_csv_path,\n",
    "        converters={'Embedding': lambda s: np.array(ast.literal_eval(s)) \n",
    "                                if isinstance(s, str) else np.array(s)}\n",
    "    )\n",
    "    print(f\"‚úÖ Loaded CMOA embeddings: {embeddings_csv_path} ({len(df)} rows)\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: CMOA embeddings not found at {embeddings_csv_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Load the pre-fitted CMOA label encoder ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "label_encoder_path = \"../Models/cmoa_label_encoder.pkl\"\n",
    "try:\n",
    "    label_encoder = joblib.load(label_encoder_path)\n",
    "    print(f\"‚úÖ Loaded label encoder from: {label_encoder_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: Label encoder not found at {label_encoder_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Prepare features & labels ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df['Embedding'].values)      # shape: (n_samples, dim)\n",
    "y = df['Factor'].values                    # CMOA factor names\n",
    "y_encoded = label_encoder.transform(y)     # numeric labels\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Train/test split ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "counts = pd.Series(y_encoded).value_counts()\n",
    "stratify_param = y_encoded if counts.min() >= 2 else None\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded,\n",
    "    test_size=0.4,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=stratify_param\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
    "if stratify_param is None:\n",
    "    print(\"‚ö†Ô∏è  Skipped stratification: some classes have only 1 sample.\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 5) MLflow run: train & evaluate ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"CMOA_RF_Training_Run\"):\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_type\", \"RandomForestClassifier\")\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"test_size\", 0.4)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_artifact(label_encoder_path, artifact_path=\"label_encoder\")\n",
    "\n",
    "    start_ts = datetime.now(timezone.utc)\n",
    "    mlflow.log_param(\"start_time\", start_ts.isoformat())\n",
    "    print(f\"‚è≥ Training started at {start_ts.isoformat()}\")\n",
    "\n",
    "    # Train classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    end_ts = datetime.now(timezone.utc)\n",
    "    mlflow.log_param(\"end_time\", end_ts.isoformat())\n",
    "    print(f\"‚úÖ Training finished at {end_ts.isoformat()} (Duration: {end_ts - start_ts})\")\n",
    "\n",
    "    # Predict & evaluate\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"test_accuracy\", acc)\n",
    "    print(f\"üîç Test accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Only labels present\n",
    "    present = np.unique(np.concatenate([y_test, y_pred]))\n",
    "    names = [label_encoder.classes_[i] for i in present]\n",
    "\n",
    "    # Classification report\n",
    "    report_dict = classification_report(\n",
    "        y_test, y_pred,\n",
    "        labels=present,\n",
    "        target_names=names,\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "    report_df = pd.DataFrame(report_dict).transpose()\n",
    "    report_path = \"cmoa_classification_report.csv\"\n",
    "    report_df.to_csv(report_path, index=True)\n",
    "    mlflow.log_artifact(report_path, artifact_path=\"metrics\")\n",
    "    print(f\"üìä Saved classification report: {report_path}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=present)\n",
    "    cm_df = pd.DataFrame(cm, index=names, columns=names)\n",
    "    cm_csv = \"cmoa_confusion_matrix.csv\"\n",
    "    cm_df.to_csv(cm_csv, index=True)\n",
    "    mlflow.log_artifact(cm_csv, artifact_path=\"metrics\")\n",
    "    print(f\"üìä Saved confusion matrix CSV: {cm_csv}\")\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"CMOA RandomForest Confusion Matrix\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.tight_layout()\n",
    "    cm_img = \"cmoa_confusion_matrix.png\"\n",
    "    plt.savefig(cm_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cm_img, artifact_path=\"metrics\")\n",
    "    print(f\"üñºÔ∏è Saved confusion matrix plot: {cm_img}\")\n",
    "\n",
    "    # Save trained model\n",
    "    os.makedirs(\"../Models\", exist_ok=True)\n",
    "    model_path = \"../Models/cmoa_rf_model.pkl\"\n",
    "    joblib.dump(clf, model_path)\n",
    "    mlflow.log_artifact(model_path, artifact_path=\"models\")\n",
    "    print(f\"üíæ Trained model saved to {model_path}\")\n",
    "\n",
    "    # Final summary\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(\n",
    "        y_test, y_pred, labels=present, target_names=names, zero_division=0\n",
    "    ))\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm_df)\n",
    "\n",
    "print(\"‚úÖ CMOA model training complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3656c2b1-5d3d-489d-9759-ed219e20d2b5",
   "metadata": {},
   "source": [
    "This block of code is a comprehensive step-by-step process focusing specifically on:\n",
    "1. **Data Loading and Preprocessing**: Parsing and preparing embeddings from a CSV file for machine learning.\n",
    "2. **Model Training**: Using a RandomForestClassifier to train on the embeddings.\n",
    "3. **Model Evaluation**: Calculating and logging metrics such as accuracy, alongside detailed classification reports and confusion matrices.\n",
    "4. **Visualization and Logging**: Visualizing the confusion matrix and logging both the visual represenPAPCion and numerical data as artifacts in MLflow.\n",
    "5. **Model Persistence**: Saving the trained model for future use or deployment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b586cb-65eb-4f24-9726-c7b61611182c",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 7: Evaluate Model** <a class=\"anchor\" id=\"PAPC_page_3\"></a>\n",
    "\n",
    "[Back to Top](#PAPC_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bbc78ca-7e53-4ab5-8c7c-c2d2848d4367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/26 16:24:03 INFO mlflow.tracking.fluent: Experiment with name 'CMOA_Model_Evaluation' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded embeddings from: ../Embeddings/cmoa_embeddings.csv\n",
      "‚úÖ Label encoder loaded from: ../Models/cmoa_label_encoder.pkl\n",
      "‚úÖ Model loaded from: ../Models/cmoa_rf_model.pkl\n",
      "Train size: 21, Test size: 15\n",
      "üîç Test accuracy: 1.0000\n",
      "üìä Saved classification report: cmoa_evaluation_classification_report.csv\n",
      "üìä Saved confusion matrix CSV: cmoa_evaluation_confusion_matrix.csv\n",
      "üñºÔ∏è Saved confusion matrix plot: cmoa_evaluation_confusion_matrix.png\n",
      "üèÉ View run CMOA_Evaluation at: http://127.0.0.1:5000/#/experiments/894601254720879506/runs/60d6c09949924180a5edf3b03e2f9232\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/894601254720879506\n",
      "‚úÖ CMOA model evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "if os.getenv(\"MLFLOW_TRACKING_URI\"):\n",
    "    mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"CMOA_Model_Evaluation\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Paths ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "EMBEDDINGS_CSV    = \"../Embeddings/cmoa_embeddings.csv\"\n",
    "LABEL_ENCODER_PKL = \"../Models/cmoa_label_encoder.pkl\"\n",
    "MODEL_PKL         = \"../Models/cmoa_rf_model.pkl\"\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Load embeddings with safe parsing ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        EMBEDDINGS_CSV,\n",
    "        converters={\n",
    "            \"Embedding\": lambda s: np.array(ast.literal_eval(s))\n",
    "                        if isinstance(s, str) else np.array(s)\n",
    "        }\n",
    "    )\n",
    "    print(f\"‚úÖ Loaded embeddings from: {EMBEDDINGS_CSV}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Error loading embeddings: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Load label encoder & model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    label_encoder = joblib.load(LABEL_ENCODER_PKL)\n",
    "    print(f\"‚úÖ Label encoder loaded from: {LABEL_ENCODER_PKL}\")\n",
    "    clf = joblib.load(MODEL_PKL)\n",
    "    print(f\"‚úÖ Model loaded from: {MODEL_PKL}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Artifact missing: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Prepare features & labels ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df[\"Embedding\"].values)\n",
    "y = df[\"Factor\"].values\n",
    "y_encoded = label_encoder.transform(y)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Train/test split (optional stratify) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "counts = pd.Series(y_encoded).value_counts()\n",
    "stratify_param = y_encoded if counts.min() >= 2 else None\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded,\n",
    "    test_size=0.4,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=stratify_param\n",
    ")\n",
    "print(f\"Train size: {len(y_train)}, Test size: {len(y_test)}\")\n",
    "if stratify_param is None:\n",
    "    print(\"‚ö†Ô∏è  Skipped stratification‚Äîat least one class has only one sample\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 5) Evaluate under MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"CMOA_Evaluation\"):\n",
    "    mlflow.log_param(\"step\", \"evaluate_model\")\n",
    "    mlflow.log_param(\"test_samples\", len(y_test))\n",
    "    mlflow.log_artifact(LABEL_ENCODER_PKL, artifact_path=\"label_encoder\")\n",
    "    mlflow.log_artifact(MODEL_PKL, artifact_path=\"model\")\n",
    "    mlflow.log_param(\"start_time\", datetime.now().isoformat())\n",
    "\n",
    "    # Predict\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Accuracy\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    print(f\"üîç Test accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Only keep labels actually seen\n",
    "    present = np.unique(np.concatenate([y_test, y_pred]))\n",
    "    names   = [label_encoder.classes_[i] for i in present]\n",
    "\n",
    "    # Classification report\n",
    "    report_dict = classification_report(\n",
    "        y_test, y_pred,\n",
    "        labels=present,\n",
    "        target_names=names,\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "    report_df = pd.DataFrame(report_dict).transpose()\n",
    "    report_csv = \"cmoa_evaluation_classification_report.csv\"\n",
    "    report_df.to_csv(report_csv, index=True)\n",
    "    mlflow.log_artifact(report_csv, artifact_path=\"evaluation\")\n",
    "    print(f\"üìä Saved classification report: {report_csv}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm    = confusion_matrix(y_test, y_pred, labels=present)\n",
    "    cm_df = pd.DataFrame(cm, index=names, columns=names)\n",
    "    cm_csv = \"cmoa_evaluation_confusion_matrix.csv\"\n",
    "    cm_df.to_csv(cm_csv, index=True)\n",
    "    mlflow.log_artifact(cm_csv, artifact_path=\"evaluation\")\n",
    "    print(f\"üìä Saved confusion matrix CSV: {cm_csv}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(\"CMOA RandomForest Confusion Matrix (Test Set)\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.tight_layout()\n",
    "    cm_img = \"cmoa_evaluation_confusion_matrix.png\"\n",
    "    plt.savefig(cm_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cm_img, artifact_path=\"evaluation\")\n",
    "    print(f\"üñºÔ∏è Saved confusion matrix plot: {cm_img}\")\n",
    "\n",
    "    mlflow.log_param(\"end_time\", datetime.now().isoformat())\n",
    "\n",
    "print(\"‚úÖ CMOA model evaluation complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af80057-6c04-4228-ae9b-ed84b87fa9a6",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 8: Test and Evaluate Model** <a class=\"anchor\" id=\"PAPC_page_3\"></a>\n",
    "\n",
    "[Back to Top](#PAPC_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe70d8f9-a9eb-4908-bbf9-db62ee23023b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded embeddings from: ../Embeddings/cmoa_embeddings.csv\n",
      "‚úÖ Label encoder loaded from: ../Models/cmoa_label_encoder.pkl\n",
      "‚úÖ Model loaded from: ../Models/cmoa_rf_model.pkl\n",
      "Train size: 21, Test size: 15\n",
      "üîç Test accuracy: 1.0000\n",
      "üìä Saved classification report: cmoa_evaluation_classification_report.csv\n",
      "üìä Saved confusion matrix CSV: cmoa_evaluation_confusion_matrix.csv\n",
      "üñºÔ∏è Saved confusion matrix plot: cmoa_evaluation_confusion_matrix.png\n",
      "üèÉ View run CMOA_Model_Evaluation at: http://127.0.0.1:5000/#/experiments/894601254720879506/runs/bfd55468b29f4a34b9086df59d0f072c\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/894601254720879506\n",
      "‚úÖ CMOA model evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "if os.getenv(\"MLFLOW_TRACKING_URI\"):\n",
    "    mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"CMOA_Model_Evaluation\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Paths ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "EMBEDDINGS_CSV    = \"../Embeddings/cmoa_embeddings.csv\"\n",
    "LABEL_ENCODER_PKL = \"../Models/cmoa_label_encoder.pkl\"\n",
    "MODEL_PKL         = \"../Models/cmoa_rf_model.pkl\"\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Load embeddings with safe parsing ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        EMBEDDINGS_CSV,\n",
    "        converters={\n",
    "            \"Embedding\": lambda s: np.array(ast.literal_eval(s))\n",
    "                       if isinstance(s, str) else np.array(s)\n",
    "        }\n",
    "    )\n",
    "    print(f\"‚úÖ Loaded embeddings from: {EMBEDDINGS_CSV}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Error loading embeddings: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Load label encoder & model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    label_encoder = joblib.load(LABEL_ENCODER_PKL)\n",
    "    print(f\"‚úÖ Label encoder loaded from: {LABEL_ENCODER_PKL}\")\n",
    "    clf = joblib.load(MODEL_PKL)\n",
    "    print(f\"‚úÖ Model loaded from: {MODEL_PKL}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Artifact missing: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Prepare features & labels ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df[\"Embedding\"].values)\n",
    "y = df[\"Factor\"].values\n",
    "y_encoded = label_encoder.transform(y)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Train/test split (optional stratify) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "counts = pd.Series(y_encoded).value_counts()\n",
    "stratify_param = y_encoded if counts.min() >= 2 else None\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded,\n",
    "    test_size=0.4,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=stratify_param\n",
    ")\n",
    "print(f\"Train size: {len(y_train)}, Test size: {len(y_test)}\")\n",
    "if stratify_param is None:\n",
    "    print(\"‚ö†Ô∏è  Skipped stratification‚Äîat least one class has only one sample\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 5) Evaluate under MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"CMOA_Model_Evaluation\"):\n",
    "    mlflow.log_param(\"step\", \"evaluate_model\")\n",
    "    mlflow.log_param(\"test_samples\", len(y_test))\n",
    "    mlflow.log_artifact(LABEL_ENCODER_PKL, artifact_path=\"label_encoder\")\n",
    "    mlflow.log_artifact(MODEL_PKL, artifact_path=\"model\")\n",
    "    mlflow.log_param(\"start_time\", datetime.now(timezone.utc).isoformat())\n",
    "\n",
    "    # Predict\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Accuracy\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    print(f\"üîç Test accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Only keep labels actually seen\n",
    "    present = np.unique(np.concatenate([y_test, y_pred]))\n",
    "    names   = [label_encoder.classes_[i] for i in present]\n",
    "\n",
    "    # Classification report\n",
    "    report_dict = classification_report(\n",
    "        y_test, y_pred,\n",
    "        labels=present,\n",
    "        target_names=names,\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "    report_df = pd.DataFrame(report_dict).transpose()\n",
    "    report_csv = \"cmoa_evaluation_classification_report.csv\"\n",
    "    report_df.to_csv(report_csv, index=True)\n",
    "    mlflow.log_artifact(report_csv, artifact_path=\"evaluation\")\n",
    "    print(f\"üìä Saved classification report: {report_csv}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm    = confusion_matrix(y_test, y_pred, labels=present)\n",
    "    cm_df = pd.DataFrame(cm, index=names, columns=names)\n",
    "    cm_csv = \"cmoa_evaluation_confusion_matrix.csv\"\n",
    "    cm_df.to_csv(cm_csv, index=True)\n",
    "    mlflow.log_artifact(cm_csv, artifact_path=\"evaluation\")\n",
    "    print(f\"üìä Saved confusion matrix CSV: {cm_csv}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(\"CMOA RandomForest Confusion Matrix (Test Set)\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.tight_layout()\n",
    "    cm_img = \"cmoa_evaluation_confusion_matrix.png\"\n",
    "    plt.savefig(cm_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cm_img, artifact_path=\"evaluation\")\n",
    "    print(f\"üñºÔ∏è Saved confusion matrix plot: {cm_img}\")\n",
    "\n",
    "    mlflow.log_param(\"end_time\", datetime.now(timezone.utc).isoformat())\n",
    "\n",
    "print(\"‚úÖ CMOA model evaluation complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dc0d50-5e9f-4b73-bb5f-f8e64b2c1f62",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 9: Visualize and Evaluate Model** <a class=\"anchor\" id=\"PAPC_page_3\"></a>\n",
    "\n",
    "[Back to Top](#PAPC_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02e69b18-6364-4067-98b8-4c144511dee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/26 16:25:51 INFO mlflow.tracking.fluent: Experiment with name 'CMOA_Visualization_and_Eval' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded embeddings from: ../Embeddings/cmoa_embeddings.csv\n",
      "‚è≥ Run started at 2025-05-26T15:25:52.121590+00:00\n",
      "üîç In-sample accuracy: 1.0000\n",
      "‚úÖ Clustered data saved: ../Embeddings/cmoa_clustered_embeddings.csv\n",
      "‚úÖ Run finished at 2025-05-26T15:25:55.456007+00:00 (Duration: 0:00:03.334417)\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Arousal       1.00      1.00      1.00        18\n",
      "     Valence       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "üèÉ View run CMOA_Visualization_and_Eval at: http://127.0.0.1:5000/#/experiments/197689396444727205/runs/3438736e7fbc471d9426bdaa0c9cdfff\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/197689396444727205\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timezone\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup MLflow & Environment ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "if os.getenv(\"MLFLOW_TRACKING_URI\"):\n",
    "    mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"CMOA_Visualization_and_Eval\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Paths ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "EMBEDDINGS_CSV = '../Embeddings/cmoa_embeddings.csv'\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Load embeddings with safe parsing ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        EMBEDDINGS_CSV,\n",
    "        converters={'Embedding': lambda s: np.array(ast.literal_eval(s)) if isinstance(s, str) else np.array(s)}\n",
    "    )\n",
    "    print(f\"‚úÖ Loaded embeddings from: {EMBEDDINGS_CSV}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå File not found: {EMBEDDINGS_CSV}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Prepare features and labels ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df['Embedding'].values)  # (n_samples, emb_dim)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(df['Factor'].values)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Start MLflow run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"CMOA_Visualization_and_Eval\"):\n",
    "    mlflow.log_param(\"step\", \"visualize_and_evaluate\")\n",
    "    mlflow.log_param(\"embeddings_csv\", EMBEDDINGS_CSV)\n",
    "    start_ts = datetime.now(timezone.utc)\n",
    "    mlflow.log_param(\"start_time\", start_ts.isoformat())\n",
    "    print(f\"‚è≥ Run started at {start_ts.isoformat()}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 4) Train a RandomForest on full data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X, y_encoded)\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 4a) Infer signature & prepare input example ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    preds = clf.predict(X)\n",
    "    signature = infer_signature(X, preds)\n",
    "    input_example = pd.DataFrame([X[0]], columns=[f\"emb_{i}\" for i in range(X.shape[1])])\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 4b) Log model with signature & example ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    mlflow.sklearn.log_model(\n",
    "        clf,\n",
    "        artifact_path=\"models/cmoa_rf_model\",\n",
    "        signature=signature,\n",
    "        input_example=input_example\n",
    "    )\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 5) In-sample evaluation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    in_acc = accuracy_score(y_encoded, preds)\n",
    "    mlflow.log_metric(\"in_sample_accuracy\", in_acc)\n",
    "    print(f\"üîç In-sample accuracy: {in_acc:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(y_encoded, preds)\n",
    "    cm_df = pd.DataFrame(cm, index=le.classes_, columns=le.classes_)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"CMOA In-Sample Confusion Matrix\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.tight_layout()\n",
    "    cm_img = \"cmoa_in_sample_confusion_matrix.png\"\n",
    "    plt.savefig(cm_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cm_img, artifact_path=\"evaluation\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 6) PCA visualization ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_encoded, cmap='viridis', alpha=0.7)\n",
    "    handles, _ = scatter.legend_elements()\n",
    "    plt.legend(handles, le.classes_, title=\"CMOA Factor\")\n",
    "    plt.title(\"PCA of CMOA Embeddings\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.tight_layout()\n",
    "    pca_img = \"cmoa_pca.png\"\n",
    "    plt.savefig(pca_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(pca_img, artifact_path=\"visualization\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 7) K-Means clustering ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    n_clusters = len(le.classes_)\n",
    "    mlflow.log_param(\"n_clusters\", n_clusters)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X)\n",
    "    df['Cluster'] = clusters\n",
    "\n",
    "    clustered_csv = '../Embeddings/cmoa_clustered_embeddings.csv'\n",
    "    os.makedirs(os.path.dirname(clustered_csv), exist_ok=True)\n",
    "    df.to_csv(clustered_csv, index=False)\n",
    "    mlflow.log_artifact(clustered_csv, artifact_path=\"clustered_data\")\n",
    "    print(f\"‚úÖ Clustered data saved: {clustered_csv}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='tab10', alpha=0.7)\n",
    "    plt.title(\"K-Means Clusters of CMOA Embeddings\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.tight_layout()\n",
    "    cluster_img = \"cmoa_clusters.png\"\n",
    "    plt.savefig(cluster_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cluster_img, artifact_path=\"visualization\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 8) Log end time ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    end_ts = datetime.now(timezone.utc)\n",
    "    mlflow.log_param(\"end_time\", end_ts.isoformat())\n",
    "    print(f\"‚úÖ Run finished at {end_ts.isoformat()} (Duration: {end_ts - start_ts})\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 9) Print final classification report ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    report = classification_report(y_encoded, preds, target_names=le.classes_, zero_division=0)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d6c46-cbed-44b1-acd1-f36a71195fca",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 10: Save Visualization and Evaluation of Model** <a class=\"anchor\" id=\"PAPC_page_3\"></a>\n",
    "\n",
    "[Back to Top](#PAPC_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b7e7cb8-ba04-4b99-b982-7dde60729478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/26 16:26:40 INFO mlflow.tracking.fluent: Experiment with name 'CMOA_PCA_and_Clustering' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded embeddings from: ../Embeddings/cmoa_embeddings.csv\n",
      "‚úÖ LabelEncoder loaded from: ../Models/cmoa_label_encoder.pkl\n",
      "‚úÖ RF model loaded from: ../Models/cmoa_rf_model.pkl\n",
      "‚è≥ Run started at 2025-05-26T15:26:40.237823+00:00\n",
      "‚úÖ PCA plot saved: cmoa_pca.png\n",
      "‚úÖ Clustered data saved: ../Embeddings/cmoa_clustered_embeddings.csv\n",
      "‚úÖ Cluster plot saved: cmoa_clusters.png\n",
      "‚úÖ Run finished at 2025-05-26T15:26:40.385946+00:00 (Duration: 0:00:00.148123)\n",
      "üèÉ View run CMOA_PCA_and_Clustering at: http://127.0.0.1:5000/#/experiments/214683443650091090/runs/bcc290bb42f94564a0a6f2f830a3a908\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/214683443650091090\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timezone\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import joblib\n",
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "if os.getenv(\"MLFLOW_TRACKING_URI\"):\n",
    "    mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"CMOA_PCA_and_Clustering\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Paths ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "EMBEDDINGS_CSV    = '../Embeddings/cmoa_embeddings.csv'\n",
    "LABEL_ENCODER_PKL = '../Models/cmoa_label_encoder.pkl'\n",
    "RF_MODEL_PKL      = '../Models/cmoa_rf_model.pkl'\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Load embeddings with safe parsing ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        EMBEDDINGS_CSV,\n",
    "        converters={'Embedding': lambda s: np.array(ast.literal_eval(s)) if isinstance(s, str) else np.array(s)}\n",
    "    )\n",
    "    print(f\"‚úÖ Loaded embeddings from: {EMBEDDINGS_CSV}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Embeddings CSV not found: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Load label‚Äêencoder & model (for traceability) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    label_encoder = joblib.load(LABEL_ENCODER_PKL)\n",
    "    print(f\"‚úÖ LabelEncoder loaded from: {LABEL_ENCODER_PKL}\")\n",
    "    rf_model = joblib.load(RF_MODEL_PKL)\n",
    "    print(f\"‚úÖ RF model loaded from: {RF_MODEL_PKL}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Artifact missing: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Prepare data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df['Embedding'].values)\n",
    "y = df['Factor'].values\n",
    "y_encoded = label_encoder.transform(y)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 5) Begin MLflow run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"CMOA_PCA_and_Clustering\"):\n",
    "    mlflow.log_param(\"step\", \"PCA_and_KMeans\")\n",
    "    mlflow.log_param(\"embeddings_csv\", EMBEDDINGS_CSV)\n",
    "    start_ts = datetime.now(timezone.utc)\n",
    "    mlflow.log_param(\"start_time\", start_ts.isoformat())\n",
    "    print(f\"‚è≥ Run started at {start_ts.isoformat()}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 6) PCA visualization ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_encoded, cmap='viridis', alpha=0.7)\n",
    "    handles, _ = scatter.legend_elements()\n",
    "    plt.legend(handles, label_encoder.classes_, title=\"CMOA Factor\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.title(\"PCA of CMOA Embeddings\")\n",
    "    plt.tight_layout()\n",
    "    pca_img = \"cmoa_pca.png\"\n",
    "    plt.savefig(pca_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(pca_img, artifact_path=\"visualization\")\n",
    "    print(f\"‚úÖ PCA plot saved: {pca_img}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 7) K-Means clustering ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    n_clusters = len(label_encoder.classes_)\n",
    "    mlflow.log_param(\"n_clusters\", n_clusters)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X)\n",
    "    df['Cluster'] = clusters\n",
    "\n",
    "    clustered_csv = '../Embeddings/cmoa_clustered_embeddings.csv'\n",
    "    os.makedirs(os.path.dirname(clustered_csv), exist_ok=True)\n",
    "    df.to_csv(clustered_csv, index=False)\n",
    "    mlflow.log_artifact(clustered_csv, artifact_path=\"clustered_data\")\n",
    "    print(f\"‚úÖ Clustered data saved: {clustered_csv}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='tab10', alpha=0.7)\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.title(\"K-Means Clusters of CMOA Embeddings\")\n",
    "    plt.tight_layout()\n",
    "    cluster_img = \"cmoa_clusters.png\"\n",
    "    plt.savefig(cluster_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cluster_img, artifact_path=\"visualization\")\n",
    "    print(f\"‚úÖ Cluster plot saved: {cluster_img}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 8) End run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    end_ts = datetime.now(timezone.utc)\n",
    "    mlflow.log_param(\"end_time\", end_ts.isoformat())\n",
    "    duration = end_ts - start_ts\n",
    "    print(f\"‚úÖ Run finished at {end_ts.isoformat()} (Duration: {duration})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013ba63c-ce13-4667-a5d9-a799ab883b97",
   "metadata": {},
   "source": [
    "This block of code integrates several stages that not only include training but also applying the model to new data and exploring the data through clustering:\n",
    "1. **Data Loading and Feature Parsing**: Similar to Block 1, with an additional step of displaying the parsed data.\n",
    "2. **Model Creation and Logging**: Training a RandomForestClassifier and logging the model directly with MLflow for possibly immediate deployment.\n",
    "3. **Model Evaluation and Reporting**: Assessing model performance with metrics and detailed reports, and logging these evaluations.\n",
    "4. **Clustering Analysis**: Utilizing KMeans to perform clustering on the embeddings, which adds an exploratory data analysis component.\n",
    "5. **Model Application on New Data**: Demonstrating a practical application of the trained model to predict factors for new text inputs.\n",
    "6. **End-to-End Experiment Tracking**: From the beginning of the run to its completion, tracking all parameters, artifacts, and outcomes, emphasizing a full-cycle view of the modeling process.\n",
    "\n",
    "This provides a broader overview of how a model can be developed and applied within a workflow that includes prediction and clustering alongside the fundamental steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f3cfce-24bd-4f6c-a748-54b1fe39d107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5916893-8b0f-450f-9ce6-09015901f5eb",
   "metadata": {},
   "source": [
    "The results show that the RandomForestClassifier model trained on the dataset of embeddings has achieved an accuracy of 1.0 on the test set, which means it has correctly classified all the test samples. Here is the breakdown of the evaluation:\n",
    "\n",
    "### Accuracy:\n",
    "- **1.0**: The model has 100% accuracy, meaning it correctly classified every instance in the test set.\n",
    "\n",
    "### Classification Report:\n",
    "- **Precision, Recall, and F1-score** for each class (0 through 4) are all 1.00.\n",
    "- **Support** indicates the number of actual occurrences of each class in the test set.\n",
    "\n",
    "### InterprePAPCion:\n",
    "- **Precision**: This is the ratio of true positive predictions to the total predicted positives. A precision of 1.0 means that all instances predicted as a specific class were actually of that class.\n",
    "- **Recall**: This is the ratio of true positive predictions to the total actual positives. A recall of 1.0 means that all actual instances of a specific class were correctly predicted.\n",
    "- **F1-score**: This is the harmonic mean of precision and recall. An F1-score of 1.0 indicates perfect precision and recall.\n",
    "- **Support**: This indicates the number of true instances for each label in the test set. \n",
    "\n",
    "### Considerations:\n",
    "1. **Model Overfitting**: The perfect score could indicate overfitting, especially if the test set is small or not represenPAPCive of unseen data.\n",
    "2. **Test Set Size**: The test set has only 24 samples, which is relatively small. It's important to ensure that the test set is large enough and represenPAPCive to get a reliable estimate of model performance.\n",
    "3. **Data Leakage**: Double-check that there's no data leakage, meaning that no information from the test set was used during training.\n",
    "4. **Cross-Validation**: To better assess the model's performance, consider using cross-validation to ensure the model performs well across different subsets of the data.\n",
    "\n",
    "### Next Steps:\n",
    "- **Cross-validation**: Implement cross-validation to get a more robust evaluation of model performance.\n",
    "- **Larger Test Set**: If possible, increase the size of the test set to ensure the performance metrics are reliable.\n",
    "- **Feature Analysis**: Examine feature importance scores from the RandomForestClassifier to understand which parts of the embeddings contribute most to the predictions.\n",
    "\n",
    "### Updated Code for Cross-Validation:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(clf, X, y_encoded, cv=5)  # 5-fold cross-validation\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean cross-validation score: {np.mean(cv_scores)}\")\n",
    "```\n",
    "\n",
    "We added this cross-validation step will help us verify that the model generalizes well and is not just performing well on a small or potentially non-represenPAPCive test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16fac8dd-46d3-4595-99f0-f15b83e244a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/26 16:27:35 INFO mlflow.tracking.fluent: Experiment with name 'CMOA_LOO_CV' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 36 CMOA embeddings from ../Embeddings/cmoa_embeddings.csv\n",
      "‚úÖ Loaded CMOA label encoder and RF model\n",
      "‚ñ∂ Class counts (code ‚Üí factor):\n",
      "  0 (Arousal): 18 samples\n",
      "  1 (Valence): 18 samples\n",
      "‚ñ∂ Running Leave-One-Out CV with 36 splits\n",
      "‚ñ∂ First 10 LOO accuracies: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]‚Ä¶\n",
      "‚ñ∂ Mean LOO accuracy: 1.0000\n",
      "‚ñ∂ Std  LOO accuracy:  0.0000\n",
      "üèÉ View run CMOA_LOO_CV at: http://127.0.0.1:5000/#/experiments/475417333485657022/runs/79c1f1bfd16d4536ad6f075d3da84eff\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/475417333485657022\n",
      "‚úÖ CMOA Leave-One-Out CV complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import mlflow\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Make sure your MLFLOW_TRACKING_URI is set in the environment\n",
    "mlflow.set_experiment(\"CMOA_LOO_CV\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Load embeddings ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "embeddings_csv = '../Embeddings/cmoa_embeddings.csv'\n",
    "df = pd.read_csv(\n",
    "    embeddings_csv,\n",
    "    converters={'Embedding': lambda s: np.array(ast.literal_eval(s)) if isinstance(s, str) else np.array(s)}\n",
    ")\n",
    "X = np.stack(df['Embedding'].values)\n",
    "print(f\"‚úÖ Loaded {X.shape[0]} CMOA embeddings from {embeddings_csv}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Load label encoder & model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "label_encoder = joblib.load('../Models/cmoa_label_encoder.pkl')\n",
    "clf           = joblib.load('../Models/cmoa_rf_model.pkl')\n",
    "print(\"‚úÖ Loaded CMOA label encoder and RF model\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Prepare labels ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "y = df['Factor'].values\n",
    "y_encoded = label_encoder.transform(y)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Inspect class distribution ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "dist = pd.Series(y_encoded).value_counts().sort_index()\n",
    "print(\"‚ñ∂ Class counts (code ‚Üí factor):\")\n",
    "for code, cnt in dist.items():\n",
    "    factor = label_encoder.inverse_transform([code])[0]\n",
    "    print(f\"  {code} ({factor}): {cnt} samples\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 5) Leave-One-Out CV ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "loo = LeaveOneOut()\n",
    "n_splits = loo.get_n_splits(X)\n",
    "print(f\"‚ñ∂ Running Leave-One-Out CV with {n_splits} splits\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 6) Run CV and log in MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"CMOA_LOO_CV\"):\n",
    "    mlflow.log_param(\"cv_method\", \"LeaveOneOut\")\n",
    "    mlflow.log_param(\"n_splits\", n_splits)\n",
    "\n",
    "    cv_scores = cross_val_score(\n",
    "        clf,\n",
    "        X,\n",
    "        y_encoded,\n",
    "        cv=loo,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 7) Summarize & print ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    mean_acc = cv_scores.mean()\n",
    "    std_acc  = cv_scores.std()\n",
    "    print(f\"‚ñ∂ First 10 LOO accuracies: {cv_scores[:10]}‚Ä¶\")\n",
    "    print(f\"‚ñ∂ Mean LOO accuracy: {mean_acc:.4f}\")\n",
    "    print(f\"‚ñ∂ Std  LOO accuracy:  {std_acc:.4f}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 8) Log metrics ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    mlflow.log_metric(\"loo_mean_accuracy\", mean_acc)\n",
    "    mlflow.log_metric(\"loo_std_accuracy\", std_acc)\n",
    "\n",
    "print(\"‚úÖ CMOA Leave-One-Out CV complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adf2f5ea-3181-4f0f-8a62-c95784cac78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 36 CMOA embeddings from ../Embeddings/cmoa_embeddings.csv\n",
      "CMOA factors (2): ['Arousal', 'Valence']\n",
      "Train/Test split: 21 train / 15 test samples\n",
      "‚úÖ Trained RandomForest on CMOA factors\n",
      "Test accuracy: 1.000\n",
      "‚úÖ Confusion matrix saved to cmoa_confusion_matrix.png\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Arousal       1.00      1.00      1.00         8\n",
      "     Valence       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "‚ñ∂ Using 5-fold StratifiedKFold CV\n",
      "\n",
      "CV accuracy scores: [1. 1. 1. 1. 1.]\n",
      "Mean CV accuracy: 1.000 ¬± 0.000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, LeaveOneOut, cross_val_score\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Load embeddings safely ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "embeddings_path = '../Embeddings/cmoa_embeddings.csv'\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        embeddings_path,\n",
    "        converters={'Embedding': lambda s: np.array(ast.literal_eval(s)) if isinstance(s, str) else np.array(s)}\n",
    "    )\n",
    "    print(f\"‚úÖ Loaded {len(df)} CMOA embeddings from {embeddings_path}\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"Embeddings file not found at {embeddings_path}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Prepare features & labels ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df['Embedding'].values)\n",
    "y = df['Factor'].values  # e.g., 'Valence' or 'Arousal' labels like 'Positive','High', etc.\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "print(f\"CMOA factors ({len(le.classes_)}): {list(le.classes_)}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Train/test split ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded,\n",
    "    test_size=0.4,\n",
    "    random_state=42,\n",
    "    stratify=y_encoded\n",
    ")\n",
    "print(f\"Train/Test split: {X_train.shape[0]} train / {X_test.shape[0]} test samples\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Train RandomForest ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"‚úÖ Trained RandomForest on CMOA factors\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 5) Evaluate on hold-out set ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test accuracy: {acc:.3f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=le.classes_, columns=le.classes_)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"CMOA Confusion Matrix (Test Set)\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.tight_layout()\n",
    "cm_file = \"cmoa_confusion_matrix.png\"\n",
    "plt.savefig(cm_file)\n",
    "plt.close()\n",
    "print(f\"‚úÖ Confusion matrix saved to {cm_file}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_test, y_pred,\n",
    "    target_names=le.classes_,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 6) Cross-Validation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "min_count = pd.Series(y_encoded).value_counts().min()\n",
    "if min_count < 5:\n",
    "    print(f\"‚ö†Ô∏è  Least-populated class has only {min_count} samples; using Leave-One-Out CV\")\n",
    "    cv = LeaveOneOut()\n",
    "else:\n",
    "    print(\"‚ñ∂ Using 5-fold StratifiedKFold CV\")\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(clf, X, y_encoded, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"\\nCV accuracy scores: {np.round(cv_scores, 3)}\")\n",
    "print(f\"Mean CV accuracy: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d8667c-30e8-4db0-8fca-03ccb53d773e",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 11: Test Model Directly** <a class=\"anchor\" id=\"PAPC_page_3\"></a>\n",
    "\n",
    "[Back to Top](#PAPC_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d8b6c39-c12d-4076-95e4-692d7a89371d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 36 rows from ../Embeddings/cmoa_embeddings.csv\n",
      "‚úÖ Loaded CMOA label encoder and RandomForest model.\n",
      "\n",
      "--- CMOA Model Predictions on New Examples ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joyful Celebration\n",
      "  Input: ‚ÄúI feel a surge of happiness and excitement when I get great news.‚Äù\n",
      "  ‚Üí Predicted CMOA Dimension: Arousal\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calm Serenity\n",
      "  Input: ‚ÄúI sit quietly by the lake, feeling peaceful and relaxed.‚Äù\n",
      "  ‚Üí Predicted CMOA Dimension: Valence\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angry Outburst\n",
      "  Input: ‚ÄúI raise my voice and frown when things don‚Äôt go my way.‚Äù\n",
      "  ‚Üí Predicted CMOA Dimension: Valence\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energized Workout\n",
      "  Input: ‚ÄúAfter my morning jog I'm full of energy and ready to tackle my day.‚Äù\n",
      "  ‚Üí Predicted CMOA Dimension: Arousal\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focused Attention\n",
      "  Input: ‚ÄúI concentrate deeply on the task, tuning out all distractions.‚Äù\n",
      "  ‚Üí Predicted CMOA Dimension: Arousal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from openai import OpenAI, OpenAIError\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Bootstrap OpenAI client ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "\n",
    "def _get_api_key_from_file(path=\"~/openai_api_key.txt\"):\n",
    "    p = os.path.expanduser(path)\n",
    "    try:\n",
    "        with open(p, \"r\") as f:\n",
    "            key = f.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"API key file not found at {p}\")\n",
    "    if not key:\n",
    "        raise ValueError(f\"No API key found in {p}\")\n",
    "    return key\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\") or _get_api_key_from_file()\n",
    "client  = OpenAI(api_key=api_key)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Load CMOA embeddings ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "EMB_PATH = '../Embeddings/cmoa_embeddings.csv'\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        EMB_PATH,\n",
    "        converters={'Embedding': lambda s: np.array(ast.literal_eval(s)) if isinstance(s, str) else np.array(s)}\n",
    "    )\n",
    "    print(f\"‚úÖ Loaded {len(df)} rows from {EMB_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load embeddings: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Load artifacts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "ENCODER_PATH = '../Models/cmoa_label_encoder.pkl'\n",
    "MODEL_PATH   = '../Models/cmoa_rf_model.pkl'\n",
    "try:\n",
    "    label_encoder = joblib.load(ENCODER_PATH)\n",
    "    clf           = joblib.load(MODEL_PATH)\n",
    "    print(\"‚úÖ Loaded CMOA label encoder and RandomForest model.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load artifacts: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Inference helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def get_embedding(text: str, model: str = \"text-embedding-3-small\") -> list:\n",
    "    try:\n",
    "        resp = client.embeddings.create(input=[text], model=model)\n",
    "        return resp.data[0].embedding\n",
    "    except OpenAIError as e:\n",
    "        raise RuntimeError(f\"OpenAI embedding error: {e}\")\n",
    "\n",
    "def predict_cmoa_dimension(text: str) -> str:\n",
    "    emb  = get_embedding(text)\n",
    "    code = clf.predict([emb])[0]\n",
    "    return label_encoder.inverse_transform([code])[0]\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 5) Test on representative CMOA examples ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "examples = {\n",
    "    \"Joyful Celebration\":     \"I feel a surge of happiness and excitement when I get great news.\",\n",
    "    \"Calm Serenity\":          \"I sit quietly by the lake, feeling peaceful and relaxed.\",\n",
    "    \"Angry Outburst\":         \"I raise my voice and frown when things don‚Äôt go my way.\",\n",
    "    \"Energized Workout\":      \"After my morning jog I'm full of energy and ready to tackle my day.\",\n",
    "    \"Focused Attention\":      \"I concentrate deeply on the task, tuning out all distractions.\"\n",
    "}\n",
    "\n",
    "print(\"\\n--- CMOA Model Predictions on New Examples ---\\n\")\n",
    "for desc, sample in examples.items():\n",
    "    try:\n",
    "        pred = predict_cmoa_dimension(sample)\n",
    "        print(f\"{desc}\\n  Input: ‚Äú{sample}‚Äù\\n  ‚Üí Predicted CMOA Dimension: {pred}\\n\")\n",
    "    except Exception as ex:\n",
    "        print(f\"‚ùå Error on '{desc}': {ex}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab54c21-ee36-4c0e-b9c4-445b11fa65ed",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 12: Test Neo4j Connection** <a class=\"anchor\" id=\"PAPC_page_4\"></a>\n",
    "\n",
    "\n",
    "[Back to Top](#PAPC_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce3fd307-5fcf-46d7-867d-78ecd5a83887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://localhost:7474/browser/\" target=\"_blank\">üîó Open Neo4j Bolt Connection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Define Neo4j Browser URL\n",
    "neo4j_browser_url = \"http://localhost:7474/browser/\"\n",
    "\n",
    "# Create a clickable link\n",
    "html_code = f'<a href=\"{neo4j_browser_url}\" target=\"_blank\">üîó Open Neo4j Bolt Connection</a>'\n",
    "\n",
    "# Display the clickable link in Jupyter Notebook\n",
    "display(HTML(html_code))\n",
    "\n",
    "# Open the Neo4j Browser in a new tab automatically\n",
    "webbrowser.open_new_tab(neo4j_browser_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a12796f0-11cb-40cb-8c48-e9e20760ed42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bolt port 7687 is reachable!\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "HOST = \"localhost\"\n",
    "PORT = 7687\n",
    "\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "result = sock.connect_ex((HOST, PORT))\n",
    "\n",
    "if result == 0:\n",
    "    print(f\"‚úÖ Bolt port {PORT} is reachable!\")\n",
    "else:\n",
    "    print(f\"‚ùå Bolt port {PORT} is NOT reachable!\")\n",
    "\n",
    "sock.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3abeb19a-7681-4c01-bb52-3b567513142a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Python Connection Failed: Unknown protocol 'neo4j'\n"
     ]
    }
   ],
   "source": [
    "from py2neo import Graph\n",
    "import mlflow\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ End any active MLflow run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Original URI (using neo4j://) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "raw_uri      = \"neo4j://localhost:7687\"\n",
    "NEO4J_USER   = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"mypassword\"\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Rewrite to bolt:// for py2neo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if raw_uri.startswith(\"neo4j://\"):\n",
    "    uri = \"bolt://\" + raw_uri[len(\"neo4j://\"):]\n",
    "else:\n",
    "    uri = raw_uri\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Attempt connection ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    graph = Graph(uri, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    # run a simple test query\n",
    "    message = graph.run(\"RETURN 'Connection successful!' AS message\").evaluate()\n",
    "    print(\"‚úÖ Python Connected Successfully:\", message)\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Python Connection Failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1142a99b-5cc2-4917-b423-5b8d52a45c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Connecting to Bolt URI: bolt://localhost:7687\n",
      "‚ùå Connection failed: Unknown protocol 'neo4j'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown protocol 'neo4j'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 4) Attempt connection\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[43mGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbolt_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpwd\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     greeting \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETURN \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124müéâ Bolt connection successful!\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m AS msg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ\u001b[39m\u001b[38;5;124m\"\u001b[39m, greeting)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/database.py:288\u001b[0m, in \u001b[0;36mGraph.__init__\u001b[0;34m(self, profile, name, **settings)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, profile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings):\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice \u001b[38;5;241m=\u001b[39m \u001b[43mGraphService\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m=\u001b[39m Schema(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/database.py:119\u001b[0m, in \u001b[0;36mGraphService.__init__\u001b[0;34m(self, profile, **settings)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connector_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m profile\u001b[38;5;241m.\u001b[39mrouting:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Ensures credentials are checked on construction\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     connector_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connector \u001b[38;5;241m=\u001b[39m \u001b[43mConnector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconnector_settings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graphs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/client/__init__.py:948\u001b[0m, in \u001b[0;36mConnector.__init__\u001b[0;34m(self, profile, user_agent, init_size, max_size, max_age, routing_refresh_ttl)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, profile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_agent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    946\u001b[0m              max_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_age\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, routing_refresh_ttl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile \u001b[38;5;241m=\u001b[39m ServiceProfile(profile)\n\u001b[0;32m--> 948\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_routers \u001b[38;5;241m=\u001b[39m [\u001b[43mConnectionProfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_agent \u001b[38;5;241m=\u001b[39m user_agent\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server_agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:176\u001b[0m, in \u001b[0;36mConnectionProfile.__init__\u001b[0;34m(self, profile, **settings)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__password \u001b[38;5;241m=\u001b[39m DEFAULT_PASSWORD\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__address \u001b[38;5;241m=\u001b[39m Address\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_env_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:220\u001b[0m, in \u001b[0;36mConnectionProfile._apply_env_vars\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply_env_vars\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m NEO4J_URI:\n\u001b[0;32m--> 220\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNEO4J_URI\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m NEO4J_AUTH:\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_settings(auth\u001b[38;5;241m=\u001b[39mNEO4J_AUTH)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:232\u001b[0m, in \u001b[0;36mConnectionProfile._apply_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    230\u001b[0m parsed \u001b[38;5;241m=\u001b[39m urlsplit(uri)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_scheme\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheme\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mnetloc:\n\u001b[1;32m    234\u001b[0m     settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m parsed\u001b[38;5;241m.\u001b[39mnetloc\u001b[38;5;241m.\u001b[39mpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:249\u001b[0m, in \u001b[0;36mConnectionProfile._apply_scheme\u001b[0;34m(self, scheme)\u001b[0m\n\u001b[1;32m    247\u001b[0m     protocol, _, ext \u001b[38;5;241m=\u001b[39m scheme\u001b[38;5;241m.\u001b[39mpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_settings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_settings(protocol\u001b[38;5;241m=\u001b[39mprotocol, secure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:266\u001b[0m, in \u001b[0;36mConnectionProfile._apply_settings\u001b[0;34m(self, uri, scheme, protocol, secure, verify, address, host, port, port_number, auth, user, password, **other)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_scheme(scheme)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol:\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_protocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m secure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__secure \u001b[38;5;241m=\u001b[39m secure\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:297\u001b[0m, in \u001b[0;36mConnectionProfile._apply_protocol\u001b[0;34m(self, protocol)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply_protocol\u001b[39m(\u001b[38;5;28mself\u001b[39m, protocol):\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbolt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown protocol \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m protocol)\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__protocol \u001b[38;5;241m=\u001b[39m protocol\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown protocol 'neo4j'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from py2neo import Graph\n",
    "import mlflow\n",
    "\n",
    "# 1) Tear down any active MLflow run\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "# 2) Load env\n",
    "load_dotenv(override=True)\n",
    "raw_uri = os.getenv(\"NEO4J_URI\", \"\")\n",
    "user    = os.getenv(\"NEO4J_USERNAME\")\n",
    "pwd     = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "if not raw_uri:\n",
    "    raise RuntimeError(\"‚ùå NEO4J_URI is not set in .env\")\n",
    "if not user or not pwd:\n",
    "    raise RuntimeError(\"‚ùå NEO4J_USERNAME or NEO4J_PASSWORD not set in .env\")\n",
    "\n",
    "# 3) Rewrite protocol\n",
    "if raw_uri.startswith(\"neo4j://\"):\n",
    "    bolt_uri = \"bolt://\" + raw_uri[len(\"neo4j://\"):]\n",
    "else:\n",
    "    bolt_uri = raw_uri\n",
    "\n",
    "print(f\"üîç Connecting to Bolt URI: {bolt_uri}\")\n",
    "\n",
    "# 4) Attempt connection\n",
    "try:\n",
    "    graph = Graph(bolt_uri, auth=(user, pwd))\n",
    "    greeting = graph.run(\"RETURN 'üéâ Bolt connection successful!' AS msg\").evaluate()\n",
    "    print(\"‚úÖ\", greeting)\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Connection failed:\", e)\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54f9b222-dd9d-4205-b4ab-3221085fbe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection failed: Unknown protocol 'neo4j'\n",
      "üèÉ View run Test Neo4j Connection at: http://127.0.0.1:5000/#/experiments/886681214121108750/runs/8f80dd79628a4cda85587faa4064eb8b\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/886681214121108750\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from py2neo import Graph\n",
    "import mlflow\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Load environment ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv()\n",
    "raw_uri       = os.getenv(\"NEO4J_URI\", \"\")\n",
    "NEO4J_USER    = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD= os.getenv(\"NEO4J_PASSWORD\")\n",
    "MLFLOW_URI    = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Fix URI for py2neo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if raw_uri.startswith(\"neo4j://\"):\n",
    "    bolt_uri = \"bolt://\" + raw_uri[len(\"neo4j://\"):]\n",
    "else:\n",
    "    bolt_uri = raw_uri\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Configure MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "mlflow.set_experiment(\"PAPC\")\n",
    "\n",
    "def test_neo4j_connection(uri, user, pwd):\n",
    "    graph = Graph(uri, auth=(user, pwd))\n",
    "    return graph.run(\"RETURN 'Connection successful!' AS greeting\").evaluate()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Run the connection test under MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"Test Neo4j Connection\"):\n",
    "    mlflow.log_param(\"Test\", \"Neo4j Connection\")\n",
    "    \n",
    "    try:\n",
    "        result = test_neo4j_connection(bolt_uri, NEO4J_USER, NEO4J_PASSWORD)\n",
    "    except Exception as e:\n",
    "        result = f\"Connection failed: {e}\"\n",
    "    \n",
    "    mlflow.log_param(\"Connection Result\", result)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0ce307e-9ad1-4891-9f4f-8966af9ce07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Test & Clear Neo4j at: http://127.0.0.1:5000/#/experiments/616263351584470447/runs/dba3a670164f4a5a916cafc8a2cc1914\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/616263351584470447\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown protocol 'neo4j'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# ‚îÄ‚îÄ‚îÄ Test & Clear Neo4j inside an MLflow run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run(run_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest & Clear Neo4j\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# 1) Test connection\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtest_neo4j_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNEO4J_URI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNEO4J_USER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNEO4J_PASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection Test\u001b[39m\u001b[38;5;124m\"\u001b[39m, result)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müîó Connection test result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 26\u001b[0m, in \u001b[0;36mtest_neo4j_connection\u001b[0;34m(uri, user, password)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtest_neo4j_connection\u001b[39m(uri, user, password):\n\u001b[0;32m---> 26\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[43mGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETURN \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConnection successful!\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m AS greeting\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/database.py:288\u001b[0m, in \u001b[0;36mGraph.__init__\u001b[0;34m(self, profile, name, **settings)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, profile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings):\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice \u001b[38;5;241m=\u001b[39m \u001b[43mGraphService\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m=\u001b[39m Schema(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/database.py:119\u001b[0m, in \u001b[0;36mGraphService.__init__\u001b[0;34m(self, profile, **settings)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connector_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m profile\u001b[38;5;241m.\u001b[39mrouting:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Ensures credentials are checked on construction\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     connector_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connector \u001b[38;5;241m=\u001b[39m \u001b[43mConnector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconnector_settings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graphs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/client/__init__.py:948\u001b[0m, in \u001b[0;36mConnector.__init__\u001b[0;34m(self, profile, user_agent, init_size, max_size, max_age, routing_refresh_ttl)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, profile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_agent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    946\u001b[0m              max_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_age\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, routing_refresh_ttl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile \u001b[38;5;241m=\u001b[39m ServiceProfile(profile)\n\u001b[0;32m--> 948\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_routers \u001b[38;5;241m=\u001b[39m [\u001b[43mConnectionProfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_agent \u001b[38;5;241m=\u001b[39m user_agent\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server_agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:176\u001b[0m, in \u001b[0;36mConnectionProfile.__init__\u001b[0;34m(self, profile, **settings)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__password \u001b[38;5;241m=\u001b[39m DEFAULT_PASSWORD\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__address \u001b[38;5;241m=\u001b[39m Address\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_env_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:220\u001b[0m, in \u001b[0;36mConnectionProfile._apply_env_vars\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply_env_vars\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m NEO4J_URI:\n\u001b[0;32m--> 220\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNEO4J_URI\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m NEO4J_AUTH:\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_settings(auth\u001b[38;5;241m=\u001b[39mNEO4J_AUTH)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:232\u001b[0m, in \u001b[0;36mConnectionProfile._apply_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    230\u001b[0m parsed \u001b[38;5;241m=\u001b[39m urlsplit(uri)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_scheme\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheme\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mnetloc:\n\u001b[1;32m    234\u001b[0m     settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m parsed\u001b[38;5;241m.\u001b[39mnetloc\u001b[38;5;241m.\u001b[39mpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:249\u001b[0m, in \u001b[0;36mConnectionProfile._apply_scheme\u001b[0;34m(self, scheme)\u001b[0m\n\u001b[1;32m    247\u001b[0m     protocol, _, ext \u001b[38;5;241m=\u001b[39m scheme\u001b[38;5;241m.\u001b[39mpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_settings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_settings(protocol\u001b[38;5;241m=\u001b[39mprotocol, secure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:266\u001b[0m, in \u001b[0;36mConnectionProfile._apply_settings\u001b[0;34m(self, uri, scheme, protocol, secure, verify, address, host, port, port_number, auth, user, password, **other)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_scheme(scheme)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol:\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_protocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m secure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__secure \u001b[38;5;241m=\u001b[39m secure\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:297\u001b[0m, in \u001b[0;36mConnectionProfile._apply_protocol\u001b[0;34m(self, protocol)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply_protocol\u001b[39m(\u001b[38;5;28mself\u001b[39m, protocol):\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbolt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown protocol \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m protocol)\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__protocol \u001b[38;5;241m=\u001b[39m protocol\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown protocol 'neo4j'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from py2neo import Graph\n",
    "import mlflow\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Load environment variables ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Neo4j connection settings ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "raw_uri    = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASS = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "# Normalize URI: use bolt:// if someone set neo4j://\n",
    "if raw_uri and raw_uri.startswith(\"neo4j://\"):\n",
    "    NEO4J_URI = raw_uri.replace(\"neo4j://\", \"bolt://\", 1)\n",
    "else:\n",
    "    NEO4J_URI = raw_uri\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ MLflow tracking setup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(\"MCMI\")\n",
    "\n",
    "def test_neo4j_connection(uri, user, password):\n",
    "    graph = Graph(uri, auth=(user, password))\n",
    "    return graph.run(\"RETURN 'Connection successful!' AS greeting\").evaluate()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Test & Clear Neo4j inside an MLflow run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"Test & Clear Neo4j\"):\n",
    "    # 1) Test connection\n",
    "    result = test_neo4j_connection(NEO4J_URI, NEO4J_USER, NEO4J_PASS)\n",
    "    mlflow.log_param(\"Connection Test\", result)\n",
    "    print(f\"üîó Connection test result: {result}\")\n",
    "\n",
    "    # 2) Clear the entire database\n",
    "    graph = Graph(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASS))\n",
    "    graph.delete_all()\n",
    "    mlflow.log_param(\"Database Cleared\", True)\n",
    "    print(\"üóëÔ∏è  All nodes and relationships have been deleted.\")\n",
    "\n",
    "    # 3) Confirm it's empty\n",
    "    remaining = graph.run(\"MATCH (n) RETURN count(n) AS nodes\").evaluate()\n",
    "    mlflow.log_param(\"Remaining Nodes\", remaining)\n",
    "    print(f\"üìä Remaining node count after clear: {remaining}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a2d41d-2f56-4b50-b4b1-77ebcd2c7279",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 13: Create CMOA Schema in Neo4j** <a class=\"anchor\" id=\"PAPC_page_4\"></a>\n",
    "\n",
    "\n",
    "[Back to Top](#PAPC_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957e5833-d44d-401d-8df7-0b430efac4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from py2neo import Graph\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Load environment & fix URI ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "raw_uri = os.getenv(\"NEO4J_URI\", \"\")\n",
    "bolt_uri = raw_uri.replace(\"neo4j://\", \"bolt://\") if raw_uri.startswith(\"neo4j://\") else raw_uri\n",
    "\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASS = os.getenv(\"NEO4J_PASSWORD\")\n",
    "if not all([bolt_uri, NEO4J_USER, NEO4J_PASS]):\n",
    "    raise RuntimeError(\"Please set NEO4J_URI, NEO4J_USERNAME & NEO4J_PASSWORD in your .env\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Connect & clear ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "graph = Graph(bolt_uri, auth=(NEO4J_USER, NEO4J_PASS))\n",
    "print(f\"üîó Connected to Neo4j via {bolt_uri}\")\n",
    "graph.delete_all()\n",
    "print(\"üóëÔ∏è  Cleared all existing nodes & relationships\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Load the CMOA flattened CSV ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "csv_path = os.path.join(\"..\", \"Datasets\", \"cmoa.csv\")\n",
    "cmoa_df = pd.read_csv(csv_path)\n",
    "print(f\"‚úÖ Loaded {len(cmoa_df)} rows from {csv_path}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Build the CMOA taxonomy graph ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "for _, row in cmoa_df.iterrows():\n",
    "    dimension = row['Factor']       # Valence or Arousal\n",
    "    adjective = row['Adjective']\n",
    "    synonym   = row['Synonym']\n",
    "    verb      = row['Verb']\n",
    "    noun      = row['Noun']\n",
    "\n",
    "    # Merge CMOA Dimension and Adjective nodes\n",
    "    graph.run(\"MERGE (d:CMOA_Dimension {name: $dimension})\", dimension=dimension)\n",
    "    graph.run(\"MERGE (a:CMOA_Adjective {name: $adjective})\", adjective=adjective)\n",
    "    graph.run(\n",
    "        \"\"\"\n",
    "        MATCH (d:CMOA_Dimension {name:$dimension}), (a:CMOA_Adjective {name:$adjective})\n",
    "        MERGE (d)-[:CMOA_HAS_ADJECTIVE]->(a)\n",
    "        \"\"\",\n",
    "        dimension=dimension, adjective=adjective\n",
    "    )\n",
    "\n",
    "    # Merge & link Synonym\n",
    "    if synonym:\n",
    "        graph.run(\"MERGE (s:CMOA_Synonym {name: $synonym})\", synonym=synonym)\n",
    "        graph.run(\n",
    "            \"\"\"\n",
    "            MATCH (a:CMOA_Adjective {name:$adjective}), (s:CMOA_Synonym {name:$synonym})\n",
    "            MERGE (a)-[:CMOA_HAS_SYNONYM]->(s)\n",
    "            \"\"\",\n",
    "            adjective=adjective, synonym=synonym\n",
    "        )\n",
    "\n",
    "    # Merge & link Verb\n",
    "    if verb:\n",
    "        graph.run(\"MERGE (v:CMOA_Verb {name: $verb})\", verb=verb)\n",
    "        graph.run(\n",
    "            \"\"\"\n",
    "            MATCH (a:CMOA_Adjective {name:$adjective}), (v:CMOA_Verb {name:$verb})\n",
    "            MERGE (a)-[:CMOA_HAS_VERB]->(v)\n",
    "            \"\"\",\n",
    "            adjective=adjective, verb=verb\n",
    "        )\n",
    "\n",
    "    # Merge & link Noun\n",
    "    if noun:\n",
    "        graph.run(\"MERGE (n:CMOA_Noun {name: $noun})\", noun=noun)\n",
    "        graph.run(\n",
    "            \"\"\"\n",
    "            MATCH (a:CMOA_Adjective {name:$adjective}), (n:CMOA_Noun {name:$noun})\n",
    "            MERGE (a)-[:CMOA_HAS_NOUN]->(n)\n",
    "            \"\"\",\n",
    "            adjective=adjective, noun=noun\n",
    "        )\n",
    "\n",
    "print(\"üéâ Completed building the CMOA taxonomy graph in Neo4j.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5da5e04-52b0-432d-9324-ba465af1865b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "746cc0fc-8e2f-4f59-b0e8-75b663e2802b",
   "metadata": {},
   "source": [
    "```cypher\n",
    "// 1) List all nodes with their labels and properties:\n",
    "MATCH (n)\n",
    "RETURN n\n",
    "ORDER BY labels(n), n.name;\n",
    "\n",
    "// 2) List all relationships between nodes:\n",
    "MATCH (a)-[r]->(b)\n",
    "RETURN a, r, b\n",
    "ORDER BY type(r);\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a55358-91a2-4b3f-8bc7-e22d822b975e",
   "metadata": {},
   "source": [
    "## Process for Building the PAPC Personality Model\n",
    "\n",
    "1. **Data Preparation**\n",
    "\n",
    "   * Define taxonomy (`Factor \\to Adjective \\to Synonym/Verb/Noun`).\n",
    "   * Normalize lists and flatten to CSV (`PAPC.csv`).\n",
    "\n",
    "2. **Embedding Generation**\n",
    "\n",
    "   * Load `PAPC.csv` into pandas.\n",
    "   * Initialize OpenAI client and MLflow.\n",
    "   * Generate embeddings via `client.embeddings.create(...)` for full text prompt.\n",
    "   * Save `PAPC_embeddings.csv` with `Embedding` column.\n",
    "\n",
    "3. **Label Encoding**\n",
    "\n",
    "   * Load embeddings CSV.\n",
    "   * Fit `LabelEncoder` on `Factor` column.\n",
    "   * Save encoder (`PAPC_label_encoder.pkl`).\n",
    "   * Visualize mapping with bar chart and log to MLflow.\n",
    "\n",
    "4. **Model Training**\n",
    "\n",
    "   * Load embeddings and label encoder.\n",
    "   * Split into train/test (stratify when possible).\n",
    "   * Train `RandomForestClassifier`.\n",
    "   * Log metrics, artifacts, and model to MLflow.\n",
    "\n",
    "5. **Model Evaluation**\n",
    "\n",
    "   * Reload model and encoder.\n",
    "   * Split and predict on test set.\n",
    "   * Compute accuracy, classification report, confusion matrix.\n",
    "   * Log evaluation artifacts to MLflow.\n",
    "   * Perform cross-validation (LOO if class imbalance).\n",
    "\n",
    "6. **Inference on New Data**\n",
    "\n",
    "   * Load model & encoder.\n",
    "   * Define `predict_factor(text)` helper that requests embedding and predicts.\n",
    "   * Test on meaningful example sentences.\n",
    "   * Log predictions to MLflow.\n",
    "\n",
    "7. **Visualization & Clustering**\n",
    "\n",
    "   * Train RF on full dataset.\n",
    "   * In‚Äësample evaluation & plot confusion matrix.\n",
    "   * PCA into 2D & scatter by encoded class.\n",
    "   * K‚ÄëMeans clustering on embeddings, save `PAPC_clustered_embeddings.csv`.\n",
    "   * Plot clusters in PCA space.\n",
    "\n",
    "8. **Neo4j Graph Construction**\n",
    "\n",
    "   * Clear existing graph: `MATCH (n) DETACH DELETE n`.\n",
    "   * Ingest `PAPC.csv`, create nodes for Factor, Adjective, Synonym, Verb, Noun.\n",
    "   * Create `:RELATES_TO` relationships following taxonomy hierarchy.\n",
    "\n",
    "9. **Cypher Query to View Graph**\n",
    "\n",
    "   ```cypher\n",
    "   MATCH p = (f:Factor)-[:HAS_ADJECTIVE]->(a:Adjective)\n",
    "             -[:HAS_SYNONYM|HAS_VERB|HAS_NOUN]->(x)\n",
    "   RETURN p LIMIT 100\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## BibTeX Entries (`references.bib`)\n",
    "\n",
    "```bipapcex\n",
    "@article{Holland1959,\n",
    "  author    = {Holland, John L.},\n",
    "  title     = {A Theory of Vocational Choice},\n",
    "  journal   = {Journal of Counseling Psychology},\n",
    "  year      = {1959},\n",
    "  volume    = {6},\n",
    "  number    = {1},\n",
    "  pages     = {35--47},\n",
    "  doi       = {10.1037/h0040767},\n",
    "}\n",
    "\n",
    "@book{Holland1973,\n",
    "  author    = {Holland, John L.},\n",
    "  title     = {Making Vocational Choices: A Theory of Careers},\n",
    "  publisher = {Prentice-Hall},\n",
    "  year      = {1973},\n",
    "}\n",
    "\n",
    "@article{GatiMeir1982,\n",
    "  author    = {Gati, Itamar and Meir, Eliyahu I.},\n",
    "  title     = {Congruence and Consistency Derived from the Circular and the Hierarchical Models as Predictors of Occupational Choice Satisfaction},\n",
    "  journal   = {Journal of Vocational Behavior},\n",
    "  year      = {1982},\n",
    "  volume    = {20},\n",
    "  pages     = {354--365},\n",
    "  doi       = {10.1016/0001-8791(82)90022-7},\n",
    "}\n",
    "\n",
    "@article{OsipowAshbyWall1966,\n",
    "  author    = {Osipow, Samuel H. and Ashby, John and Wall, Harry},\n",
    "  title     = {Personality Types and Vocational Choice: A Test of Holland's Theory},\n",
    "  journal   = {The Personnel and Guidance Journal},\n",
    "  year      = {1966},\n",
    "  volume    = {45},\n",
    "  number    = {1},\n",
    "  pages     = {37--42},\n",
    "  doi       = {10.1002/j.2164-4918.1966.tb03063.x},\n",
    "}\n",
    "\n",
    "@article{Nauta2010,\n",
    "  author    = {Nauta, Margaret M.},\n",
    "  title     = {The Development, Evolution, and Status of Holland's Theory of Vocational Personalities: Reflections and Future Directions for Counseling Psychology},\n",
    "  journal   = {Journal of Counseling Psychology},\n",
    "  year      = {2010},\n",
    "  volume    = {57},\n",
    "  number    = {1},\n",
    "  pages     = {11--22},\n",
    "  doi       = {10.1037/a0018213},\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9073f9-01c9-4778-b64e-8ce2fd50a6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (personality-models-env)",
   "language": "python",
   "name": "personality-models-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
