{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a6587bd-4dd4-4796-946b-6eaf8853f659",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "## Wechsler Adult Intelligence Scale (WAIS)<a class=\"anchor\" id=\"PTMD_page_20.8\"></a>\n",
    "\n",
    "[Back to Top](#PTMD_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286e8c9f-fc3b-4e56-a72a-04bea5b5d432",
   "metadata": {},
   "source": [
    "The **Wechsler Adult Intelligence Scale (WAIS)** is a standardized assessment that measures the intelligence of adults and older adolescents. Developed by David Wechsler, it is one of the most commonly used tests to evaluate cognitive abilities and generate an intelligence quotient (IQ) score. Over time, the WAIS has undergone several revisions to remain current and reflect new understanding of cognitive abilities.\n",
    "\n",
    "### WAIS Milestones Timeline\n",
    "\n",
    "| Year | Milestone                                          | Contributor(s)    | Original Work Reference                                          | Key Contributions                                                                                  |\n",
    "|------|----------------------------------------------------|-------------------|------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|\n",
    "| 1955 | Introduction of the first Wechsler Adult Intelligence Scale | David Wechsler    | Wechsler, D. (1955). \"Wechsler Adult Intelligence Scale.\"        | Provided a comprehensive measure of adult intelligence based on both verbal and performance scores. |\n",
    "| 1981 | Development of WAIS-R (Revised Edition)            | David Wechsler    | Wechsler, D. (1981). \"WAIS-R Manual.\"                            | Updated the test to improve reliability and cultural relevance.                                    |\n",
    "| 1997 | WAIS-III                                           | David Wechsler    | Wechsler, D. (1997). \"WAIS-III Manual.\"                          | Introduced the Working Memory Index and Processing Speed Index as new components.                  |\n",
    "| 2008 | WAIS-IV                                            | David Wechsler    | Wechsler, D. (2008). \"WAIS-IV Manual.\"                           | Added the General Ability Index (GAI) to provide an alternative score excluding working memory and processing speed. |\n",
    "| 2020 | WAIS-V Development and Refinement                  | Various scholars  | Academic research and publications                               | Updated the structure and norms to reflect recent psychometric findings.                           |\n",
    "\n",
    "### WAIS Dataset Structure\n",
    "\n",
    "The WAIS dataset can be structured according to its indices and subtests. Each index represents a primary cognitive ability, with subtests that provide detailed scores:\n",
    "\n",
    "- **Verbal Comprehension Index (VCI)**: Assesses verbal reasoning, comprehension, and expression.\n",
    "  - Subtests: Similarities, Vocabulary, Information, Comprehension.\n",
    "  \n",
    "- **Perceptual Reasoning Index (PRI)**: Evaluates visual-spatial reasoning, problem-solving, and perceptual organization.\n",
    "  - Subtests: Block Design, Matrix Reasoning, Visual Puzzles, Figure Weights.\n",
    "  \n",
    "- **Working Memory Index (WMI)**: Measures short-term memory and attention.\n",
    "  - Subtests: Digit Span, Arithmetic, Letter-Number Sequencing.\n",
    "  \n",
    "- **Processing Speed Index (PSI)**: Assesses cognitive processing speed and efficiency.\n",
    "  - Subtests: Symbol Search, Coding, Cancellation.\n",
    "\n",
    "- **Scoring Information**: Interpretation guidelines include index scores, subtest scores, and optional composite scores like the Full-Scale IQ and General Ability Index.\n",
    "\n",
    "### WAIS Reference Table:\n",
    "\n",
    "| **#** | **Author(s)**                                  | **Year** | **Title**                                                                                  | **Journal/Source**                  | **Volume** | **Pages**    | **DOI/URL**                                       |\n",
    "|-------|-----------------------------------------------|----------|----------------------------------------------------------------------------------------------|--------------------------------------|------------|--------------|--------------------------------------------------|\n",
    "| 1     | D. Wechsler                                   | 2021     | Wechsler Adult Intelligence Scale                                                          | Encyclopedia of Evolutionary Psychological Science | - | - | [DOI](https://doi.org/10.4135/9781412952644.n478) |\n",
    "| 2     | J. Nigg, E. Willcutt, A. Doyle, E. Sonuga-Barke | 2005 | Causal Heterogeneity in Attention-Deficit/Hyperactivity Disorder: Do We Need Neuropsychologically Impaired Subtypes? | Biological Psychiatry | 57 | 1224-1230 | [DOI](https://doi.org/10.1016/j.biopsych.2004.08.025) |\n",
    "| 3     | E. Kaplan, H. Goodglass, S. Weintraub, O. Segal | 2001 | Boston Naming Test | - | - | - | [DOI](https://doi.org/10.1007/springerreference_183640) |\n",
    "| 4     | J. Ryan, S. Lopez                             | 2001     | Wechsler Adult Intelligence Scale-III                                                      | -                                    | -          | -            | [DOI](https://doi.org/10.1007/978-1-4615-1185-4_2) |\n",
    "| 5     | S. Freeman                                   | 2021     | Wechsler Preschool and Primary Scale of Intelligence                                       | Encyclopedia of Autism Spectrum Disorders | - | - | [DOI](https://doi.org/10.1007/springerreference_184297) |\n",
    "| 6     | S. Warschausky, S. E. Raiford                 | 2018     | Wechsler Preschool and Primary Scale of Intelligence                                       | -                                    | -          | -            | [DOI](https://doi.org/10.1007/978-3-319-57111-9_1606) |\n",
    "| 7     | R. Reitan                                    | 1958     | Validity of the Trail Making Test as an Indicator of Organic Brain Damage                   | Perceptual and Motor Skills          | 8          | 271-276      | [DOI](https://doi.org/10.2466/pms.1958.8.3.271)   |\n",
    "| 8     | A. Kertesz                                   | 1982     | The Western Aphasia Battery                                                               | -                                    | -          | -            | [DOI](https://doi.org/10.1007/springerreference_183701) |\n",
    "| 9     | R. Dumont, J. O. Willis, K. D. Viezel, J. Zibulsky | 2014  | California Verbal Learning Test, Second Edition | - | - | - | [DOI](https://doi.org/10.1002/9781118660584.ESE0399) |\n",
    "| 10    | D. Delis, J. Kramer, E. Kaplan, B. Ober       | 2016     | California Verbal Learning Test--Second Edition                                           | -                                    | -          | -            | [DOI](https://doi.org/10.1037/T15072-000)         |\n",
    "| 11    | L. Cohen                                     | 1993     | Wechsler Individual Achievement Test                                                      | -                                    | -          | -            | [DOI](https://doi.org/10.4135/9781412952644.n479) |\n",
    "| 12    | -                                            | 2020     | Behavior Rating Inventory of Executive Function                                           | Definitions                          | -          | -            | [DOI](https://doi.org/10.32388/ygkcwf)             |\n",
    "| 13    | R. Dumont, J. O. Willis                       | 2008     | Behavior Rating Inventory of Executive Function                                           | -                                    | -          | -            | [DOI](https://doi.org/10.1002/9780470373699.SPECED0263) |\n",
    "| 14    | D. Wechsler                                  | 2018     | Wechsler Preschool and Primary Scale of Intelligence--Revised                             | -                                    | -          | -            | [DOI](https://doi.org/10.1037/T48859-000)         |\n",
    "| 15    | M. Schlossberg                              | 1986     | The Halstead-Reitan Neuropsychological Test Battery: Theory and Clinical Interpretation   | Psyccritiques                        | -          | -            | -                                                |\n",
    "| 16    | C. Reynolds, J. Powel                        | 1988     | Wechsler Memory Scale-Revised                                                             | Archives of Clinical Neuropsychology | 3          | 397-403      | [DOI](https://doi.org/10.1093/ARCLIN/3.4.397)    |\n",
    "| 17    | R. Dumont, J. O. Willis, K. Veizel, J. Zibulsky | 2014 | Wechsler Intelligence Scale for Children‚ÄìFourth Edition | - | - | - | [DOI](https://doi.org/10.1002/9781118660584.ESE2522) |\n",
    "| 18    | Hyewon Park, Ïù¥Ï†ïÎØ∏                         | 2002     | The Performance of Autistic Children on the Korean Wechsler Preschool and Primary Scale of Intelligence | - | - | - | [URL](https://www.semanticscholar.org/paper/24edb84d86181b82e6da8596a7a48d4ddbffb968) |\n",
    "| 19    | W. F. Vonderhaar                             | 1977     | A Comparative Study of Performance Scale IQ's and Subtest Scores of Deaf Children on the Wechsler Intelligence Scale for Children and the Wechsler Intelligence Scale for Children-Revised | - | - | - | [URL](https://www.semanticscholar.org/paper/c2ac3a23e8d158f5d6cb7164e1e74d140c8c4ae9) |\n",
    "| 20    | M. A. Tipton                                | 2014     | Wechsler Adult Intelligence Scale (4th Edition) and the Validity of Supplementary/Core Subtest Substitution | - | - | - | [URL](https://www.semanticscholar.org/paper/bc4e1a7a85a311a27bf9b4acceaf76c65c0b4284) |\n",
    "| 21    | E. Willcutt, A. Doyle, J. Nigg, S. Faraone, B. Pennington | 2005 | Validity of the Executive Function Theory of Attention-Deficit/Hyperactivity Disorder: A Meta-Analytic Review | Biological Psychiatry | 57 | 1336-1346 | [DOI](https://doi.org/10.1016/j.biopsych.2005.02.006) |\n",
    "| 22    | F. Petermann, D. Wechsler                    | 2012     | Wechsler Adult Intelligence Scale - fourth edition                                      | - | - | - | [DOI](https://doi.org/10.1037/T15169-000) |\n",
    "| 23    | L. G. Weiss, V. Locke, T. Pan, J. G. Harris, D. Saklofske, A. Prifitera | 2019 | Wechsler Intelligence Scale for Children‚ÄîFifth Edition | WISC-V | - | - | [DOI](https://doi.org/10.1016/B978-0-12-815744-2.00005-7) |\n",
    "| 24    | D. Wechsler                                 | 2020     | Wechsler Intelligence Scale for Children                                                 | Definitions                          | -          | -            | [DOI](https://doi.org/10.4135/9781483392271.n537) |\n",
    "| 25    | D. Wechsler                                 | 2012     | Wechsler Preschool and Primary Scale of Intelligence‚ÄîFourth Edition                       | -                                    | -          | -            | [DOI](https://doi.org/10.1037/spq0000038.supp) |\n",
    "| 26    | J. Lani, D. Wechsler                        | 2010     | Wechsler Adult Intelligence Scale‚ÄîFourth Edition (WAIS-IV)                               | -                                    | -          | -            | [URL](https://www.semanticscholar.org/paper/fa9b338ad64286f43a4f3f6da5420ffdbd2ba752) |\n",
    "| 27    | D. Delis, J. Kramer, E. Kaplan, B. Ober     | 2016     | The California Verbal Learning Test                                                      | -                                    | -          | -            | [DOI](https://doi.org/10.1037/T48844-000)         |\n",
    "| 28    | P. Yang, C. Cheng, C. Chang, T. Liu, H. Hsu, C. Yen | 2013 | Wechsler Intelligence Scale for Children 4th edition‚ÄêChinese  version index scores in Taiwanese children with attention‚Äêdeficit/hyperactivity disorder | Psychiatry and Clinical Neurosciences | 67 | - | [DOI](https://doi.org/10.1111/pcn.12014) |\n",
    "| 29    | R. Dumont, J. O. Willis                     | 2008     | Delis‚ÄêKaplan Executive Function System                                                   | -                                    | -          | -            | [DOI](https://doi.org/10.1002/9780470373699.SPECED0613) |\n",
    "| 30    | D. R. Smith                                | 2001     | Chapter 6 ‚Äì Wechsler Individual Achievement Test                                         | -                                    | -          | -            | [DOI](https://doi.org/10.1016/B978-012058570-0/50008-2) |\n",
    "| 31    | R. Hogan, J. Hogan, P. Barrett                | 2008     | Good Judgment: The Intersection of Intelligence and Personality                            | -                                    | -          | -            | [DOI](https://doi.org/10.1201/9781420067019-28) |\n",
    "| 32    | R. Barkley                                   | 1997     | Behavioral Inhibition, Sustained Attention, and Executive Functions: Constructing a Unifying Theory of ADHD | Psychological Bulletin | 121 | 65-94 | [DOI](https://doi.org/10.1037/0033-2909.121.1.65) |\n",
    "| 33    | J. M. Hunt                                   | 1975     | Psychological Development and The Educational Enterprise                                  | Educational Theory                   | 25         | 333-353      | [DOI](https://doi.org/10.1111/J.1741-5446.1975.TB00697.X) |\n",
    "| 34    | B. Choi, C. Kim                              | 2006     | A Learning Attitude Evaluation System for Learning Concentration on Distance Education   | -                                    | -          | -            | [DOI](https://doi.org/10.1007/11751632_87)      |\n",
    "| 35    | J. Lautrey                                  | 2004     | Introduction: Hauts potentiels et talents: La position actuelle du probl√®me              | Psychologie Francaise                | 49         | 219-232      | [DOI](https://doi.org/10.1016/J.PSFR.2004.03.001) |\n",
    "| 36    | E. Lichtenberger, A. Kaufman                 | 2000     | Essentials of WISC-IV Assessment                                                          | -                                    | -          | -            | [URL](https://www.semanticscholar.org/paper/9abebfa4ecd1263e93f21accea1dd5d018cea34a) |\n",
    "| 37    | P. Hagmann-von Arx, A. Grob, F. Petermann, M. Daseking | 2012 | [Concurrent Validity of the HAWIK-IV and the Intelligence and Development Scales (IDS)]  | Zeitschrift fur Kinder- und Jugendpsychiatrie und Psychotherapie | 40 | 41-50 | [DOI](https://doi.org/10.1024/1422-4917/a000148) |\n",
    "| 38    | D. Bacza≈Ça                                  | 2016     | Social Skills of Individuals with Intellectual Disabilities                              | -                                    | -          | -            | [URL](https://www.semanticscholar.org/paper/4898c8d0a7530ae57acd2d82c535d7ab3d0421e5) |\n",
    "| 39    | B. Pennington, S. Ozonoff                    | 1996     | Executive Functions and Developmental Psychopathology                                   | Journal of Child Psychology and Psychiatry, and Allied Disciplines | 37 | 51-87 | [DOI](https://doi.org/10.1111/J.1469-7610.1996.TB01380.X) |\n",
    "| 40    | G. Gittler, M. Arendasy                      | 2005     | Menschliche Intelligenz ‚Äî die Sichtweise der Psychologie                                | e & i Elektrotechnik und Informationstechnik | 122 | 227-231 | [DOI](https://doi.org/10.1007/BF03054433) |\n",
    "| 41    | R. Sternberg, E. Grigorenko, M. Ferrari, P. R. Clinkenbeard | 1999 | A Triarchic Analysis of an Aptitude-Treatment Interaction | European Journal of Psychological Assessment | 15 | 3-13 | [DOI](https://doi.org/10.1027//1015-5759.15.1.3) |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "index, subtest, description, synonym, verb, noun\n",
    "\n",
    "### Taxonomy\n",
    "```\n",
    "- Index\n",
    "    |__ Subtest\n",
    "        |__ Description\n",
    "            |__ Synonym\n",
    "            |__ Verb\n",
    "            |__ Noun\n",
    "```\n",
    "\n",
    "\n",
    "### New Taxonomy\n",
    "```\n",
    "- Index\n",
    "    |__ Subtest = Factor\n",
    "        |__ Description = Adjective\n",
    "            |__ Synonym\n",
    "            |__ Verb\n",
    "            |__ Noun\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2fbca8-e4c8-41d1-ae14-775df4dd1c07",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 1: Create Dataset** <a class=\"anchor\" id=\"OCEAN_page_1\"></a>\n",
    "\n",
    "Data Preparation and Cleaning: Ensure the dataset is cleaned and preprocessed properly. Handle missing values, duplicates, and outliers.\n",
    "\n",
    "[Back to Top](#OCEAN_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8febbf4-62df-4e4f-a88e-897e5bcfc3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/opt/python@3.13/bin/python3.13\n",
      "MLflow version: 2.22.0\n"
     ]
    }
   ],
   "source": [
    "import sys, mlflow\n",
    "print(sys.executable)\n",
    "print(\"MLflow version:\", mlflow.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fcaf510d-c9a5-4ecc-bfcb-3fe6b6d7e7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (60, 7)\n",
      "                              Index       Subtest  \\\n",
      "0  Verbal Comprehension Index (VCI)  Similarities   \n",
      "1  Verbal Comprehension Index (VCI)  Similarities   \n",
      "2  Verbal Comprehension Index (VCI)  Similarities   \n",
      "3  Verbal Comprehension Index (VCI)  Similarities   \n",
      "4  Verbal Comprehension Index (VCI)    Vocabulary   \n",
      "\n",
      "                                         Description      Synonym      Verb  \\\n",
      "0  Assesses abstract verbal reasoning by identify...   Comparison   Compare   \n",
      "1  Assesses abstract verbal reasoning by identify...     Matching     Match   \n",
      "2  Assesses abstract verbal reasoning by identify...      Pairing      Pair   \n",
      "3  Assesses abstract verbal reasoning by identify...  Resemblance  Resemble   \n",
      "4  Measures word knowledge and verbal concept for...      Lexicon    Define   \n",
      "\n",
      "         Noun Embedding  \n",
      "0  Similarity      None  \n",
      "1  Comparison      None  \n",
      "2       Match      None  \n",
      "3        Pair      None  \n",
      "4  Vocabulary      None  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Wechsler Adult Intelligence Scale dataset structure\n",
    "wais_dataset = {\n",
    "    'Verbal Comprehension Index (VCI)': {\n",
    "        'Similarities': {\n",
    "            'Description': 'Assesses abstract verbal reasoning by identifying similarities between paired concepts.',\n",
    "            'Synonyms':   ['Comparison', 'Matching', 'Pairing', 'Resemblance'],\n",
    "            'Verbs':      ['Compare',    'Match',    'Pair',    'Resemble'],\n",
    "            'Nouns':      ['Similarity', 'Comparison','Match', 'Pair']\n",
    "        },\n",
    "        'Vocabulary': {\n",
    "            'Description': 'Measures word knowledge and verbal concept formation.',\n",
    "            'Synonyms':   ['Lexicon', 'Word list', 'Terminology', 'Vocabulary'],\n",
    "            'Verbs':      ['Define',   'Understand', 'Explain',   'Interpret'],\n",
    "            'Nouns':      ['Vocabulary','Definition','Word',      'Concept']\n",
    "        },\n",
    "        'Information': {\n",
    "            'Description': 'Evaluates general knowledge and the ability to acquire factual information.',\n",
    "            'Synonyms':   ['Knowledge', 'Awareness',  'Education', 'Facts'],\n",
    "            'Verbs':      ['Know',      'Learn',      'Acquire',   'Understand'],\n",
    "            'Nouns':      ['Information','Fact',     'Knowledge', 'Education']\n",
    "        },\n",
    "        'Comprehension': {\n",
    "            'Description': 'Measures practical judgment and common sense by answering everyday questions.',\n",
    "            'Synonyms':   ['Understanding','Awareness','Perception','Grasp'],\n",
    "            'Verbs':      ['Understand',   'Perceive', 'Grasp',     'Comprehend'],\n",
    "            'Nouns':      ['Comprehension','Understanding','Awareness','Perception']\n",
    "        }\n",
    "    },\n",
    "    'Perceptual Reasoning Index (PRI)': {\n",
    "        'Block Design': {\n",
    "            'Description': 'Assesses visual‚Äëspatial reasoning by replicating patterns using blocks.',\n",
    "            'Synonyms':   ['Pattern',   'Design',      'Replication','Structure'],\n",
    "            'Verbs':      ['Replicate', 'Construct',   'Arrange',    'Build'],\n",
    "            'Nouns':      ['Block',     'Pattern',     'Design',     'Structure']\n",
    "        },\n",
    "        'Matrix Reasoning': {\n",
    "            'Description': 'Evaluates non‚Äëverbal reasoning by identifying patterns within a series of matrices.',\n",
    "            'Synonyms':   ['Pattern',     'Arrangement', 'Sequence', 'Logic'],\n",
    "            'Verbs':      ['Identify',    'Organize',    'Sequence', 'Analyze'],\n",
    "            'Nouns':      ['Matrix',      'Pattern',     'Arrangement','Sequence']\n",
    "        },\n",
    "        'Visual Puzzles': {\n",
    "            'Description': 'Measures visual‚Äëspatial problem‚Äësolving by completing jigsaw‚Äëlike puzzles.',\n",
    "            'Synonyms':   ['Puzzle',       'Problem‚Äësolving', 'Jigsaw', 'Game'],\n",
    "            'Verbs':      ['Solve',        'Complete',        'Arrange','Piece together'],\n",
    "            'Nouns':      ['Puzzle',       'Jigsaw',          'Problem', 'Solution']\n",
    "        },\n",
    "        'Figure Weights': {\n",
    "            'Description': 'Assesses quantitative and analogical reasoning by balancing scales.',\n",
    "            'Synonyms':   ['Balance',  'Analogy',   'Calculation', 'Weighing'],\n",
    "            'Verbs':      ['Balance',  'Calculate', 'Reason',      'Weigh'],\n",
    "            'Nouns':      ['Weight',   'Figure',    'Balance',     'Calculation']\n",
    "        },\n",
    "        'Picture Completion': {\n",
    "            'Description': 'Evaluates attention to detail by identifying missing parts in a picture.',\n",
    "            'Synonyms':   ['Completion',      'Attention',   'Observation', 'Missing details'],\n",
    "            'Verbs':      ['Complete',        'Observe',     'Identify',    'Find'],\n",
    "            'Nouns':      ['Picture',         'Completion',  'Detail',      'Observation']\n",
    "        }\n",
    "    },\n",
    "    'Working Memory Index (WMI)': {\n",
    "        'Digit Span': {\n",
    "            'Description': 'Measures short‚Äëterm memory by repeating increasingly longer sequences of numbers.',\n",
    "            'Synonyms':   ['Memory',   'Sequence',  'Repetition', 'Recall'],\n",
    "            'Verbs':      ['Remember', 'Repeat',    'Sequence',   'Recall'],\n",
    "            'Nouns':      ['Digit',    'Memory',    'Sequence',   'Repetition']\n",
    "        },\n",
    "        'Arithmetic': {\n",
    "            'Description': 'Evaluates numerical reasoning and concentration through mental arithmetic problems.',\n",
    "            'Synonyms':   ['Calculation', 'Numeracy',     'Math', 'Problem‚Äësolving'],\n",
    "            'Verbs':      ['Calculate',    'Solve',        'Add',  'Multiply'],\n",
    "            'Nouns':      ['Arithmetic',   'Calculation',  'Problem','Math']\n",
    "        },\n",
    "        'Letter‚ÄëNumber Sequencing': {\n",
    "            'Description': 'Measures working memory by recalling and arranging sequences of letters and numbers.',\n",
    "            'Synonyms':   ['Arrangement','Sequencing','Recall','Memory'],\n",
    "            'Verbs':      ['Arrange',    'Sequence',   'Recall','Organize'],\n",
    "            'Nouns':      ['Letter',     'Number',     'Sequence','Arrangement']\n",
    "        }\n",
    "    },\n",
    "    'Processing Speed Index (PSI)': {\n",
    "        'Symbol Search': {\n",
    "            'Description': 'Measures cognitive processing speed by identifying matching symbols.',\n",
    "            'Synonyms':   ['Recognition','Matching','Speed','Identification'],\n",
    "            'Verbs':      ['Search',     'Identify','Match','Recognize'],\n",
    "            'Nouns':      ['Symbol','Search','Match','Speed']\n",
    "        },\n",
    "        'Coding': {\n",
    "            'Description': 'Evaluates cognitive efficiency by quickly pairing numbers with symbols.',\n",
    "            'Synonyms':   ['Coding','Pairing','Efficiency','Speed'],\n",
    "            'Verbs':      ['Code','Pair','Match','Identify'],\n",
    "            'Nouns':      ['Code','Symbol','Number','Pairing']\n",
    "        },\n",
    "        'Cancellation': {\n",
    "            'Description': 'Measures attention and speed by canceling out specific target symbols.',\n",
    "            'Synonyms':   ['Cancellation','Targeting','Attention','Elimination'],\n",
    "            'Verbs':      ['Cancel','Target','Identify','Eliminate'],\n",
    "            'Nouns':      ['Cancellation','Target','Symbol','Attention']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# 1) Make sure the output dir exists\n",
    "os.makedirs('../Datasets', exist_ok=True)\n",
    "\n",
    "# 2) Flatten into rows\n",
    "rows = []\n",
    "for index, subtests in wais_dataset.items():\n",
    "    for subtest, attrs in subtests.items():\n",
    "        desc   = attrs.get('Description', '')\n",
    "        syns   = list(attrs.get('Synonyms',   []))\n",
    "        verbs  = list(attrs.get('Verbs',      []))\n",
    "        nouns  = list(attrs.get('Nouns',      []))\n",
    "        max_len = max(len(syns), len(verbs), len(nouns))\n",
    "        syns   += [''] * (max_len - len(syns))\n",
    "        verbs  += [''] * (max_len - len(verbs))\n",
    "        nouns  += [''] * (max_len - len(nouns))\n",
    "\n",
    "        for syn, vb, nn in zip(syns, verbs, nouns):\n",
    "            # 3) Skip rows where Synonym, Verb, AND Noun are all blank\n",
    "            if not (syn or vb or nn):\n",
    "                continue\n",
    "            rows.append({\n",
    "                'Index':       index,\n",
    "                'Subtest':     subtest,\n",
    "                'Description': desc,\n",
    "                'Synonym':     syn,\n",
    "                'Verb':        vb,\n",
    "                'Noun':        nn\n",
    "            })\n",
    "\n",
    "# 4) Build DataFrame and add empty Embedding column\n",
    "wais_df = pd.DataFrame(rows, columns=[\n",
    "    'Index', 'Subtest', 'Description', 'Synonym', 'Verb', 'Noun'\n",
    "])\n",
    "wais_df['Embedding'] = None  # placeholder for later\n",
    "\n",
    "# 5) Save to CSV\n",
    "output_path = '../Datasets/wais.csv'\n",
    "wais_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Preview\n",
    "print(\"Dataset shape:\", wais_df.shape)\n",
    "print(wais_df.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c5b327-3d34-439f-8a75-9e9471a0e65e",
   "metadata": {},
   "source": [
    "##  Steps for WAIS Personality Modeling Workflow \n",
    "\n",
    "1.  **Step 1: Create the Personality Dataset**\n",
    "\n",
    "    * **Purpose:** This initial step involves defining and generating the dataset that represents the Eysenck Personality Model (WAIS).\n",
    "    * **Actions:**\n",
    "        * Define the WAIS dataset structure (e.g., using a dictionary to represent factors, adjectives, synonyms, etc.).\n",
    "        * Generate the dataset by organizing the data into a Pandas DataFrame.\n",
    "        * Save the dataset to a CSV file.\n",
    "        * Log dataset metadata (e.g., number of rows, factors, data schema) and the dataset file itself as an artifact in MLflow.\n",
    "    * **Importance:** This step creates the raw data that will be used for embedding generation and model training.\n",
    "\n",
    "2.  **Step 2: API Key Handling and Initialization**\n",
    "\n",
    "    * **Purpose:** This cwaisical step ensures that your OpenAI API key is securely loaded and the OpenAI client is initialized. This sets the foundation for using the OpenAI API in subsequent steps.\n",
    "    * **Actions:**\n",
    "        * Load the OpenAI API key from a secure location (e.g., a file in the user's home directory).\n",
    "        * Validate the API key (e.g., check for existence, emptiness, and potentially a basic API call).\n",
    "        * Initialize the OpenAI client (`client`).\n",
    "        * Log the API key handling process and its outcome in MLflow.\n",
    "    * **Importance:** This step must succeed for the rest of the workflow that utilizes the OpenAI API (like embedding generation) to function. It's essential to handle potential errors (e.g., file not found, invalid key) gracefully.\n",
    "\n",
    "3.  **Step 3: Test Embedding API**\n",
    "\n",
    "    * **Purpose:** This step verifies that the OpenAI Embedding API is accessible and functioning correctly.\n",
    "    * **Actions:**\n",
    "        * Use the initialized OpenAI client (`client`) to make a test call to the Embedding API (e.g., by embedding a sample text).\n",
    "        * Check the API response for validity.\n",
    "        * Log the API call details and the outcome (success or failure) in MLflow.\n",
    "    * **Importance:** This step ensures that you can successfully generate embeddings before proceeding to the next step.\n",
    "\n",
    "4.  **Step 4: Create Embeddings for the Dataset**\n",
    "\n",
    "    * **Purpose:** This step generates numerical represenwaisions (embeddings) for the text data in the WAIS dataset using the OpenAI Embedding API.\n",
    "    * **Actions:**\n",
    "        * Load the WAIS dataset (created in Step 2).\n",
    "        * Use the OpenAI client (`client`) to generate embeddings for the relevant text fields (e.g., combining factor, adjective, synonym, verb, noun).\n",
    "        * Add the generated embeddings as a new column in the Pandas DataFrame.\n",
    "        * Save the DataFrame with embeddings to a new CSV file.\n",
    "        * Log embedding generation parameters (e.g., embedding model used), swaisistics (e.g., embedding length), and the embeddings file as an artifact in MLflow.\n",
    "    * **Importance:** This step transforms the text data into a numerical format that can be used for machine learning models.\n",
    "\n",
    "5.  **Step 5: Create and Visualize a Label Encoder**\n",
    "\n",
    "    * **Purpose:** This step prepares the categorical labels (personality factors) for model training by encoding them into numerical values and provides a visualization of this encoding.\n",
    "    * **Actions:**\n",
    "        * Load the dataset with embeddings (created in Step 4).\n",
    "        * Initialize a `LabelEncoder` from scikit-learn.\n",
    "        * Fit the `LabelEncoder` to the 'Factor' column to create the mapping between personality factors and numerical codes.\n",
    "        * Transform the 'Factor' column using the fitted `LabelEncoder` to create a new 'Factor_Encoded' column.\n",
    "        * Save the fitted `LabelEncoder` object.\n",
    "        * Generate a visualization (e.g., a bar chart) to show the mapping between original factors and encoded values.\n",
    "        * Save the visualization as an image file.\n",
    "        * Log the label encoder object and the visualization as artifacts in MLflow.\n",
    "        * Log the mapping between original factors and encoded values as a dictionary in MLflow.\n",
    "    * **Importance:** This step prepares the target variable for model training and provides a clear represenwaision of the encoding.\n",
    "\n",
    "6.  **Step 6: Create our WAIS Model (Model Training and Evaluation)**\n",
    "\n",
    "    * **Purpose:** This step trains a machine learning model on the generated embeddings to predict personality factors and evaluates its performance.\n",
    "    * **Actions:**\n",
    "        * Load the dataset with embeddings (created in Step 4).\n",
    "        * Load the saved `LabelEncoder` (created in Step 5).\n",
    "        * Prepare the data for model training:\n",
    "            * Extract the embeddings as features (`X`).\n",
    "            * Encode the 'Factor' column using the loaded `LabelEncoder` to get the target variable (`y`).\n",
    "            * Split the data into training and testing sets.\n",
    "        * Initialize a machine learning model (e.g., `RandomForestClassifier`).\n",
    "        * Train the model on the training data.\n",
    "        * Make predictions on the test data.\n",
    "        * Evaluate the model's performance using appropriate metrics (e.g., accuracy, classification report, confusion matrix).\n",
    "        * Generate visualizations of the evaluation results (e.g., confusion matrix plot).\n",
    "        * Save the trained model.\n",
    "        * Log model training parameters (e.g., hyperparameters), evaluation metrics, visualizations, and the trained model as artifacts in MLflow.\n",
    "    * **Importance:** This step is the core of the machine learning process, where the model learns to predict personality factors from the embeddings.\n",
    "\n",
    "7.  **Step 7: Model Testing (Inference on New Data)**\n",
    "\n",
    "    * **Purpose:** This step demonstrates how to use the trained model to predict personality factors for new, unseen text inputs.\n",
    "    * **Actions:**\n",
    "        * Load the trained model (saved in Step 6).\n",
    "        * Load the saved `LabelEncoder` (created in Step 5).\n",
    "        * Define a function that:\n",
    "            * Takes new text as input.\n",
    "            * Generates an embedding for the new text using the OpenAI API.\n",
    "            * Uses the loaded model to predict the personality factor.\n",
    "            * Uses the loaded `LabelEncoder` to decode the numerical prediction back to the original factor name.\n",
    "        * Provide example new text inputs.\n",
    "        * Use the function to predict personality factors for the example texts.\n",
    "        * Print the predictions.\n",
    "        * Log the test inputs and predictions in MLflow.\n",
    "    * **Importance:** This step demonstrates the practical application of the trained model for making predictions on new data.\n",
    "\n",
    "8.  **Step 8: Model Application, Visualization, and Analysis**\n",
    "\n",
    "    * **Purpose:** This step provides additional visualization and analysis of the data and model.\n",
    "    * **Actions:**\n",
    "        * Load the dataset with embeddings (created in Step 4).\n",
    "        * Apply PCA for dimensionality reduction and visualization of the embeddings.\n",
    "        * Generate and log PCA plots to visualize the embedding distribution.\n",
    "        * Perform K-Means clustering on the embeddings to identify potential groupings or clusters of similar personality traits.\n",
    "        * Add cluster labels to the dataset and save the clustered data.\n",
    "        * Log clustering parameters (e.g., number of clusters) and the clustered data as artifacts in MLflow.\n",
    "    * **Importance:** This step offers valuable insights into the data and model:\n",
    "        * PCA visualization helps understand the distribution of embeddings.\n",
    "        * Clustering can reveal underlying patterns in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b2a39-e66d-4a46-8f62-ad88cd36ce87",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 2: API key setup** <a class=\"anchor\" id=\"wais_page_2\"></a>\n",
    "\n",
    "[Back to Top](#wais_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95a16a6e-4c83-45ff-9adb-6bacd3c88193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/opt/python@3.13/bin/python3.13\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a790191a-5760-45d1-a325-0cb2dcff5582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API key file found at: /Users/jsr/openai_api_key.txt\n",
      "üîë API key read successfully.\n",
      "ü§ñ OpenAI API client initialized.\n",
      "‚úÖ OpenAI API key verified successfully with a basic API call.\n",
      "üèÉ View run API Key Handling and Initialization at: http://127.0.0.1:5000/#/experiments/836008548927582795/runs/374703655e4e4e63bc8dd45f1440afde\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/836008548927582795\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import mlflow\n",
    "\n",
    "# Start an MLFlow run for API key setup\n",
    "with mlflow.start_run(run_name=\"API Key Handling and Initialization\") as run:\n",
    "    try:\n",
    "        # Log the environment setup process\n",
    "        mlflow.log_param(\"Step\", \"API Key Handling and Initialization\")\n",
    "\n",
    "        # Define the path to your API key file\n",
    "        api_key_file_path = os.path.expanduser('~/openai_api_key.txt')\n",
    "        mlflow.log_param(\"API Key File Path\", api_key_file_path)\n",
    "\n",
    "        # Evaluation: Check if the API key file exists\n",
    "        if not os.path.exists(api_key_file_path):\n",
    "            error_message = f\"API key file not found at: {api_key_file_path}. Please ensure the file exists.\"\n",
    "            mlflow.log_param(\"API Key Swaisus\", \"Error: File not found\")\n",
    "            mlflow.log_param(\"Error\", error_message)\n",
    "            raise FileNotFoundError(error_message)\n",
    "        else:\n",
    "            mlflow.log_param(\"API Key File Existence\", \"Confirmed\")\n",
    "            print(f\"‚úÖ API key file found at: {api_key_file_path}\")\n",
    "\n",
    "        # Read the API key from the file\n",
    "        with open(api_key_file_path, 'r') as file:\n",
    "            api_key = file.read().strip()\n",
    "\n",
    "        # Evaluation: Check if the read API key is empty\n",
    "        if not api_key:\n",
    "            error_message = f\"API key file at: {api_key_file_path} is empty. Please ensure your API key is in the file.\"\n",
    "            mlflow.log_param(\"API Key Swaisus\", \"Error: Empty file\")\n",
    "            mlflow.log_param(\"Error\", error_message)\n",
    "            raise ValueError(error_message)\n",
    "        else:\n",
    "            mlflow.log_param(\"API Key Swaisus\", \"Read successfully\")\n",
    "            mlflow.log_param(\"API Key Length\", len(api_key)) # Log the length as a basic sanity check\n",
    "            print(\"üîë API key read successfully.\")\n",
    "\n",
    "        # Set up your OpenAI API key\n",
    "        openai.api_key = api_key\n",
    "        client = openai.OpenAI(api_key=api_key)\n",
    "        mlflow.log_param(\"OpenAI API Client\", \"Initialized successfully\")\n",
    "        print(\"ü§ñ OpenAI API client initialized.\")\n",
    "\n",
    "        # Evaluation: Attempt a basic API call to verify the key (optional, but recommended for immediate feedback)\n",
    "        try:\n",
    "            response = client.models.list()  # Removed the 'limit' argument\n",
    "            mlflow.log_param(\"API Key Verification\", \"Successful (models list)\")\n",
    "            print(\"‚úÖ OpenAI API key verified successfully with a basic API call.\")\n",
    "        except openai.AuthenticationError as auth_error:\n",
    "            mlflow.log_param(\"API Key Verification\", \"Failed (AuthenticationError)\")\n",
    "            mlflow.log_param(\"Error\", str(auth_error))\n",
    "            raise openai.AuthenticationError(f\"OpenAI API key authentication failed: {auth_error}\")\n",
    "        except openai.OpenAIError as general_error:\n",
    "            mlflow.log_param(\"API Key Verification\", \"Failed (OpenAIError)\")\n",
    "            mlflow.log_param(\"Error\", str(general_error))\n",
    "            print(f\"‚ö†Ô∏è Warning: OpenAI API client initialized, but a test call failed with: {general_error}. Further API calls might fail.\")\n",
    "            mlflow.log_param(\"API Key Verification Warning\", str(general_error))\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"FileNotFoundError\")\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        raise\n",
    "    except ValueError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"ValueError\")\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        raise\n",
    "    except openai.AuthenticationError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"AuthenticationError\")\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        raise\n",
    "    except openai.OpenAIError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"OpenAIError\")\n",
    "        print(f\"‚ö†Ô∏è Warning during API initialization: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        # Log the error if any other unexpected issue occurs\n",
    "        mlflow.log_param(\"Error Type\", type(e).__name__)\n",
    "        mlflow.log_param(\"Error\", str(e))\n",
    "        print(f\"‚ùå An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        # End the MLFlow run\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d949ba3-7cf4-4bda-9e56-6a4f43cb8882",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 3: Test Embedding** <a class=\"anchor\" id=\"wais_page_2\"></a>\n",
    "\n",
    "[Back to Top](#wais_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8da8f526-a61f-4805-9d71-2a20383e45f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI client found and ready.\n",
      "üìù Testing embedding for text: 'The quick brown fox jumps over the lazy dog.'\n",
      "‚úÖ Embedding model 'text-embedding-3-small' is available.\n",
      "Embedding length: 1536\n",
      "Embedding snippet: [-0.01842353865504265, -0.00725775770843029, 0.0036669441033154726, -0.0542047917842865, -0.022724902257323265, 0.03694858402013779, 0.02903103083372116, 0.023866858333349228, 0.011229223571717739, -0.020618630573153496]\n",
      "‚úÖ Embedding API test successful.\n",
      "üèÉ View run Test Embedding API at: http://127.0.0.1:5000/#/experiments/836008548927582795/runs/e992353f94034dbcbf1a7e45724f32cd\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/836008548927582795\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import mlflow\n",
    "\n",
    "# Function to test the OpenAI Embedding API\n",
    "def test_openai_embedding_api():\n",
    "    with mlflow.start_run(run_name=\"Test Embedding API\") as run:\n",
    "        try:\n",
    "            # Log the step name\n",
    "            mlflow.log_param(\"Step\", \"Test Embedding API\")\n",
    "\n",
    "            # Evaluation: Check if the OpenAI client is initialized\n",
    "            if 'client' not in globals() or not isinstance(client, openai.OpenAI):\n",
    "                error_message = \"OpenAI client is not initialized. Ensure the API key setup step was executed successfully.\"\n",
    "                mlflow.log_param(\"API Client Swaisus\", \"Not Initialized\")\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                raise RuntimeError(error_message)\n",
    "            else:\n",
    "                mlflow.log_param(\"API Client Swaisus\", \"Initialized\")\n",
    "                print(\"‚úÖ OpenAI client found and ready.\")\n",
    "\n",
    "            # Example text to embed\n",
    "            text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "            mlflow.log_param(\"Test Text\", text)\n",
    "            print(f\"üìù Testing embedding for text: '{text}'\")\n",
    "\n",
    "            # Evaluation: Check if the specified embedding model is available (optional, but good practice)\n",
    "            embedding_model = \"text-embedding-3-small\"\n",
    "            mlflow.log_param(\"Embedding Model\", embedding_model)\n",
    "            try:\n",
    "                model_info = client.models.retrieve(embedding_model)\n",
    "                mlflow.log_param(\"Embedding Model Availability\", \"Confirmed\")\n",
    "                print(f\"‚úÖ Embedding model '{embedding_model}' is available.\")\n",
    "            except openai.NotFoundError:\n",
    "                error_message = f\"Embedding model '{embedding_model}' not found. Please check the model name.\"\n",
    "                mlflow.log_param(\"Embedding Model Availability\", \"Not Found\")\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                raise ValueError(error_message)\n",
    "            except Exception as e:\n",
    "                error_message = f\"Error checking embedding model availability: {e}\"\n",
    "                mlflow.log_param(\"Embedding Model Availability Check Error\", str(e))\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                print(f\"‚ö†Ô∏è Warning: Error checking model availability: {e}. Proceeding with embedding request.\")\n",
    "\n",
    "            # Request to generate embeddings\n",
    "            response = client.embeddings.create(\n",
    "                input=[text],  # The input should be a list of strings\n",
    "                model=embedding_model\n",
    "            )\n",
    "\n",
    "            # Evaluation: Check if the embedding response contains data\n",
    "            if not response.data:\n",
    "                error_message = \"Embedding API response does not contain any data.\"\n",
    "                mlflow.log_param(\"Embedding API Response Swaisus\", \"No Data\")\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                raise ValueError(error_message)\n",
    "            else:\n",
    "                mlflow.log_param(\"Embedding API Response Swaisus\", \"Data Received\")\n",
    "\n",
    "            # Extract the embedding\n",
    "            embedding = response.data[0].embedding\n",
    "\n",
    "            # Evaluation: Check if the extracted embedding is not empty\n",
    "            if not embedding:\n",
    "                error_message = \"Extracted embedding is empty.\"\n",
    "                mlflow.log_param(\"Embedding Extraction Swaisus\", \"Empty Embedding\")\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                raise ValueError(error_message)\n",
    "            else:\n",
    "                mlflow.log_param(\"Embedding Extraction Swaisus\", \"Success\")\n",
    "\n",
    "            # Log the embedding length and a snippet\n",
    "            embedding_length = len(embedding)\n",
    "            mlflow.log_param(\"Embedding Length\", embedding_length)\n",
    "            mlflow.log_param(\"Embedding Snippet\", embedding[:10])\n",
    "\n",
    "            # Print the embedding length and a snippet\n",
    "            print(f\"Embedding length: {embedding_length}\")\n",
    "            print(f\"Embedding snippet: {embedding[:10]}\")  # Print the first 10 elements of the embedding\n",
    "\n",
    "            print(\"‚úÖ Embedding API test successful.\")\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            mlflow.log_param(\"Error Type\", \"RuntimeError\")\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            raise\n",
    "        except ValueError as e:\n",
    "            mlflow.log_param(\"Error Type\", \"ValueError\")\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            raise\n",
    "        except openai.NotFoundError as e:\n",
    "            mlflow.log_param(\"Error Type\", \"NotFoundError\")\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            raise\n",
    "        except openai.OpenAIError as e:\n",
    "            mlflow.log_param(\"Error Type\", \"OpenAIError\")\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"‚ùå OpenAI API error: {e}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            # Log the error if any other unexpected issue occurs\n",
    "            mlflow.log_param(\"Error Type\", type(e).__name__)\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"‚ùå An unexpected error occurred: {e}\")\n",
    "            raise\n",
    "\n",
    "        finally:\n",
    "            # End the MLFlow run\n",
    "            mlflow.end_run()\n",
    "\n",
    "# Test the OpenAI Embedding API\n",
    "test_openai_embedding_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c144305-f45d-4bd8-bb64-b5873d8b1029",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 4: Create WAIS Embeddings** <a class=\"anchor\" id=\"wais_page_3\"></a>\n",
    "\n",
    "[Back to Top](#wais_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6894c193-8e3e-40af-b544-79f26a77349c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI client initialized.\n",
      "‚úÖ Dataset loaded: ../Datasets/wais.csv (60 rows)\n",
      "‚è≥ Started embeddings at 2025-05-24 22:41:30.780200\n",
      "‚úÖ Finished embeddings at 2025-05-24 22:42:04.005467 (took 0:00:33.225267)\n",
      "üíæ Embeddings saved to ../Embeddings/wais_embeddings.csv\n",
      "\n",
      "Sample rows:\n",
      "                              Index       Subtest  \\\n",
      "0  Verbal Comprehension Index (VCI)  Similarities   \n",
      "1  Verbal Comprehension Index (VCI)  Similarities   \n",
      "2  Verbal Comprehension Index (VCI)  Similarities   \n",
      "3  Verbal Comprehension Index (VCI)  Similarities   \n",
      "4  Verbal Comprehension Index (VCI)    Vocabulary   \n",
      "\n",
      "                                         Description      Synonym      Verb  \\\n",
      "0  Assesses abstract verbal reasoning by identify...   Comparison   Compare   \n",
      "1  Assesses abstract verbal reasoning by identify...     Matching     Match   \n",
      "2  Assesses abstract verbal reasoning by identify...      Pairing      Pair   \n",
      "3  Assesses abstract verbal reasoning by identify...  Resemblance  Resemble   \n",
      "4  Measures word knowledge and verbal concept for...      Lexicon    Define   \n",
      "\n",
      "         Noun                                          Embedding  \n",
      "0  Similarity  [-0.018594644963741302, -0.02942529506981373, ...  \n",
      "1  Comparison  [-0.0252859927713871, -0.019689394161105156, -...  \n",
      "2       Match  [-0.020812654867768288, -0.022765416651964188,...  \n",
      "3        Pair  [-0.01504573505371809, -0.04250355064868927, -...  \n",
      "4  Vocabulary  [0.008364218287169933, -0.007146368268877268, ...  \n",
      "üèÉ View run Generate WAIS Embeddings at: http://127.0.0.1:5000/#/experiments/836008548927582795/runs/cc94c45d7c704637bb18ba34b83d48ca\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/836008548927582795\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "def get_openai_api_key_from_file(filepath='~/openai_api_key.txt'):\n",
    "    filepath = os.path.expanduser(filepath)\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            api_key = f.read().strip()\n",
    "        if not api_key:\n",
    "            raise ValueError(f\"API key file at '{filepath}' is empty.\")\n",
    "        return api_key\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"API key file not found at '{filepath}'.\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error reading API key from file '{filepath}': {e}\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "try:\n",
    "    openai_api_key = get_openai_api_key_from_file()\n",
    "    client = OpenAI(api_key=openai_api_key)\n",
    "    print(\"‚úÖ OpenAI client initialized.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing OpenAI client: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Load the flattened WAIS dataset\n",
    "dataset_path = '../Datasets/wais.csv'\n",
    "try:\n",
    "    wais_df = pd.read_csv(dataset_path)\n",
    "    print(f\"‚úÖ Dataset loaded: {dataset_path} ({wais_df.shape[0]} rows)\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"Dataset not found at {dataset_path}\")\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    try:\n",
    "        resp = client.embeddings.create(input=[text], model=model)\n",
    "        return resp.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating embedding for '{text}': {e}\")\n",
    "        raise\n",
    "\n",
    "with mlflow.start_run(run_name=\"Generate WAIS Embeddings\") as run:\n",
    "    mlflow.log_param(\"model\", \"text-embedding-3-small\")\n",
    "    mlflow.log_param(\"dataset\", dataset_path)\n",
    "    start = datetime.now()\n",
    "    mlflow.log_param(\"start_time\", str(start))\n",
    "    print(f\"‚è≥ Started embeddings at {start}\")\n",
    "\n",
    "    if wais_df.empty:\n",
    "        raise ValueError(\"Loaded dataset is empty.\")\n",
    "\n",
    "    # Generate embeddings using the correct columns\n",
    "    wais_df['Embedding'] = wais_df.apply(\n",
    "        lambda r: get_embedding(f\"{r['Index']} {r['Subtest']} {r['Synonym']} {r['Verb']} {r['Noun']}\"),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    end = datetime.now()\n",
    "    mlflow.log_param(\"end_time\", str(end))\n",
    "    print(f\"‚úÖ Finished embeddings at {end} (took {end - start})\")\n",
    "\n",
    "    # Save and log\n",
    "    out_path = '../Embeddings/wais_embeddings.csv'\n",
    "    wais_df[['Index','Subtest','Synonym','Verb','Noun','Embedding']].to_csv(out_path, index=False)\n",
    "    mlflow.log_artifact(out_path, artifact_path=\"embeddings\")\n",
    "    print(f\"üíæ Embeddings saved to {out_path}\")\n",
    "\n",
    "    # Log some stats\n",
    "    mlflow.log_param(\"num_rows\", wais_df.shape[0])\n",
    "    mlflow.log_param(\"num_columns\", wais_df.shape[1])\n",
    "    mlflow.log_param(\"embedding_length\", len(wais_df['Embedding'].iloc[0]))\n",
    "\n",
    "    print(\"\\nSample rows:\")\n",
    "    print(wais_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34b9502-e9f9-4b20-bbb4-813e3e5dd54a",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 5: Create Label Embeddings** <a class=\"anchor\" id=\"wais_page_3\"></a>\n",
    "\n",
    "[Back to Top](#wais_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ddfe5c0b-fda2-439c-9348-ac797b5eb29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings dataset loaded from: ../Embeddings/wais_embeddings.csv\n",
      "üíæ Label encoder saved to: ../Models/wais_label_encoder.pkl\n",
      "                              Index  Index_Encoded\n",
      "0  Verbal Comprehension Index (VCI)              2\n",
      "1  Verbal Comprehension Index (VCI)              2\n",
      "2  Verbal Comprehension Index (VCI)              2\n",
      "3  Verbal Comprehension Index (VCI)              2\n",
      "4  Verbal Comprehension Index (VCI)              2\n",
      "\n",
      "Mapping:\n",
      "  Perceptual Reasoning Index (PRI) ‚Üí 0\n",
      "  Processing Speed Index (PSI) ‚Üí 1\n",
      "  Verbal Comprehension Index (VCI) ‚Üí 2\n",
      "  Working Memory Index (WMI) ‚Üí 3\n",
      "‚úÖ Plot saved to /Users/jsr/Downloads/GitHub/Personality-Trait-Models/Notebooks/wais_label_encoder_mapping.png\n",
      "üèÉ View run Create and Visualize Label Encoder at: http://127.0.0.1:5000/#/experiments/836008548927582795/runs/9d3529be6fe64ca184459b75b72caa54\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/836008548927582795\n",
      "‚úÖ Label encoding and visualization complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#‚îÄ‚îÄ 1) Load embeddings dataset ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "embeddings_csv_path = '../Embeddings/wais_embeddings.csv'\n",
    "try:\n",
    "    df = pd.read_csv(embeddings_csv_path)\n",
    "    print(f\"‚úÖ Embeddings dataset loaded from: {embeddings_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: Embeddings dataset not found at: {embeddings_csv_path}\")\n",
    "    exit(1)\n",
    "\n",
    "#‚îÄ‚îÄ 2) Fit LabelEncoder on the 'Index' column ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "label_encoder = LabelEncoder()\n",
    "df['Index_Encoded'] = label_encoder.fit_transform(df['Index'])\n",
    "\n",
    "#‚îÄ‚îÄ 3) Save the encoder to disk ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "label_encoder_path = \"../Models/wais_label_encoder.pkl\"\n",
    "joblib.dump(label_encoder, label_encoder_path)\n",
    "print(f\"üíæ Label encoder saved to: {label_encoder_path}\")\n",
    "\n",
    "#‚îÄ‚îÄ 4) Visualization helper ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def visualize_label_encoder(le, artifact_path=\"visualization\"):\n",
    "    classes = le.classes_\n",
    "    values = le.transform(classes)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=classes, y=values)\n",
    "    plt.xlabel(\"Original Index\")\n",
    "    plt.ylabel(\"Encoded Value\")\n",
    "    plt.title(\"WAIS Index ‚Üí Encoded Mapping\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    out_file = \"wais_label_encoder_mapping.png\"\n",
    "    plt.savefig(out_file)\n",
    "    plt.close()\n",
    "    print(f\"‚úÖ Plot saved to {os.path.abspath(out_file)}\")\n",
    "    mlflow.log_artifact(out_file, artifact_path=artifact_path)\n",
    "\n",
    "#‚îÄ‚îÄ 5) Log everything in MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"Create and Visualize Label Encoder\"):\n",
    "    mlflow.log_param(\"step\", \"label_encoding\")\n",
    "    mlflow.log_artifact(label_encoder_path, artifact_path=\"label_encoder\")\n",
    "\n",
    "    # preview\n",
    "    print(df[['Index', 'Index_Encoded']].head())\n",
    "    mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    print(\"\\nMapping:\")\n",
    "    for k, v in mapping.items():\n",
    "        print(f\"  {k} ‚Üí {v}\")\n",
    "    mlflow.log_dict(mapping, \"label_encoder/mapping.json\")\n",
    "\n",
    "    # make & log the bar chart\n",
    "    visualize_label_encoder(label_encoder)\n",
    "\n",
    "print(\"‚úÖ Label encoding and visualization complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a5fde5-2c9a-46dc-998a-ca01c356e80e",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 6: Create Model** <a class=\"anchor\" id=\"wais_page_3\"></a>\n",
    "\n",
    "[Back to Top](#wais_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc4b4c49-a90c-4b4e-9235-6a2036f6cb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings dataset loaded from: ../Embeddings/wais_embeddings.csv\n",
      "‚úÖ Label encoder loaded from: ../Models/wais_label_encoder.pkl\n",
      "Train samples: 36, Test samples: 24\n",
      "‚è≥ Training started at 2025-05-24 22:42:04.435704\n",
      "‚úÖ Training finished at 2025-05-24 22:42:04.497047 (Duration: 0:00:00.061343)\n",
      "üîç Test accuracy: 1.0000\n",
      "üìä Classification report saved to wais_classification_report.csv\n",
      "üìä Confusion matrix saved to wais_confusion_matrix.csv\n",
      "üñºÔ∏è Saved confusion matrix plot to wais_confusion_matrix.png\n",
      "üíæ Trained model saved to ../Models/wais_rf_model.pkl\n",
      "\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "Perceptual Reasoning Index (PRI)       1.00      1.00      1.00         8\n",
      "    Processing Speed Index (PSI)       1.00      1.00      1.00         5\n",
      "Verbal Comprehension Index (VCI)       1.00      1.00      1.00         6\n",
      "      Working Memory Index (WMI)       1.00      1.00      1.00         5\n",
      "\n",
      "                        accuracy                           1.00        24\n",
      "                       macro avg       1.00      1.00      1.00        24\n",
      "                    weighted avg       1.00      1.00      1.00        24\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "                                   Perceptual Reasoning Index (PRI)  \\\n",
      "Perceptual Reasoning Index (PRI)                                 8   \n",
      "Processing Speed Index (PSI)                                     0   \n",
      "Verbal Comprehension Index (VCI)                                 0   \n",
      "Working Memory Index (WMI)                                       0   \n",
      "\n",
      "                                  Processing Speed Index (PSI)  \\\n",
      "Perceptual Reasoning Index (PRI)                             0   \n",
      "Processing Speed Index (PSI)                                 5   \n",
      "Verbal Comprehension Index (VCI)                             0   \n",
      "Working Memory Index (WMI)                                   0   \n",
      "\n",
      "                                  Verbal Comprehension Index (VCI)  \\\n",
      "Perceptual Reasoning Index (PRI)                                 0   \n",
      "Processing Speed Index (PSI)                                     0   \n",
      "Verbal Comprehension Index (VCI)                                 6   \n",
      "Working Memory Index (WMI)                                       0   \n",
      "\n",
      "                                  Working Memory Index (WMI)  \n",
      "Perceptual Reasoning Index (PRI)                           0  \n",
      "Processing Speed Index (PSI)                               0  \n",
      "Verbal Comprehension Index (VCI)                           0  \n",
      "Working Memory Index (WMI)                                 5  \n",
      "üèÉ View run WAIS_RF_Training at: http://127.0.0.1:5000/#/experiments/836008548927582795/runs/5fc8810fcdc84359a74aaea59b00586b\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/836008548927582795\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#‚îÄ‚îÄ 1) Load embeddings dataset ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "embeddings_csv_path = '../Embeddings/wais_embeddings.csv'\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        embeddings_csv_path,\n",
    "        converters={'Embedding': lambda s: np.array(eval(s)) if isinstance(s, str) else np.array(s)}\n",
    "    )\n",
    "    print(f\"‚úÖ Embeddings dataset loaded from: {embeddings_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: Embeddings dataset not found at: {embeddings_csv_path}\")\n",
    "    exit(1)\n",
    "\n",
    "#‚îÄ‚îÄ 2) Load the pre‚Äêfitted label encoder ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "label_encoder_path = \"../Models/wais_label_encoder.pkl\"\n",
    "try:\n",
    "    label_encoder = joblib.load(label_encoder_path)\n",
    "    print(f\"‚úÖ Label encoder loaded from: {label_encoder_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: Label encoder not found at: {label_encoder_path}\")\n",
    "    exit(1)\n",
    "\n",
    "#‚îÄ‚îÄ 3) Prepare features and labels ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df['Embedding'].values)          # shape: (n_samples, embedding_dim)\n",
    "y = df['Index'].values                        # target is the WAIS Index (VCI, PRI, etc.)\n",
    "y_encoded = label_encoder.transform(y)        # numeric labels\n",
    "\n",
    "#‚îÄ‚îÄ 4) Split into train/test ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded,\n",
    "    test_size=0.4,\n",
    "    random_state=42,\n",
    "    stratify=y_encoded\n",
    ")\n",
    "print(f\"Train samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "#‚îÄ‚îÄ 5) Start MLflow run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"WAIS_RF_Training\") as run:\n",
    "    # Log params\n",
    "    mlflow.log_param(\"model_type\", \"RandomForestClassifier\")\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"test_size\", 0.4)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_artifact(label_encoder_path, artifact_path=\"label_encoder\")\n",
    "\n",
    "    start_ts = datetime.now()\n",
    "    mlflow.log_param(\"start_time\", str(start_ts))\n",
    "    print(f\"‚è≥ Training started at {start_ts}\")\n",
    "\n",
    "    # Train\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    end_ts = datetime.now()\n",
    "    mlflow.log_param(\"end_time\", str(end_ts))\n",
    "    print(f\"‚úÖ Training finished at {end_ts} (Duration: {end_ts - start_ts})\")\n",
    "\n",
    "    # Predict & evaluate\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    print(f\"üîç Test accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Classification report\n",
    "    report_dict = classification_report(\n",
    "        y_test, y_pred,\n",
    "        target_names=label_encoder.classes_,\n",
    "        output_dict=True\n",
    "    )\n",
    "    report_df = pd.DataFrame(report_dict).transpose()\n",
    "    report_path = \"wais_classification_report.csv\"\n",
    "    report_df.to_csv(report_path, index=True)\n",
    "    mlflow.log_artifact(report_path, artifact_path=\"metrics\")\n",
    "    print(f\"üìä Classification report saved to {report_path}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_df = pd.DataFrame(\n",
    "        cm,\n",
    "        index=label_encoder.classes_,\n",
    "        columns=label_encoder.classes_\n",
    "    )\n",
    "    cm_path = \"wais_confusion_matrix.csv\"\n",
    "    cm_df.to_csv(cm_path, index=True)\n",
    "    mlflow.log_artifact(cm_path, artifact_path=\"metrics\")\n",
    "    print(f\"üìä Confusion matrix saved to {cm_path}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"WAIS RandomForest Confusion Matrix\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.tight_layout()\n",
    "    cm_img = \"wais_confusion_matrix.png\"\n",
    "    plt.savefig(cm_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cm_img, artifact_path=\"metrics\")\n",
    "    print(f\"üñºÔ∏è Saved confusion matrix plot to {cm_img}\")\n",
    "\n",
    "    # Save the trained model\n",
    "    model_path = \"../Models/wais_rf_model.pkl\"\n",
    "    joblib.dump(clf, model_path)\n",
    "    mlflow.log_artifact(model_path, artifact_path=\"models\")\n",
    "    print(f\"üíæ Trained model saved to {model_path}\")\n",
    "\n",
    "    # Final logs\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3656c2b1-5d3d-489d-9759-ed219e20d2b5",
   "metadata": {},
   "source": [
    "This block of code is a comprehensive step-by-step process focusing specifically on:\n",
    "1. **Data Loading and Preprocessing**: Parsing and preparing embeddings from a CSV file for machine learning.\n",
    "2. **Model Training**: Using a RandomForestClassifier to train on the embeddings.\n",
    "3. **Model Evaluation**: Calculating and logging metrics such as accuracy, alongside detailed classification reports and confusion matrices.\n",
    "4. **Visualization and Logging**: Visualizing the confusion matrix and logging both the visual represenwaision and numerical data as artifacts in MLflow.\n",
    "5. **Model Persistence**: Saving the trained model for future use or deployment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b586cb-65eb-4f24-9726-c7b61611182c",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 7: Evaluate Model** <a class=\"anchor\" id=\"wais_page_3\"></a>\n",
    "\n",
    "[Back to Top](#wais_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3bbc78ca-7e53-4ab5-8c7c-c2d2848d4367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings dataset loaded from: ../Embeddings/wais_embeddings.csv\n",
      "‚úÖ Label encoder loaded from: ../Models/wais_label_encoder.pkl\n",
      "‚úÖ Trained model loaded from: ../Models/wais_rf_model.pkl\n",
      "Train size: 36, Test size: 24\n",
      "üîç Test accuracy: 1.0000\n",
      "üèÉ View run WAIS Model Evaluation at: http://127.0.0.1:5000/#/experiments/836008548927582795/runs/fe08f8a35af94b8bb9ef5babb0c2388b\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/836008548927582795\n",
      "‚úÖ WAIS model evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import mlflow\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#‚îÄ‚îÄ Paths ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "embeddings_csv_path = '../Embeddings/wais_embeddings.csv'\n",
    "label_encoder_path  = '../Models/wais_label_encoder.pkl'\n",
    "model_path          = '../Models/wais_rf_model.pkl'\n",
    "\n",
    "#‚îÄ‚îÄ 1) Load embeddings with converter ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        embeddings_csv_path,\n",
    "        converters={'Embedding': lambda s: np.array(ast.literal_eval(s)) if isinstance(s, str) else np.array(s)}\n",
    "    )\n",
    "    print(f\"‚úÖ Embeddings dataset loaded from: {embeddings_csv_path}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Error loading embeddings: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "#‚îÄ‚îÄ 2) Load label encoder ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    label_encoder = joblib.load(label_encoder_path)\n",
    "    print(f\"‚úÖ Label encoder loaded from: {label_encoder_path}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Error loading label encoder: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "#‚îÄ‚îÄ 3) Load trained model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    loaded_clf = joblib.load(model_path)\n",
    "    print(f\"‚úÖ Trained model loaded from: {model_path}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Error loading model: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "#‚îÄ‚îÄ 4) Prepare features & labels ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df['Embedding'].values)\n",
    "y = df['Index'].values\n",
    "y_encoded = label_encoder.transform(y)\n",
    "\n",
    "#‚îÄ‚îÄ 5) Train/test split ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded,\n",
    "    test_size=0.4,\n",
    "    random_state=42,\n",
    "    stratify=y_encoded\n",
    ")\n",
    "print(f\"Train size: {X_train.shape[0]}, Test size: {X_test.shape[0]}\")\n",
    "\n",
    "#‚îÄ‚îÄ 6) Evaluate under MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"WAIS Model Evaluation\"):\n",
    "    mlflow.log_param(\"step\", \"evaluate_model\")\n",
    "    mlflow.log_artifact(label_encoder_path, artifact_path=\"label_encoder\")\n",
    "    mlflow.log_artifact(model_path, artifact_path=\"model\")\n",
    "    mlflow.log_param(\"test_samples\", X_test.shape[0])\n",
    "\n",
    "    # Predict\n",
    "    y_pred = loaded_clf.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    print(f\"üîç Test accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Classification report\n",
    "    report_dict = classification_report(\n",
    "        y_test, y_pred,\n",
    "        target_names=label_encoder.classes_,\n",
    "        output_dict=True\n",
    "    )\n",
    "    report_df = pd.DataFrame(report_dict).transpose()\n",
    "    report_path = \"wais_evaluation_classification_report.csv\"\n",
    "    report_df.to_csv(report_path, index=True)\n",
    "    mlflow.log_artifact(report_path, artifact_path=\"evaluation\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_df = pd.DataFrame(cm, index=label_encoder.classes_, columns=label_encoder.classes_)\n",
    "    cm_path = \"wais_evaluation_confusion_matrix.csv\"\n",
    "    cm_df.to_csv(cm_path, index=True)\n",
    "    mlflow.log_artifact(cm_path, artifact_path=\"evaluation\")\n",
    "\n",
    "    # Plot & log confusion matrix\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"Confusion Matrix (Test Set)\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.tight_layout()\n",
    "    cm_img = \"wais_evaluation_confusion_matrix.png\"\n",
    "    plt.savefig(cm_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cm_img, artifact_path=\"evaluation\")\n",
    "\n",
    "print(\"‚úÖ WAIS model evaluation complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af80057-6c04-4228-ae9b-ed84b87fa9a6",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 8: Test and Evaluate Model** <a class=\"anchor\" id=\"wais_page_3\"></a>\n",
    "\n",
    "[Back to Top](#wais_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe70d8f9-a9eb-4908-bbf9-db62ee23023b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Testing (Inference on New Data) ---\n",
      "‚úÖ Label encoder loaded from: ../Models/wais_label_encoder.pkl\n",
      "‚úÖ Trained model loaded from: ../Models/wais_rf_model.pkl\n",
      "\n",
      "--- Testing Model on New Data ---\n",
      "Predicted Factor for 'I love going to parties and meeting new people....': Processing Speed Index (PSI)\n",
      "Predicted Factor for 'I prefer staying home with a good book....': Processing Speed Index (PSI)\n",
      "Predicted Factor for 'I often feel anxious and worried....': Processing Speed Index (PSI)\n",
      "Predicted Factor for 'I am generally calm and relaxed....': Verbal Comprehension Index (VCI)\n",
      "Predicted Factor for 'I enjoy taking risks and trying new things....': Verbal Comprehension Index (VCI)\n",
      "üèÉ View run Step 7: Model Testing (Inference on New Data) at: http://127.0.0.1:5000/#/experiments/836008548927582795/runs/c70b348830694e5d88f1352237e572cb\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/836008548927582795\n",
      "\n",
      "‚úÖ Model testing (inference on new data) complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import joblib\n",
    "from openai import OpenAI  # Keep this import for type hinting or other openai functions\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "label_encoder_path = \"../Models/wais_label_encoder.pkl\"\n",
    "model_path = \"../Models/wais_rf_model.pkl\"\n",
    "\n",
    "# -------------------- Utility Function --------------------\n",
    "\n",
    "def parse_embedding(embedding_str):\n",
    "    \"\"\"\n",
    "    Converts a string represenwaision of an embedding (from the CSV)\n",
    "    into a NumPy array.\n",
    "\n",
    "    Args:\n",
    "        embedding_str: The string represenwaision of the embedding.\n",
    "\n",
    "    Returns:\n",
    "        A NumPy array representing the embedding.\n",
    "    \"\"\"\n",
    "    return np.fromstring(embedding_str.strip(\"\"), sep=\", \")\n",
    "\n",
    "# -------------------- Embedding Function --------------------\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    \"\"\"\n",
    "    Generates an embedding for the given text using the OpenAI API.\n",
    "\n",
    "    Args:\n",
    "        text: The text to embed.\n",
    "        model: The name of the embedding model to use.\n",
    "\n",
    "    Returns:\n",
    "        The generated embedding as a list.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.embeddings.create(input=[text], model=model)\n",
    "        embedding = response.data[0].embedding\n",
    "        return embedding\n",
    "    except openai.OpenAIError as e:\n",
    "        print(f\"‚ùå OpenAI API error during embedding generation: {e}\")\n",
    "        raise\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=\"Step 7: Model Testing (Inference on New Data)\") as run:\n",
    "    try:\n",
    "        mlflow.log_param(\"Step\", \"Model Testing (Inference on New Data)\")\n",
    "        mlflow.log_artifact(label_encoder_path, artifact_path=\"label_encoder\")\n",
    "        mlflow.log_artifact(model_path, artifact_path=\"model\")\n",
    "\n",
    "        print(\"\\n--- Model Testing (Inference on New Data) ---\")\n",
    "\n",
    "        # Load the pre-fitted label encoder\n",
    "        try:\n",
    "            label_encoder = joblib.load(label_encoder_path)\n",
    "            print(f\"‚úÖ Label encoder loaded from: {label_encoder_path}\")\n",
    "        except FileNotFoundError:\n",
    "            mlflow.log_param(\"Error Type\", \"FileNotFoundError\")\n",
    "            mlflow.log_param(\n",
    "                \"Error\", f\"Label encoder not found at: {label_encoder_path}\"\n",
    "            )\n",
    "            print(f\"‚ùå Error: Label encoder not found at: {label_encoder_path}\")\n",
    "            raise\n",
    "\n",
    "        # Load the trained model\n",
    "        try:\n",
    "            loaded_clf = joblib.load(model_path)\n",
    "            print(f\"‚úÖ Trained model loaded from: {model_path}\")\n",
    "        except FileNotFoundError:\n",
    "            mlflow.log_param(\"Error Type\", \"FileNotFoundError\")\n",
    "            mlflow.log_param(\"Error\", f\"Model not found at: {model_path}\")\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            raise\n",
    "\n",
    "        # -------------------- Model Application/Inference --------------------\n",
    "\n",
    "        def predict_factor(new_text):\n",
    "            \"\"\"\n",
    "            Predicts the personality factor for new text using the trained model\n",
    "            and the saved label encoder.\n",
    "\n",
    "            Args:\n",
    "                new_text: The text to predict the personality factor for.\n",
    "\n",
    "            Returns:\n",
    "                The predicted personality factor.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                # Get the embedding for the new text\n",
    "                new_embedding = get_embedding(new_text)\n",
    "\n",
    "                # Predict the factor\n",
    "                predicted_factor_encoded = loaded_clf.predict([new_embedding])\n",
    "\n",
    "                # Decode the prediction using the label encoder\n",
    "                predicted_factor = label_encoder.inverse_transform(\n",
    "                    predicted_factor_encoded\n",
    "                )[0]\n",
    "\n",
    "                return predicted_factor\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå An error occurred during prediction: {e}\")\n",
    "                raise\n",
    "\n",
    "        # Example usage:\n",
    "        test_texts = [\n",
    "            \"I love going to parties and meeting new people.\",\n",
    "            \"I prefer staying home with a good book.\",\n",
    "            \"I often feel anxious and worried.\",\n",
    "            \"I am generally calm and relaxed.\",\n",
    "            \"I enjoy taking risks and trying new things.\"\n",
    "        ]\n",
    "        mlflow.log_param(\"Number of Test Inputs\", len(test_texts))\n",
    "\n",
    "        print(\"\\n--- Testing Model on New Data ---\")\n",
    "        for i, text in enumerate(test_texts):\n",
    "            try:\n",
    "                predicted_factor = predict_factor(text)\n",
    "                print(f\"Predicted Factor for '{text[:50]}...': {predicted_factor}\")\n",
    "                mlflow.log_param(f\"New Text {i+1}\", text)\n",
    "                mlflow.log_param(f\"Predicted Factor {i+1}\", predicted_factor)\n",
    "            except Exception as e:\n",
    "                mlflow.log_param(\"Error Type\", type(e).__name__)\n",
    "                mlflow.log_param(\n",
    "                    \"Error\", f\"Error predicting for text: {text[:50]}...: {e}\"\n",
    "                )\n",
    "                print(f\"‚ùå Error predicting for text: {text[:50]}...: {e}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"FileNotFoundError\")\n",
    "        mlflow.log_param(\"Error\", str(e))\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        mlflow.log_param(\"Error Type\", type(e).__name__)\n",
    "        mlflow.log_param(\"Error\", str(e))\n",
    "        print(f\"‚ùå An error occurred during model testing: {e}\")\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        mlflow.end_run()\n",
    "\n",
    "print(\"\\n‚úÖ Model testing (inference on new data) complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dc0d50-5e9f-4b73-bb5f-f8e64b2c1f62",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 9: Visualize and Evaluate Model** <a class=\"anchor\" id=\"wais_page_3\"></a>\n",
    "\n",
    "[Back to Top](#wais_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "02e69b18-6364-4067-98b8-4c144511dee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded embeddings from: ../Embeddings/wais_embeddings.csv\n",
      "‚è≥ Run started at 2025-05-24 22:42:31.973343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/05/24 22:42:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç In‚Äësample accuracy: 1.0000\n",
      "‚úÖ Run finished at 2025-05-24 22:42:34.777576 (Duration: 0:00:02.804233)\n",
      "\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "Perceptual Reasoning Index (PRI)       1.00      1.00      1.00        20\n",
      "    Processing Speed Index (PSI)       1.00      1.00      1.00        12\n",
      "Verbal Comprehension Index (VCI)       1.00      1.00      1.00        16\n",
      "      Working Memory Index (WMI)       1.00      1.00      1.00        12\n",
      "\n",
      "                        accuracy                           1.00        60\n",
      "                       macro avg       1.00      1.00      1.00        60\n",
      "                    weighted avg       1.00      1.00      1.00        60\n",
      "\n",
      "üèÉ View run WAIS Visualization & Eval at: http://127.0.0.1:5000/#/experiments/836008548927582795/runs/13b8ecf7eff547d89c2b02829d6993df\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/836008548927582795\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "#‚îÄ‚îÄ 1) Load embeddings with safe parsing ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "embeddings_csv_path = '../Embeddings/wais_embeddings.csv'\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        embeddings_csv_path,\n",
    "        converters={'Embedding': lambda s: np.array(ast.literal_eval(s)) if isinstance(s, str) else np.array(s)}\n",
    "    )\n",
    "    print(f\"‚úÖ Loaded embeddings from: {embeddings_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå File not found: {embeddings_csv_path}\")\n",
    "    exit(1)\n",
    "\n",
    "#‚îÄ‚îÄ 2) Prepare features and labels ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df['Embedding'].values)\n",
    "y = df['Index'].values                       # use 'Index' (VCI, PRI, WMI, PSI)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "#‚îÄ‚îÄ 3) Start MLflow run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"WAIS Visualization & Eval\") as run:\n",
    "    mlflow.log_param(\"step\", \"visualize_and_evaluate\")\n",
    "    mlflow.log_param(\"dataset\", embeddings_csv_path)\n",
    "    start_ts = datetime.now()\n",
    "    mlflow.log_param(\"start_time\", str(start_ts))\n",
    "    print(f\"‚è≥ Run started at {start_ts}\")\n",
    "\n",
    "    #‚îÄ‚îÄ 4) Train a RandomForest on full data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X, y_encoded)\n",
    "    mlflow.sklearn.log_model(clf, \"wais_rf_model\")\n",
    "\n",
    "    #‚îÄ‚îÄ 5) In‚Äësample evaluation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    y_pred = clf.predict(X)\n",
    "    acc = accuracy_score(y_encoded, y_pred)\n",
    "    mlflow.log_metric(\"in_sample_accuracy\", acc)\n",
    "    print(f\"üîç In‚Äësample accuracy: {acc:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(y_encoded, y_pred)\n",
    "    cm_df = pd.DataFrame(cm, index=le.classes_, columns=le.classes_)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"Confusion Matrix (In‚ÄëSample)\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    cm_img = \"wais_confusion_matrix.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cm_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cm_img, artifact_path=\"evaluation\")\n",
    "\n",
    "    #‚îÄ‚îÄ 6) PCA visualization ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    scatter = plt.scatter(X_pca[:,0], X_pca[:,1], c=y_encoded, cmap='viridis', alpha=0.7)\n",
    "    # correct legend call:\n",
    "    handles, _ = scatter.legend_elements()\n",
    "    plt.legend(handles, le.classes_, title=\"Index\")\n",
    "    plt.title(\"PCA of WAIS Embeddings\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    pca_img = \"wais_pca.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(pca_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(pca_img, artifact_path=\"visualization\")\n",
    "\n",
    "    #‚îÄ‚îÄ 7) K‚ÄëMeans clustering ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X)\n",
    "    df['Cluster'] = clusters\n",
    "    clustered_path = '../Embeddings/wais_clustered_embeddings.csv'\n",
    "    df.to_csv(clustered_path, index=False)\n",
    "    mlflow.log_artifact(clustered_path, artifact_path=\"clustered_data\")\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    scatter = plt.scatter(X_pca[:,0], X_pca[:,1], c=clusters, cmap='tab10', alpha=0.7)\n",
    "    plt.title(\"K‚ÄëMeans Clusters of WAIS Embeddings\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    cluster_img = \"wais_clusters.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cluster_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cluster_img, artifact_path=\"visualization\")\n",
    "\n",
    "    #‚îÄ‚îÄ 8) Log end time ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    end_ts = datetime.now()\n",
    "    mlflow.log_param(\"end_time\", str(end_ts))\n",
    "    print(f\"‚úÖ Run finished at {end_ts} (Duration: {end_ts - start_ts})\")\n",
    "\n",
    "    #‚îÄ‚îÄ 9) Optional: show classification report ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    report = classification_report(y_encoded, y_pred, target_names=le.classes_)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d6c46-cbed-44b1-acd1-f36a71195fca",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 10: Save Visualization and Evaluation of Model** <a class=\"anchor\" id=\"wais_page_3\"></a>\n",
    "\n",
    "[Back to Top](#wais_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b7e7cb8-ba04-4b99-b982-7dde60729478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded embeddings from: ../Embeddings/wais_embeddings.csv\n",
      "‚úÖ LabelEncoder loaded from: ../Models/wais_label_encoder.pkl\n",
      "‚úÖ RandomForest model loaded from: ../Models/wais_rf_model.pkl\n",
      "‚è≥ Run started at 2025-05-24 22:42:35.141554\n",
      "‚úÖ PCA plot saved: wais_pca.png\n",
      "‚úÖ Clustered data saved: wais_clustered_embeddings.csv\n",
      "‚úÖ Cluster plot saved: wais_clusters.png\n",
      "‚úÖ Run finished at 2025-05-24 22:42:35.271282 (Duration: 0:00:00.129728)\n",
      "üèÉ View run WAIS PCA & Clustering at: http://127.0.0.1:5000/#/experiments/836008548927582795/runs/c19ecbe9900640728cd4cf6e4965d9bd\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/836008548927582795\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import joblib\n",
    "import mlflow\n",
    "\n",
    "#‚îÄ‚îÄ 1) Paths ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "EMBEDDINGS_CSV = '../Embeddings/wais_embeddings.csv'\n",
    "LABEL_ENCODER_PKL = '../Models/wais_label_encoder.pkl'\n",
    "RF_MODEL_PKL = '../Models/wais_rf_model.pkl'\n",
    "\n",
    "#‚îÄ‚îÄ 2) Load embeddings and parse ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        EMBEDDINGS_CSV,\n",
    "        converters={'Embedding': lambda s: np.array(ast.literal_eval(s))}\n",
    "    )\n",
    "    print(f\"‚úÖ Loaded embeddings from: {EMBEDDINGS_CSV}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Embeddings CSV not found: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "#‚îÄ‚îÄ 3) Load artifacts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    label_encoder = joblib.load(LABEL_ENCODER_PKL)\n",
    "    print(f\"‚úÖ LabelEncoder loaded from: {LABEL_ENCODER_PKL}\")\n",
    "    rf_model = joblib.load(RF_MODEL_PKL)\n",
    "    print(f\"‚úÖ RandomForest model loaded from: {RF_MODEL_PKL}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Artifact missing: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "#‚îÄ‚îÄ 4) Prepare data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df['Embedding'].values)\n",
    "y = df['Index'].values                # use 'Index', not 'Factor'\n",
    "y_encoded = label_encoder.transform(y)\n",
    "\n",
    "#‚îÄ‚îÄ 5) Begin MLflow run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"WAIS PCA & Clustering\") as run:\n",
    "    mlflow.log_param(\"step\", \"PCA_and_KMeans\")\n",
    "    mlflow.log_param(\"embeddings_csv\", EMBEDDINGS_CSV)\n",
    "    start_ts = datetime.now()\n",
    "    mlflow.log_param(\"start_time\", str(start_ts))\n",
    "    print(f\"‚è≥ Run started at {start_ts}\")\n",
    "\n",
    "    #‚îÄ‚îÄ 6) PCA visualization ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    scatter = plt.scatter(X_pca[:,0], X_pca[:,1], c=y_encoded, cmap='viridis', alpha=0.7)\n",
    "    handles, _ = scatter.legend_elements()\n",
    "    plt.legend(handles, label_encoder.classes_, title=\"Index\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.title(\"PCA of WAIS Embeddings\")\n",
    "    plt.tight_layout()\n",
    "    pca_img = \"wais_pca.png\"\n",
    "    plt.savefig(pca_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(pca_img, artifact_path=\"visualization\")\n",
    "    print(f\"‚úÖ PCA plot saved: {pca_img}\")\n",
    "\n",
    "    #‚îÄ‚îÄ 7) K-Means clustering ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    n_clusters = 4\n",
    "    mlflow.log_param(\"n_clusters\", n_clusters)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X)\n",
    "    df['Cluster'] = clusters\n",
    "\n",
    "    clustered_csv = \"wais_clustered_embeddings.csv\"\n",
    "    df.to_csv(clustered_csv, index=False)\n",
    "    mlflow.log_artifact(clustered_csv, artifact_path=\"clustered_data\")\n",
    "    print(f\"‚úÖ Clustered data saved: {clustered_csv}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    scatter = plt.scatter(X_pca[:,0], X_pca[:,1], c=clusters, cmap='tab10', alpha=0.7)\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.title(\"K-Means Clusters of WAIS Embeddings\")\n",
    "    plt.tight_layout()\n",
    "    cluster_img = \"wais_clusters.png\"\n",
    "    plt.savefig(cluster_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cluster_img, artifact_path=\"visualization\")\n",
    "    print(f\"‚úÖ Cluster plot saved: {cluster_img}\")\n",
    "\n",
    "    #‚îÄ‚îÄ 8) Model inference demo (optional) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    # Using the loaded rf_model on the PCA features, if desired\n",
    "    # pred = rf_model.predict(X)\n",
    "    # print(\"Demo predictions:\", label_encoder.inverse_transform(pred[:5]))\n",
    "\n",
    "    #‚îÄ‚îÄ 9) End run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    end_ts = datetime.now()\n",
    "    mlflow.log_param(\"end_time\", str(end_ts))\n",
    "    print(f\"‚úÖ Run finished at {end_ts} (Duration: {end_ts - start_ts})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013ba63c-ce13-4667-a5d9-a799ab883b97",
   "metadata": {},
   "source": [
    "This block of code integrates several stages that not only include training but also applying the model to new data and exploring the data through clustering:\n",
    "1. **Data Loading and Feature Parsing**: Similar to Block 1, with an additional step of displaying the parsed data.\n",
    "2. **Model Creation and Logging**: Training a RandomForestClassifier and logging the model directly with MLflow for possibly immediate deployment.\n",
    "3. **Model Evaluation and Reporting**: Assessing model performance with metrics and detailed reports, and logging these evaluations.\n",
    "4. **Clustering Analysis**: Utilizing KMeans to perform clustering on the embeddings, which adds an exploratory data analysis component.\n",
    "5. **Model Application on New Data**: Demonstrating a practical application of the trained model to predict factors for new text inputs.\n",
    "6. **End-to-End Experiment Tracking**: From the beginning of the run to its completion, tracking all parameters, artifacts, and outcomes, emphasizing a full-cycle view of the modeling process.\n",
    "\n",
    "This provides a broader overview of how a model can be developed and applied within a workflow that includes prediction and clustering alongside the fundamental steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f3cfce-24bd-4f6c-a748-54b1fe39d107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5916893-8b0f-450f-9ce6-09015901f5eb",
   "metadata": {},
   "source": [
    "The results show that the RandomForestClassifier model trained on the dataset of embeddings has achieved an accuracy of 1.0 on the test set, which means it has correctly classified all the test samples. Here is the breakdown of the evaluation:\n",
    "\n",
    "### Accuracy:\n",
    "- **1.0**: The model has 100% accuracy, meaning it correctly classified every instance in the test set.\n",
    "\n",
    "### Classification Report:\n",
    "- **Precision, Recall, and F1-score** for each class (0 through 4) are all 1.00.\n",
    "- **Support** indicates the number of actual occurrences of each class in the test set.\n",
    "\n",
    "### Interprewaision:\n",
    "- **Precision**: This is the ratio of true positive predictions to the total predicted positives. A precision of 1.0 means that all instances predicted as a specific class were actually of that class.\n",
    "- **Recall**: This is the ratio of true positive predictions to the total actual positives. A recall of 1.0 means that all actual instances of a specific class were correctly predicted.\n",
    "- **F1-score**: This is the harmonic mean of precision and recall. An F1-score of 1.0 indicates perfect precision and recall.\n",
    "- **Support**: This indicates the number of true instances for each label in the test set. \n",
    "\n",
    "### Considerations:\n",
    "1. **Model Overfitting**: The perfect score could indicate overfitting, especially if the test set is small or not represenwaisive of unseen data.\n",
    "2. **Test Set Size**: The test set has only 24 samples, which is relatively small. It's important to ensure that the test set is large enough and represenwaisive to get a reliable estimate of model performance.\n",
    "3. **Data Leakage**: Double-check that there's no data leakage, meaning that no information from the test set was used during training.\n",
    "4. **Cross-Validation**: To better assess the model's performance, consider using cross-validation to ensure the model performs well across different subsets of the data.\n",
    "\n",
    "### Next Steps:\n",
    "- **Cross-validation**: Implement cross-validation to get a more robust evaluation of model performance.\n",
    "- **Larger Test Set**: If possible, increase the size of the test set to ensure the performance metrics are reliable.\n",
    "- **Feature Analysis**: Examine feature importance scores from the RandomForestClassifier to understand which parts of the embeddings contribute most to the predictions.\n",
    "\n",
    "### Updated Code for Cross-Validation:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(clf, X, y_encoded, cv=5)  # 5-fold cross-validation\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean cross-validation score: {np.mean(cv_scores)}\")\n",
    "```\n",
    "\n",
    "We added this cross-validation step will help us verify that the model generalizes well and is not just performing well on a small or potentially non-represenwaisive test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16fac8dd-46d3-4595-99f0-f15b83e244a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Mean cross-validation score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(clf, X, y_encoded, cv=5)  # 5-fold cross-validation\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean cross-validation score: {np.mean(cv_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "adf2f5ea-3181-4f0f-8a62-c95784cac78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 60 rows from ../Embeddings/wais_embeddings.csv\n",
      "‚úÖ PCA plot saved: wais_embeddings_pca.png\n",
      "‚úÖ Clustered data saved: wais_clustered_embeddings.csv\n",
      "‚úÖ Cluster plot saved: wais_clusters.png\n",
      "‚úÖ Cross‚Äëval scores (5‚Äëfold): [1. 1. 1. 1. 1.]\n",
      "‚úÖ Step 9 complete.\n",
      "üèÉ View run Step 9: Model Application, Visualization, and Analysis at: http://127.0.0.1:5000/#/experiments/836008548927582795/runs/11bff2aed2394051b6039d974e748ede\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/836008548927582795\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import joblib\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî Load environment (if needed) ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî Paths & Helpers ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "EMBEDDINGS_CSV     = '../Embeddings/wais_embeddings.csv'\n",
    "LABEL_ENCODER_PKL  = '../Models/wais_label_encoder.pkl'\n",
    "RF_MODEL_PKL       = '../Models/wais_rf_model.pkl'\n",
    "\n",
    "def parse_embedding(embedding_str):\n",
    "    try:\n",
    "        return np.array(ast.literal_eval(embedding_str))\n",
    "    except Exception:\n",
    "        return np.array([])\n",
    "\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî Main Run ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "with mlflow.start_run(run_name=\"Step 9: Model Application, Visualization, and Analysis\"):\n",
    "\n",
    "    # Log inputs\n",
    "    mlflow.log_param(\"embeddings_csv\", EMBEDDINGS_CSV)\n",
    "    mlflow.log_param(\"label_encoder_pkl\", LABEL_ENCODER_PKL)\n",
    "    mlflow.log_param(\"rf_model_pkl\",      RF_MODEL_PKL)\n",
    "\n",
    "    # ---- 1. Load embeddings DataFrame ----\n",
    "    df = pd.read_csv(EMBEDDINGS_CSV, converters={'Embedding': parse_embedding})\n",
    "    print(f\"‚úÖ Loaded {len(df)} rows from {EMBEDDINGS_CSV}\")\n",
    "\n",
    "    # Stack into X, extract raw labels y\n",
    "    X = np.stack(df['Embedding'].values)\n",
    "    raw_labels = df['Index'].values   # use 'Index' instead of 'Factor'\n",
    "\n",
    "    # ---- 2. Load artifacts ----\n",
    "    label_encoder = joblib.load(LABEL_ENCODER_PKL)\n",
    "    rf_clf         = joblib.load(RF_MODEL_PKL)\n",
    "\n",
    "    # Encode labels\n",
    "    y = label_encoder.transform(raw_labels)\n",
    "\n",
    "    # ---- 3. PCA Visualization ----\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', alpha=0.7)\n",
    "    handles, _ = scatter.legend_elements()\n",
    "    plt.legend(handles, label_encoder.classes_, title=\"Index\")\n",
    "    plt.xlabel(\"PCA Component 1\")\n",
    "    plt.ylabel(\"PCA Component 2\")\n",
    "    plt.title(\"PCA of WAIS Embeddings\")\n",
    "    pca_plot = \"wais_embeddings_pca.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(pca_plot)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(pca_plot, artifact_path=\"visualization\")\n",
    "    print(f\"‚úÖ PCA plot saved: {pca_plot}\")\n",
    "\n",
    "    # ---- 4. K‚ÄëMeans Clustering ----\n",
    "    n_clusters = 5\n",
    "    mlflow.log_param(\"n_clusters\", n_clusters)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X)\n",
    "    df['Cluster'] = clusters\n",
    "\n",
    "    clustered_csv = \"wais_clustered_embeddings.csv\"\n",
    "    df.to_csv(clustered_csv, index=False)\n",
    "    mlflow.log_artifact(clustered_csv, artifact_path=\"clustering\")\n",
    "    print(f\"‚úÖ Clustered data saved: {clustered_csv}\")\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='tab10', alpha=0.7)\n",
    "    plt.xlabel(\"PCA Component 1\")\n",
    "    plt.ylabel(\"PCA Component 2\")\n",
    "    plt.title(\"K‚ÄëMeans Clusters of WAIS Embeddings\")\n",
    "    cluster_plot = \"wais_clusters.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cluster_plot)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cluster_plot, artifact_path=\"visualization\")\n",
    "    print(f\"‚úÖ Cluster plot saved: {cluster_plot}\")\n",
    "\n",
    "    # ---- 5. Safe Stratified CV ----\n",
    "    min_count    = df['Index'].value_counts().min()\n",
    "    safe_splits  = min(5, min_count)\n",
    "    mlflow.log_param(\"safe_n_splits\", safe_splits)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=safe_splits, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(rf_clf, X, y, cv=cv, scoring='accuracy')\n",
    "    mlflow.log_metric(\"cv_mean_accuracy\", np.mean(cv_scores))\n",
    "    print(f\"‚úÖ Cross‚Äëval scores ({safe_splits}‚Äëfold): {cv_scores}\")\n",
    "\n",
    "    # ---- 6. Finish ----\n",
    "    print(\"‚úÖ Step 9 complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d8667c-30e8-4db0-8fca-03ccb53d773e",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 11: Test Model Directly** <a class=\"anchor\" id=\"wais_page_3\"></a>\n",
    "\n",
    "[Back to Top](#wais_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d8b6c39-c12d-4076-95e4-692d7a89371d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 60 rows\n",
      "Predicted Index for 'Active Energetic Activate Activator': Perceptual Reasoning Index (PRI)\n",
      "Predicted Index for 'Calm Relaxed Soothing Pacify': Verbal Comprehension Index (VCI)\n",
      "Predicted Index for 'Curious Inquisitive Explore Investigator': Verbal Comprehension Index (VCI)\n",
      "Predicted Index for 'Organized Meticulous Plan Planner': Processing Speed Index (PSI)\n",
      "Predicted Index for 'Moody Anxious Worry Worrier': Perceptual Reasoning Index (PRI)\n",
      "Predicted Index for 'Unfriendly Stoic Indifferent Apathetic': Verbal Comprehension Index (VCI)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import joblib\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment & OpenAI client\n",
    "load_dotenv(override=True)\n",
    "def get_openai_api_key_from_file(filepath='~/openai_api_key.txt'):\n",
    "    filepath = os.path.expanduser(filepath)\n",
    "    with open(filepath) as f:\n",
    "        return f.read().strip()\n",
    "api_key = get_openai_api_key_from_file()\n",
    "client  = OpenAI(api_key=api_key)\n",
    "\n",
    "# Load the embeddings CSV, parsing the string back into arrays\n",
    "df = pd.read_csv(\n",
    "    '../Embeddings/wais_embeddings.csv',\n",
    "    converters={'Embedding': lambda s: np.array(ast.literal_eval(s))}\n",
    ")\n",
    "print(f\"‚úÖ Loaded {len(df)} rows\")\n",
    "\n",
    "# Stack embeddings & extract the correct label column 'Index'\n",
    "X = np.stack(df['Embedding'].values)\n",
    "y = df['Index'].values       # was 'Factor' before ‚Äî use 'Index'\n",
    "\n",
    "# Load pretrained artifacts\n",
    "label_encoder = joblib.load('../Models/wais_label_encoder.pkl')\n",
    "clf           = joblib.load('../Models/wais_rf_model.pkl')\n",
    "\n",
    "# Function to get OpenAI embedding for new text\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    resp = client.embeddings.create(input=[text], model=model)\n",
    "    return resp.data[0].embedding\n",
    "\n",
    "# Prediction helper\n",
    "def predict_factor(new_text):\n",
    "    emb = get_embedding(new_text)\n",
    "    encoded = clf.predict([emb])[0]\n",
    "    return label_encoder.inverse_transform([encoded])[0]\n",
    "\n",
    "# Test on new examples\n",
    "test_texts = [\n",
    "    \"Active Energetic Activate Activator\",\n",
    "    \"Calm Relaxed Soothing Pacify\",\n",
    "    \"Curious Inquisitive Explore Investigator\",\n",
    "    \"Organized Meticulous Plan Planner\",\n",
    "    \"Moody Anxious Worry Worrier\",\n",
    "    \"Unfriendly Stoic Indifferent Apathetic\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    pred = predict_factor(text)\n",
    "    print(f\"Predicted Index for '{text}': {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "449f69a9-6e81-4d46-9b38-f7507243338c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Factor for 'Curious': Perceptual Reasoning Index (PRI)\n"
     ]
    }
   ],
   "source": [
    "# Test a single word or phrase\n",
    "test_text = \"Curious\"\n",
    "predicted_factor = predict_factor(test_text)\n",
    "print(f\"Predicted Factor for '{test_text}': {predicted_factor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6dba3c2-f6e1-4e26-a4c8-a0cc084763d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Factor for 'afraid': Verbal Comprehension Index (VCI)\n"
     ]
    }
   ],
   "source": [
    "# Test a single word or phrase\n",
    "test_text = \"afraid\"\n",
    "predicted_factor = predict_factor(test_text)\n",
    "print(f\"Predicted Factor for '{test_text}': {predicted_factor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6753f1a4-6f8b-499d-a267-9ee80d8fe097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Factor for 'scared': Processing Speed Index (PSI)\n"
     ]
    }
   ],
   "source": [
    "# Test a single word or phrase\n",
    "test_text = \"scared\"\n",
    "predicted_factor = predict_factor(test_text)\n",
    "print(f\"Predicted Factor for '{test_text}': {predicted_factor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89969172-6939-4347-a76b-bb8402e26584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Factor for 'sad': Processing Speed Index (PSI)\n"
     ]
    }
   ],
   "source": [
    "# Test a single word or phrase\n",
    "test_text = \"sad\"\n",
    "predicted_factor = predict_factor(test_text)\n",
    "print(f\"Predicted Factor for '{test_text}': {predicted_factor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed4e3183-7ca6-4f8f-94cd-cc5e8e9f6244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Factor for 'unemotional': Processing Speed Index (PSI)\n"
     ]
    }
   ],
   "source": [
    "# Test a single word or phrase\n",
    "test_text = \"unemotional\"\n",
    "predicted_factor = predict_factor(test_text)\n",
    "print(f\"Predicted Factor for '{test_text}': {predicted_factor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab54c21-ee36-4c0e-b9c4-445b11fa65ed",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 12: Test Neo4j Connection** <a class=\"anchor\" id=\"WAIS_page_4\"></a>\n",
    "\n",
    "\n",
    "[Back to Top](#WAIS_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce3fd307-5fcf-46d7-867d-78ecd5a83887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://localhost:7474/browser/\" target=\"_blank\">üîó Open Neo4j Bolt Connection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Define Neo4j Browser URL\n",
    "neo4j_browser_url = \"http://localhost:7474/browser/\"\n",
    "\n",
    "# Create a clickable link\n",
    "html_code = f'<a href=\"{neo4j_browser_url}\" target=\"_blank\">üîó Open Neo4j Bolt Connection</a>'\n",
    "\n",
    "# Display the clickable link in Jupyter Notebook\n",
    "display(HTML(html_code))\n",
    "\n",
    "# Open the Neo4j Browser in a new tab automatically\n",
    "webbrowser.open_new_tab(neo4j_browser_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a12796f0-11cb-40cb-8c48-e9e20760ed42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bolt port 7687 is reachable!\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "HOST = \"localhost\"\n",
    "PORT = 7687\n",
    "\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "result = sock.connect_ex((HOST, PORT))\n",
    "\n",
    "if result == 0:\n",
    "    print(f\"‚úÖ Bolt port {PORT} is reachable!\")\n",
    "else:\n",
    "    print(f\"‚ùå Bolt port {PORT} is NOT reachable!\")\n",
    "\n",
    "sock.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3abeb19a-7681-4c01-bb52-3b567513142a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Python Connected Successfully: Connection successful!\n"
     ]
    }
   ],
   "source": [
    "from py2neo import Graph\n",
    "\n",
    "# Attempt connection with neo4j://\n",
    "NEO4J_URI = \"neo4j://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"mypassword\"\n",
    "\n",
    "try:\n",
    "    graph = Graph(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    result = graph.run(\"RETURN 'Connection successful!' AS message\").data()\n",
    "    print(\"‚úÖ Python Connected Successfully:\", result[0][\"message\"])\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Python Connection Failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54f9b222-dd9d-4205-b4ab-3221085fbe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n",
      "üèÉ View run Test Neo4j Connection at: http://127.0.0.1:5000/#/experiments/836008548927582795/runs/de3930818c5c498ba632574b49d35700\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/836008548927582795\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from py2neo import Graph\n",
    "import mlflow\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# MLflow and Neo4j connection settings\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "\n",
    "# Set the MLflow tracking URI\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "# Set an experiment name\n",
    "mlflow.set_experiment(\"WAIS\")\n",
    "#mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Function to test database connection\n",
    "def test_neo4j_connection(uri, user, password):\n",
    "    try:\n",
    "        # Connect to Neo4j\n",
    "        graph = Graph(uri, auth=(user, password))\n",
    "        # Run a simple query to test the connection\n",
    "        greeting = graph.run(\"RETURN 'Connection successful!' AS greeting\").data()\n",
    "        return greeting[0]['greeting']\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Start an MLFlow run\n",
    "with mlflow.start_run(run_name=\"Test Neo4j Connection\"):\n",
    "    # Log the test start\n",
    "    mlflow.log_param(\"Test\", \"Neo4j Connection\")\n",
    "    \n",
    "    # Test the Neo4j database connection\n",
    "    result = test_neo4j_connection(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
    "    \n",
    "    # Log the result of the connection test\n",
    "    mlflow.log_param(\"Connection Result\", result)\n",
    "    \n",
    "    # Output the result\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0ce307e-9ad1-4891-9f4f-8966af9ce07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Connection test result: Connection successful!\n",
      "üóëÔ∏è  All nodes and relationships have been deleted.\n",
      "üìä Remaining node count after clear: 0\n",
      "üèÉ View run Test & Clear Neo4j at: http://127.0.0.1:5000/#/experiments/616263351584470447/runs/e525d369827c4f30874ca967f0dc61a1\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/616263351584470447\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from py2neo import Graph\n",
    "import mlflow\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Neo4j connection settings\n",
    "NEO4J_URI      = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USER     = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "# MLflow tracking\n",
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(\"MCMI\")\n",
    "\n",
    "def test_neo4j_connection(uri, user, password):\n",
    "    graph = Graph(uri, auth=(user, password))\n",
    "    return graph.run(\"RETURN 'Connection successful!' AS greeting\").evaluate()\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=\"Test & Clear Neo4j\"):\n",
    "\n",
    "    # 1) Test connection\n",
    "    result = test_neo4j_connection(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
    "    mlflow.log_param(\"Connection Test\", result)\n",
    "    print(f\"üîó Connection test result: {result}\")\n",
    "\n",
    "    # 2) Clear the entire database (nodes + relationships)\n",
    "    graph = Graph(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    graph.delete_all()\n",
    "    mlflow.log_param(\"Database Cleared\", True)\n",
    "    print(\"üóëÔ∏è  All nodes and relationships have been deleted.\")\n",
    "\n",
    "    # 3) (Optional) Confirm it's empty\n",
    "    remaining = graph.run(\"MATCH (n) RETURN count(n) AS nodes\").evaluate()\n",
    "    mlflow.log_param(\"Remaining Nodes\", remaining)\n",
    "    print(f\"üìä Remaining node count after clear: {remaining}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a2d41d-2f56-4b50-b4b1-77ebcd2c7279",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 13: Create WAIS Schema in Neo4j** <a class=\"anchor\" id=\"WAIS_page_4\"></a>\n",
    "\n",
    "\n",
    "[Back to Top](#WAIS_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "957e5833-d44d-401d-8df7-0b430efac4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ WAIS schema built with the full Index‚ÜíFactor‚ÜíAdjective hierarchy.\n",
      "üèÉ View run Create WAIS Schema in Neo4j at: http://127.0.0.1:5000/#/experiments/836008548927582795/runs/1b2fd630500d4cf184c24e523c9e23f5\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/836008548927582795\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from py2neo import Graph\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Load environment ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "NEO4J_URI      = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USER     = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "MLFLOW_URI     = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "mlflow.set_experiment(\"WAIS\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Read the original flattened dataset (with Description) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "flat_path  = \"../Datasets/wais.csv\"\n",
    "flat_df    = pd.read_csv(flat_path)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Read the embeddings (no Description) and rehydrate from flat_df ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "emb_path   = \"../Embeddings/wais_embeddings.csv\"\n",
    "emb_df     = pd.read_csv(\n",
    "    emb_path,\n",
    "    converters={'Embedding': lambda x: ast.literal_eval(x) if isinstance(x, str) else x}\n",
    ")\n",
    "\n",
    "# Merge on the five identifying columns so we recover Description\n",
    "wais_df = (\n",
    "    emb_df\n",
    "    .merge(\n",
    "        flat_df[['Index','Subtest','Description','Synonym','Verb','Noun']],\n",
    "        on=['Index','Subtest','Synonym','Verb','Noun'],\n",
    "        how='left'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Optionally check for any unmatched rows:\n",
    "missing_desc = wais_df['Description'].isna().sum()\n",
    "if missing_desc:\n",
    "    raise RuntimeError(f\"{missing_desc} embedding rows failed to merge a Description!\")\n",
    "\n",
    "def create_wais_schema(graph: Graph, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Build Neo4j graph with taxonomy:\n",
    "      WAIS_Index -> WAIS_Factor -> WAIS_Adjective -> {Synonym, Verb, Noun, Embedding}\n",
    "    \"\"\"\n",
    "    for _, row in df.iterrows():\n",
    "        idx       = row['Index']\n",
    "        factor    = row['Subtest']\n",
    "        adjective = row['Description']\n",
    "        synonym   = row['Synonym']\n",
    "        verb      = row['Verb']\n",
    "        noun      = row['Noun']\n",
    "        embedding = row.get('Embedding') or []\n",
    "\n",
    "        # Skip if we still somehow missed the Description\n",
    "        if pd.isna(adjective) or not (idx and factor and adjective):\n",
    "            continue\n",
    "\n",
    "        # 1) MERGE Index\n",
    "        graph.run(\"MERGE (i:WAIS_Index {name:$idx})\", idx=idx)\n",
    "\n",
    "        # 2) MERGE Factor + link to Index\n",
    "        graph.run(\"MERGE (f:WAIS_Factor {name:$factor})\", factor=factor)\n",
    "        graph.run(\n",
    "            \"\"\"\n",
    "            MATCH (i:WAIS_Index {name:$idx}), (f:WAIS_Factor {name:$factor})\n",
    "            MERGE (i)-[:WAIS_HAS_FACTOR]->(f)\n",
    "            \"\"\",\n",
    "            idx=idx, factor=factor\n",
    "        )\n",
    "\n",
    "        # 3) MERGE Adjective + link to Factor\n",
    "        graph.run(\"MERGE (a:WAIS_Adjective {name:$adjective})\", adjective=adjective)\n",
    "        graph.run(\n",
    "            \"\"\"\n",
    "            MATCH (f:WAIS_Factor {name:$factor}), (a:WAIS_Adjective {name:$adjective})\n",
    "            MERGE (f)-[:WAIS_HAS_ADJECTIVE]->(a)\n",
    "            \"\"\",\n",
    "            factor=factor, adjective=adjective\n",
    "        )\n",
    "\n",
    "        # 4) MERGE Synonym, Verb, Noun under Adjective\n",
    "        if synonym:\n",
    "            graph.run(\"MERGE (s:WAIS_Synonym {name:$synonym})\", synonym=synonym)\n",
    "            graph.run(\n",
    "                \"\"\"\n",
    "                MATCH (a:WAIS_Adjective {name:$adjective}), (s:WAIS_Synonym {name:$synonym})\n",
    "                MERGE (a)-[:WAIS_HAS_SYNONYM]->(s)\n",
    "                \"\"\",\n",
    "                adjective=adjective, synonym=synonym\n",
    "            )\n",
    "        if verb:\n",
    "            graph.run(\"MERGE (v:WAIS_Verb {name:$verb})\", verb=verb)\n",
    "            graph.run(\n",
    "                \"\"\"\n",
    "                MATCH (a:WAIS_Adjective {name:$adjective}), (v:WAIS_Verb {name:$verb})\n",
    "                MERGE (a)-[:WAIS_HAS_VERB]->(v)\n",
    "                \"\"\",\n",
    "                adjective=adjective, verb=verb\n",
    "            )\n",
    "        if noun:\n",
    "            graph.run(\"MERGE (n:WAIS_Noun {name:$noun})\", noun=noun)\n",
    "            graph.run(\n",
    "                \"\"\"\n",
    "                MATCH (a:WAIS_Adjective {name:$adjective}), (n:WAIS_Noun {name:$noun})\n",
    "                MERGE (a)-[:WAIS_HAS_NOUN]->(n)\n",
    "                \"\"\",\n",
    "                adjective=adjective, noun=noun\n",
    "            )\n",
    "\n",
    "        # 5) Attach Embedding to the Adjective\n",
    "        if embedding:\n",
    "            graph.run(\n",
    "                \"\"\"\n",
    "                MATCH (a:WAIS_Adjective {name:$adjective})\n",
    "                MERGE (e:WAIS_Embedding {value:$embedding})\n",
    "                MERGE (a)-[:WAIS_HAS_EMBEDDING]->(e)\n",
    "                \"\"\",\n",
    "                adjective=adjective, embedding=embedding\n",
    "            )\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Execute under MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"Create WAIS Schema in Neo4j\"):\n",
    "    graph = Graph(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    create_wais_schema(graph, wais_df)\n",
    "\n",
    "    mlflow.log_artifact(emb_path, artifact_path=\"embeddings\")\n",
    "    mlflow.log_param(\"rows\", wais_df.shape[0])\n",
    "    mlflow.log_param(\"cols\", wais_df.shape[1])\n",
    "    print(\"‚úÖ WAIS schema built with the full Index‚ÜíFactor‚ÜíAdjective hierarchy.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746cc0fc-8e2f-4f59-b0e8-75b663e2802b",
   "metadata": {},
   "source": [
    "```cypher\n",
    "MATCH (n)-[r]->(m)\n",
    "WHERE (n:WAIS_Factor OR n:WAIS_Adjective OR n:WAIS_Synonym OR n:WAIS_Verb OR n:WAIS_Noun)\n",
    "AND NOT m:WAIS_Embedding\n",
    "RETURN n, r, m\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca5e75-3b9b-45a1-997b-a5fe4b4b4d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
