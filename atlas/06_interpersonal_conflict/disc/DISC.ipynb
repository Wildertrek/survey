{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8280398-f9ab-41f9-9c7e-8a3e39337d72",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "## Everything DiSC Workplace Profile (DISC)<a class=\"anchor\" id=\"PTMD_page_22\"></a>\n",
    "\n",
    "[Back to Top](#PTMD_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaec26f-e178-427d-84a6-dbd9f455096a",
   "metadata": {},
   "source": [
    "The **Everything DiSC Workplace Profile**, commonly referred to as **DiSC**, is a prominent and widely utilized personality assessment tool designed to enhance self-awareness, improve communication, and promote effective teamwork within workplaces. Rooted in psychological theories, this assessment categorizes individuals into distinct behavioral styles, enabling them to better understand themselves and their interactions with others.\n",
    "\n",
    "**Key Features and Purpose:**\n",
    "\n",
    "1. **Four Primary Behavioral Styles:** The DiSC assessment classifies individuals into four primary behavioral styles based on their natural tendencies and preferences. These styles are:\n",
    "   - **Dominance (D):** Individuals with dominant traits tend to be assertive, results-oriented, and direct in their approach.\n",
    "   - **Influence (i):** People with influential traits are sociable, persuasive, and enthusiastic, often seeking social interactions and engagement.\n",
    "   - **Steadiness (S):** Steadiness-oriented individuals are cooperative, stable, and patient, valuing harmonious relationships and reliability.\n",
    "   - **Conscientiousness (C):** Those with conscientious traits are analytical, precise, and detail-oriented, prioritizing accuracy and thoroughness.\n",
    "\n",
    "2. **Personalized Profiles:** After completing the assessment, individuals receive personalized DiSC profiles, highlighting their dominant style and providing insights into their communication preferences, work tendencies, and strengths.\n",
    "\n",
    "3. **Enhanced Self-awareness:** DiSC profiles encourage individuals to reflect on their behavioral tendencies, helping them gain a deeper understanding of their own strengths and areas for growth.\n",
    "\n",
    "4. **Improved Communication:** By recognizing their own style and the styles of others, individuals can adapt their communication approaches to be more effective in various interpersonal and professional situations.\n",
    "\n",
    "5. **Team Development:** DiSC is often used in team-building exercises to create more cohesive and harmonious work environments. Team members can understand each other's styles and work together more effectively.\n",
    "\n",
    "6. **Leadership Development:** The assessment is valuable in leadership development programs, helping leaders understand their leadership style and how it impacts their teams.\n",
    "\n",
    "**Practical Applications:**\n",
    "\n",
    "- **Team Building:** DiSC assessments are commonly employed in team-building workshops to foster better collaboration and understanding among team members.\n",
    "\n",
    "- **Leadership Development:** Organizations use DiSC to identify and develop leadership skills among employees, tailoring leadership training to individual styles.\n",
    "\n",
    "- **Conflict Resolution:** DiSC profiles can aid in conflict resolution by helping individuals understand the perspectives and communication preferences of others.\n",
    "\n",
    "- **Sales and Customer Service Training:** DiSC assessments are beneficial in sales and customer service training, allowing professionals to adapt their approaches to various customer styles effectively.\n",
    "\n",
    "- **Personal Development:** Many individuals use DiSC assessments for personal development, gaining insights into their own behavior and interpersonal skills.\n",
    "\n",
    "In summary, the Everything DiSC Workplace Profile (DiSC) is a powerful personality assessment tool that categorizes individuals into four primary behavioral styles: Dominance, Influence, Steadiness, and Conscientiousness. It promotes self-awareness, improved communication, and effective teamwork in various professional settings. With applications ranging from team building to leadership development and conflict resolution, DiSC offers valuable insights into human behavior and interactions, contributing to more productive and harmonious workplaces.\n",
    "\n",
    "Timeline and reference table for the Everything DiSC Workplace Profile, part of the broader DISC assessment framework, involves outlining the key developments of this personality assessment tool. DISC, based on William Moulton Marston's model, categorizes behavior into four types‚ÄîDominance, Influence, Steadiness, and Conscientiousness. Here's a hypothetical timeline and reference table:\n",
    "\n",
    "| Year         | Milestone                                 | Contributor(s)                     | Original Work Reference                                    | Key Contributions                                                                     | Additional Information                                                              |\n",
    "|--------------|-------------------------------------------|-------------------------------------|-----------------------------------------------------------|-------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------|\n",
    "| 1928         | Conceptual Foundations of DISC.           | William Moulton Marston            | Marston, W. M. (1928). \"Emotions of Normal People\".        | Introduction of the DISC theory, identifying four primary emotions and associated behavioral responses. | Marston‚Äôs work laid the theoretical groundwork for future DISC assessments, although he did not create an assessment himself. |\n",
    "| 1950s-1970s  | Development of DISC Assessment Tools.     | Various Psychologists              | Creation of various assessment tools based on Marston‚Äôs DISC theory. | Operationalization of Marston's theory into practical assessment tools for understanding personality and behavior in various contexts. | These tools were precursors to the modern Everything DiSC assessments. |\n",
    "| 2000s        | Introduction of Everything DiSC Workplace Profile. | Wiley (formerly Inscape Publishing) | Development of the Everything DiSC Workplace Profile.    | Provided a more detailed and nuanced application of the DISC model specifically for workplace settings. | Emphasized practical applications of DISC in improving workplace communication, teamwork, and leadership. |\n",
    "| 2010s-Present | Ongoing Development and Application.    | Various Organizational Development Experts | Continuous research, updates, and adaptations of the Everything DiSC Workplace Profile. | Further refinement of the assessment for contemporary organizational challenges and diverse work environments. | Reflects the evolving nature of workplace dynamics and the continuous relevance of DISC in organizational development. |\n",
    "\n",
    "This table provides an overview of the major developments in the Everything DiSC Workplace Profile and the broader DISC assessment framework, highlighting key contributions and milestones. Each row represents a significant event in the history of DISC, detailing the year, milestone, contributors, original work references, key contributions, and additional information.\n",
    "\n",
    "The Everything DiSC Workplace Profile, as part of the larger DISC framework, has been instrumental in helping organizations understand and leverage personality differences for effective communication, team building, and leadership development. Its ongoing evolution reflects its adaptability to modern workplace challenges.\n",
    "\n",
    "### DiSC Workplace Profile\n",
    "\n",
    "| **#** | **Author(s)**                                  | **Year** | **Title**                                                                | **Journal/Source**                   | **Volume** | **Pages**   | **DOI/URL**                                       |\n",
    "|-------|-----------------------------------------------|----------|-------------------------------------------------------------------------|---------------------------------------|------------|-------------|--------------------------------------------------|\n",
    "| 1     | W. Marston                                   | N/A      | Emotions of normal people                                               | -                                     | -          | -           | [DOI](https://doi.org/10.1037/13390-000)         |\n",
    "| 2     | M. McKenna, C. Shelton, J. Darling           | 2002     | The impact of behavioral style assessment on organizational effectiveness: A call for action | Leadership & Organization Development Journal | 23 | 314-322 | [DOI](https://doi.org/10.1108/01437730210441274) |\n",
    "| 3     | J. Bruening, R. Madsen, J. M. Evanovich, R. D. Fuller | 2010 | Discovery, Integration, Application and Teaching: Service Learning through Sport and Physical Activity | Sport Management Education Journal | 4 | 31-48 | [DOI](https://doi.org/10.1123/SMEJ.4.1.31) |\n",
    "| 4     | M. Scarbecz                                  | 2007     | Using the DISC system to motivate dental patients                       | Journal of the American Dental Association | 138 | 381-385 | [DOI](https://doi.org/10.14219/JADA.ARCHIVE.2007.0171) |\n",
    "| 5     | M. Renaud, C. M. Rutledge, L. Shepherd       | 2012     | Preparing emotionally intelligent doctor of nursing practice leaders    | The Journal of Nursing Education     | 51         | 454-460     | [DOI](https://doi.org/10.3928/01484834-20120523-03) |\n",
    "| 6     | N. Eather, L. Fray, J. Gore                   | 2020     | Who wants to be a sportsperson? Student aspirations for sporting careers | Sport, Education and Society         | 25         | 1072-1085   | [DOI](https://doi.org/10.1080/13573322.2019.1679104) |\n",
    "| 7     | B. W. Horton, I. Clarke, S. D. Welpott       | 2005     | Applying the MBTI¬Æ to Hospitality Education                             | Journal of Hospitality & Tourism Education | 17 | 36-45 | [DOI](https://doi.org/10.1080/10963758.2005.10696840) |\n",
    "| 8     | S. Christy                                  | 2018     | DiSC Assessment Impact on Communication and Understanding of Self and Team | -                                    | -          | -           | [URL](https://www.semanticscholar.org/paper/6178aaa8dc0268c2b2d0beaab217642120b0eae9) |\n",
    "| 9     | M. Pollock                                  | 2009     | Investigating the relationship between team role diversity and team performance in information systems teams | - | - | - | [URL](https://www.semanticscholar.org/paper/512d827110e403c7b061bd0bb5d42b74e38d6b13) |\n",
    "| 10    | E. Comeaux, A. Brown, N. Sieben              | 2015     | Issues in Athletic Administration: A Content Analysis of Syllabi from Intercollegiate Athletics Graduate Courses | Innovative Higher Education | 40 | 359-372 | [DOI](https://doi.org/10.1007/S10755-015-9333-8) |\n",
    "| 11    | I. Lykourentzou, A. Antoniou, Y. Naudet, S. W. Dow | 2016 | Personality Matters: Balancing for Personality Types Leads to Better Outcomes for Crowd Teams | Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work & Social Computing | N/A | N/A | [DOI](https://doi.org/10.1145/2818048.2819979) |\n",
    "| 12    | L. Whisler                                  | 1957     | A Study of the Descriptive Validity of Activity Vector Analysis         | The Journal of Psychology            | 43         | 205-223     | [DOI](https://doi.org/10.1080/00223980.1957.9713067) |\n",
    "| 13    | G. Bunn                                     | 1997     | The lie detector, Wonder Woman and liberty: the life and work of William Moulton Marston | History of the Human Sciences       | 10         | 119-191     | [DOI](https://doi.org/10.1177/095269519701000105) |\n",
    "| 14    | E. Comeaux                                  | 2013     | Rethinking Academic Reform and Encouraging Organizational Innovation: Implications for Stakeholder Management in College Sports | Innovative Higher Education         | 38         | 281-293     | [DOI](https://doi.org/10.1007/S10755-012-9240-1) |\n",
    "| 15    | P. F. Merenda, W. V. Clarke, H. Schulz, W. Strehse, G. Winneke | 1969 | CROSS‚ÄêCULTURAL PERCEPTIONS OF THE IDEAL SELF‚ÄêCONCEPT1 | Applied Psychology | 18 | 129-134 | [DOI](https://doi.org/10.1111/J.1464-0597.1969.TB00677.X) |\n",
    "| 16    | T. J. Keogh, T. J. Keogh, J. C. Robinson, J. Parnell | 2019 | Assessing Behavioral Styles Among Nurse Managers: Implications for Leading Effective Teams | Hospital Topics | 97 | 32-38 | [DOI](https://doi.org/10.1080/00185868.2018.1563460) |\n",
    "| 17    | C. S. Jones, N. T. Hartley                  | 2013     | Comparing Correlations Between Four-Quadrant And Five-Factor Personality Assessments | American Journal of Business Education | 6         | 459-470     | [DOI](https://doi.org/10.19030/AJBE.V6I4.7945) |\n",
    "| 18    | L. Furlow                                   | 2000     | Job profiling: building a winning team using behavioral assessments      | The Journal of Nursing Administration | 30         | 107-111     | [DOI](https://doi.org/10.1097/00005110-200003000-00001) |\n",
    "| 19    | -                                           | 2016     | Exploring NIRSA Championship Series Professional Development Opportunities: Understanding Their Perceived Value to the Association | Recreational Sports Journal        | 40         | 2-20        | [DOI](https://doi.org/10.1123/rsj.2015-0045) |\n",
    "| 20    | L. Masteralexis, M. Mcdonald                | 1997     | Enhancing sport management education with international dimensions including language and cultural training | Journal of Sport Management | 11 | 97-110 | [DOI](https://doi.org/10.1123/JSM.11.1.97) |\n",
    "| 21    | J. H. Reynierse                             | 1997     | An MBTI Model of Entrepreneurism and Bureaucracy: The Psychological Types of Business Entrepreneurs Compared to Business Managers and Executives | Journal of Psychology | 18 | 191-194 | [DOI](https://doi.org/10.2466/pms.1964.18.1.191) |\n",
    "| 22    | S. P. Rushton, J. Mariano, T. L. Wallace    | 2012     | Program Selection among Pre-Service Teachers: MBTI Profiles within a College of Education | Creative Education | 3 | 16-23 | [DOI](https://doi.org/10.4236/CE.2012.31003) |\n",
    "| 23    | P. F. Merenda, J. Mohan                     | 1970     | Indian Students' Pre- and Post-Election Perceptions of Nixon and Humphrey | Perceptual and Motor Skills | 30 | 677-678 | [DOI](https://doi.org/10.2466/pms.1970.30.2.677) |\n",
    "| 24    | L. Furlow                                   | 2002     | Selecting nurses based on behavioral characteristics                       | AORN Journal | 75 | 590-592 | [DOI](https://doi.org/10.1016/S0001-2092(06)61180-0) |\n",
    "| 25    | Hsien-Yung Liu, S. Silverman                | 2006     | The value profile of physical education teachers in Taiwan, ROC           | Sport, Education and Society          | 11         | 173-191     | [DOI](https://doi.org/10.1080/13573320600640694) |\n",
    "| 26    | P. F. Merenda, J. Mohan, W. V. Clarke, H. Schulz, W. Strehse, G. Winneke | 1968 | Cross-Cultural Perceptions of Johnson and Kosygin                         | Perceptual and Motor Skills | 26 | 843-847 | [DOI](https://doi.org/10.2466/pms.1968.26.3.843) |\n",
    "| 27    | P. F. Merenda                               | 1964     | Mr. K and the Ideal Self                                                  | Perceptual and Motor Skills           | 18         | 191-194     | [DOI](https://doi.org/10.2466/pms.1964.18.1.191) |\n",
    "| 28    | W. V. Clarke                                | 1956     | The Personality Profiles of Life Insurance Agents                         | The Journal of Psychology             | 42         | 295-302     | [DOI](https://doi.org/10.1080/00223980.1956.9713042) |\n",
    "| 29    | W. V. Clarke                                | 1956     | Personality Profile of Self-Made Company Presidents                       | The Journal of Psychology             | 41         | 413-418     | [DOI](https://doi.org/10.1080/00223980.1956.9713014) |\n",
    "| 30    | T. N. Jenkins                               | 1963     | Personality Characteristics Which Differentiate Two Types of Hearing Difficulties | Journal of Clinical Psychology         | 19         | 48-52       | [DOI](https://doi.org/10.1002/1097-4679(196301)19:1<48::AID-JCLP2270190105>3.0.CO;2-J) |\n",
    "| 31    | P. F. Merenda                               | 1964     | Perception of Role of the President                                    | Perceptual and Motor Skills            | 19         | 863-866     | [DOI](https://doi.org/10.2466/pms.1964.19.3.863) |\n",
    "| 32    | P. F. Merenda, W. V. Clarke                 | 1965     | Self Description and Personality Measurement                           | Journal of Clinical Psychology         | 21         | 52-56       | [DOI](https://doi.org/10.1002/1097-4679(196501)21:1<52::AID-JCLP2270210115>3.0.CO;2-K) |\n",
    "| 33    | W. V. Clarke                                | 1956     | The Construction of an Industrial Selection Personality Test           | The Journal of Psychology              | 41         | 379-394     | [DOI](https://doi.org/10.1080/00223980.1956.9713011) |\n",
    "| 34    | E. Comeaux                                 | 2017     | The Occupational Socialization of Athletic Administrators: A Content Analysis of Graduate Program Websites | Innovative Higher Education            | -1         | 75-91       | [DOI](https://doi.org/10.15763/ISSN.2376-5267.2017.1.2.75-91) |\n",
    "| 35    | J. H. Reynierse, D. Ackerman, A. A. Fink, J. Harker | 2000 | The Effects of Personality and Management Role on Perceived Values in Business Settings | International Journal of Value-Based Management | 13 | 1-13 | [DOI](https://doi.org/10.1023/A:1007707800997) |\n",
    "| 36    | E. Comeaux                                 | 2013     | Rethinking Academic Reform and Encouraging Organizational Innovation: Implications for Stakeholder Management in College Sports | Innovative Higher Education            | 38         | 281-293     | [DOI](https://doi.org/10.1007/S10755-012-9240-1) |\n",
    "| 37    | J. M. Williams, H. M. Parker                | 2016     | Integration of Experiential Learning and Leadership Development in a Sport Management Classroom | Sport Management Education Journal     | 10         | 54-63       | [DOI](https://doi.org/10.1123/SMEJ.2015-0012) |\n",
    "| 38    | W. James (Jim) Weese                        | 2020     | Internationalizing Sport Management Programs: No Longer a Luxury, But a Necessity | Sport Management Education Journal     | -1         | 1-6         | [DOI](https://doi.org/10.1123/smej.2019-0044) |\n",
    "| 39    | E. Jowdy, M. Mcdonald, K. Spence            | 2004     | An Integral Approach to Sport Management Internships                   | European Sport Management Quarterly    | 4          | 215-233     | [DOI](https://doi.org/10.1080/16184740408737478) |\n",
    "| 40    | P. F. Merenda                               | 1966     | Perception of Nehru and the Ideal Self in the Indian Culture           | Perceptual and Motor Skills            | 22         | 865-866     | [DOI](https://doi.org/10.2466/pms.1966.22.3.865) |\n",
    "\n",
    "\n",
    "### Taxonomy\n",
    "```\n",
    "- Domain\n",
    "    |\n",
    " - Sub-Domain\n",
    "    |__ Factor\n",
    "        |__ Adjective\n",
    "            |__ Synonym\n",
    "            |__ Verb\n",
    "            |__ Noun\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d931fe8d-537d-48d1-9f8a-79670ef29866",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 1: Create Dataset** <a class=\"anchor\" id=\"OCEAN_page_1\"></a>\n",
    "\n",
    "Data Preparation and Cleaning: Ensure the dataset is cleaned and preprocessed properly. Handle missing values, duplicates, and outliers.\n",
    "\n",
    "[Back to Top](#OCEAN_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0321c83f-f7cc-431c-bdf3-577ce535de2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Subcategory</th>\n",
       "      <th>Factor</th>\n",
       "      <th>Adjective</th>\n",
       "      <th>Synonym</th>\n",
       "      <th>Verb</th>\n",
       "      <th>Noun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Type</td>\n",
       "      <td>Dominance</td>\n",
       "      <td>Assertiveness</td>\n",
       "      <td>Assertive</td>\n",
       "      <td>Decisive</td>\n",
       "      <td>Assert</td>\n",
       "      <td>Assertiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Type</td>\n",
       "      <td>Dominance</td>\n",
       "      <td>Competitive</td>\n",
       "      <td>Confident</td>\n",
       "      <td>Direct</td>\n",
       "      <td>Compete</td>\n",
       "      <td>Competition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Type</td>\n",
       "      <td>Dominance</td>\n",
       "      <td>Adventurous</td>\n",
       "      <td>Impatient</td>\n",
       "      <td>Strong-willed</td>\n",
       "      <td>Explore</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Type</td>\n",
       "      <td>Dominance</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Dominant</td>\n",
       "      <td>Ambitious</td>\n",
       "      <td>Independently decide</td>\n",
       "      <td>Independence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Type</td>\n",
       "      <td>Influence</td>\n",
       "      <td>Sociability</td>\n",
       "      <td>Sociable</td>\n",
       "      <td>Enthusiastic</td>\n",
       "      <td>Influence</td>\n",
       "      <td>Sociability</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Domain Subcategory         Factor  Adjective        Synonym  \\\n",
       "0   Type   Dominance  Assertiveness  Assertive       Decisive   \n",
       "1   Type   Dominance    Competitive  Confident         Direct   \n",
       "2   Type   Dominance    Adventurous  Impatient  Strong-willed   \n",
       "3   Type   Dominance    Independent   Dominant      Ambitious   \n",
       "4   Type   Influence    Sociability   Sociable   Enthusiastic   \n",
       "\n",
       "                   Verb           Noun  \n",
       "0                Assert  Assertiveness  \n",
       "1               Compete    Competition  \n",
       "2               Explore      Adventure  \n",
       "3  Independently decide   Independence  \n",
       "4             Influence    Sociability  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# DiSC dataset with verbs and nouns included\n",
    "disc_dataset = {\n",
    "    'Type': {\n",
    "        'Dominance': {\n",
    "            'Factors': ['Assertiveness', 'Competitive', 'Adventurous', 'Independent'],\n",
    "            'Adjectives': ['Assertive', 'Confident', 'Impatient', 'Dominant'],\n",
    "            'Synonyms': ['Decisive', 'Direct', 'Strong-willed', 'Ambitious', 'Results-oriented', 'Goal-focused', 'Controlling', 'Insensitive', 'Overbearing'],\n",
    "            'Verbs': ['Assert', 'Compete', 'Explore', 'Independently decide'],\n",
    "            'Nouns': ['Assertiveness', 'Competition', 'Adventure', 'Independence']\n",
    "        },\n",
    "        'Influence': {\n",
    "            'Factors': ['Sociability', 'Expressive', 'Enthusiastic', 'Inspirational'],\n",
    "            'Adjectives': ['Sociable', 'Persuasive', 'Collaborative', 'Impulsive'],\n",
    "            'Synonyms': ['Enthusiastic', 'Energetic', 'Outgoing', 'Charming', 'Inspiring', 'Motivational', 'Optimistic', 'Motivating', 'Engaging', 'Attention-seeking', 'Overly trusting', 'Easily influenced'],\n",
    "            'Verbs': ['Influence', 'Persuade', 'Inspire', 'Motivate'],\n",
    "            'Nouns': ['Sociability', 'Persuasion', 'Inspiration', 'Enthusiasm']\n",
    "        },\n",
    "        'Steadiness': {\n",
    "            'Factors': ['Cooperativeness', 'Even-tempered', 'Accommodating', 'Patient'],\n",
    "            'Adjectives': ['Cooperative', 'Stable', 'Loyal', 'Indecisive'],\n",
    "            'Synonyms': ['Patient', 'Supportive', 'Accommodating', 'Reliable', 'Calm', 'Consistent', 'Dependable', 'Good listener', 'Trusted', 'Overly accommodating', 'Avoids conflict', 'Unassertive'],\n",
    "            'Verbs': ['Cooperate', 'Accommodate', 'Listen', 'Support'],\n",
    "            'Nouns': ['Cooperation', 'Accommodation', 'Patience', 'Loyalty']\n",
    "        },\n",
    "        'Conscientiousness': {\n",
    "            'Factors': ['Analytical Nature', 'Cautious', 'Precise', 'Analytical'],\n",
    "            'Adjectives': ['Analytical', 'Conscientious', 'Diligent', 'Perfectionistic'],\n",
    "            'Synonyms': ['Detail-oriented', 'Systematic', 'Precise', 'Thorough', 'Organized', 'Methodical', 'Meticulous', 'Accurate', 'Responsible', 'Overly critical', 'Inflexible', 'Overly cautious'],\n",
    "            'Verbs': ['Analyze', 'Organize', 'Thoroughly review', 'Systematize'],\n",
    "            'Nouns': ['Analysis', 'Conscientiousness', 'Diligence', 'Perfectionism']\n",
    "        }\n",
    "    },\n",
    "    'Person': {\n",
    "        'Person ID': {\n",
    "            'Factors': ['Identification'],\n",
    "            'Adjectives': ['Unique'],\n",
    "            'Synonyms': ['ID', 'Identifier'],\n",
    "            'Verbs': ['Identify'],\n",
    "            'Nouns': ['Identification', 'Uniqueness']\n",
    "        },\n",
    "        'Name': {\n",
    "            'Factors': ['Identity'],\n",
    "            'Adjectives': ['Identifiable', 'Recognizable', 'Distinctive'],\n",
    "            'Synonyms': ['Full Name', 'Given Name', 'Surname'],\n",
    "            'Verbs': ['Recognize', 'Identify'],\n",
    "            'Nouns': ['Identity', 'Recognition', 'Distinctiveness']\n",
    "        },\n",
    "        'Department': {\n",
    "            'Factors': ['Organization'],\n",
    "            'Adjectives': ['Organized', 'Structured', 'Efficient'],\n",
    "            'Synonyms': ['Division', 'Unit', 'Section'],\n",
    "            'Verbs': ['Organize', 'Structure'],\n",
    "            'Nouns': ['Organization', 'Structure', 'Efficiency']\n",
    "        },\n",
    "        'Tenure': {\n",
    "            'Factors': ['Experience'],\n",
    "            'Adjectives': ['Experienced', 'Seasoned', 'Long-standing'],\n",
    "            'Synonyms': ['Seniority', 'Length of Service', 'Time in Role'],\n",
    "            'Verbs': ['Serve', 'Contribute', 'Lead'],\n",
    "            'Nouns': ['Experience', 'Seniority', 'Tenure']\n",
    "        },\n",
    "        'Job Level': {\n",
    "            'Factors': ['Hierarchy'],\n",
    "            'Adjectives': ['Hierarchical', 'Senior', 'Entry-level'],\n",
    "            'Synonyms': ['Position Level', 'Rank', 'Grade'],\n",
    "            'Verbs': ['Promote', 'Rank', 'Evaluate'],\n",
    "            'Nouns': ['Hierarchy', 'Position Level', 'Grade']\n",
    "        }\n",
    "    },\n",
    "    'Workplace Priorities': {\n",
    "        'Priorities': {\n",
    "            'Factors': ['Motivators'],\n",
    "            'Adjectives': ['Motivated', 'Focused', 'Driven'],\n",
    "            'Synonyms': ['Goals', 'Objectives', 'Desires'],\n",
    "            'Verbs': ['Set goals', 'Focus', 'Drive results'],\n",
    "            'Nouns': ['Priority', 'Motivation', 'Focus']\n",
    "        },\n",
    "        'Motivators Description': {\n",
    "            'Factors': ['Intrinsic Motivators', 'Extrinsic Motivators', 'Personal Motivators'],\n",
    "            'Adjectives': ['Intrinsic', 'Extrinsic', 'Personal'],\n",
    "            'Synonyms': ['Internal Drives', 'External Rewards', 'Personal Goals'],\n",
    "            'Verbs': ['Drive', 'Reward', 'Achieve'],\n",
    "            'Nouns': ['Motivation', 'Reward', 'Achievement']\n",
    "        },\n",
    "        'Strategies for Building Relationships': {\n",
    "            'Factors': ['Interpersonal Skills', 'Empathy', 'Active Listening'],\n",
    "            'Adjectives': ['Collaborative', 'Empathetic', 'Supportive'],\n",
    "            'Synonyms': ['Interpersonal Skills', 'Connection Building', 'Relational Strategies'],\n",
    "            'Verbs': ['Build relationships', 'Collaborate', 'Support'],\n",
    "            'Nouns': ['Relationship', 'Collaboration', 'Support']\n",
    "        },\n",
    "        'Strategies for Communication': {\n",
    "            'Factors': ['Clarity', 'Active Listening', 'Assertiveness'],\n",
    "            'Adjectives': ['Clear', 'Effective', 'Adaptive'],\n",
    "            'Synonyms': ['Communication Techniques', 'Interpersonal Communication', 'Messaging Approaches'],\n",
    "            'Verbs': ['Communicate', 'Listen', 'Adapt'],\n",
    "            'Nouns': ['Clarity', 'Effectiveness', 'Adaptability']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create empty lists to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate over each category and its subcategories\n",
    "for category, subcategories in disc_dataset.items():\n",
    "    for subcategory, factors in subcategories.items():\n",
    "        synonyms = factors.get('Synonyms', [])\n",
    "        verbs = factors.get('Verbs', [])\n",
    "        nouns = factors.get('Nouns', [])\n",
    "        factors_list = factors['Factors']\n",
    "        adjective_list = factors['Adjectives']\n",
    "        \n",
    "        # Normalize lists to the same length\n",
    "        max_len = max(len(synonyms), len(verbs), len(nouns))\n",
    "        synonyms += [''] * (max_len - len(synonyms))\n",
    "        verbs += [''] * (max_len - len(verbs))\n",
    "        nouns += [''] * (max_len - len(nouns))\n",
    "        \n",
    "        # Append each factor, adjective, synonym, verb, and noun combination to the data\n",
    "        for factor, adjective, synonym, verb, noun in zip(factors_list, adjective_list, synonyms, verbs, nouns):\n",
    "            data.append((category, subcategory, factor, adjective, synonym, verb, noun))\n",
    "\n",
    "# Create DataFrame\n",
    "disc_df = pd.DataFrame(data, columns=['Domain', 'Subcategory', 'Factor', 'Adjective', 'Synonym', 'Verb', 'Noun'])\n",
    "\n",
    "# Save to CSV\n",
    "disc_df.to_csv('../Datasets/disc.csv', index=False)\n",
    "\n",
    "# Display the first few rows\n",
    "disc_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c5b327-3d34-439f-8a75-9e9471a0e65e",
   "metadata": {},
   "source": [
    "##  Steps for DISC Personality Modeling Workflow \n",
    "\n",
    "1.  **Step 1: Create the Personality Dataset**\n",
    "\n",
    "    * **Purpose:** This initial step involves defining and generating the dataset that represents the (DISC) Personality Model .\n",
    "    * **Actions:**\n",
    "        * Define the DISC dataset structure (e.g., using a dictionary to represent factors, adjectives, synonyms, etc.).\n",
    "        * Generate the dataset by organizing the data into a Pandas DataFrame.\n",
    "        * Save the dataset to a CSV file.\n",
    "        * Log dataset metadata (e.g., number of rows, factors, data schema) and the dataset file itself as an artifact in MLflow.\n",
    "    * **Importance:** This step creates the raw data that will be used for embedding generation and model training.\n",
    "\n",
    "2.  **Step 2: API Key Handling and Initialization**\n",
    "\n",
    "    * **Purpose:** This cdiscical step ensures that your OpenAI API key is securely loaded and the OpenAI client is initialized. This sets the foundation for using the OpenAI API in subsequent steps.\n",
    "    * **Actions:**\n",
    "        * Load the OpenAI API key from a secure location (e.g., a file in the user's home directory).\n",
    "        * Validate the API key (e.g., check for existence, emptiness, and potentially a basic API call).\n",
    "        * Initialize the OpenAI client (`client`).\n",
    "        * Log the API key handling process and its outcome in MLflow.\n",
    "    * **Importance:** This step must succeed for the rest of the workflow that utilizes the OpenAI API (like embedding generation) to function. It's essential to handle potential errors (e.g., file not found, invalid key) gracefully.\n",
    "\n",
    "3.  **Step 3: Test Embedding API**\n",
    "\n",
    "    * **Purpose:** This step verifies that the OpenAI Embedding API is accessible and functioning correctly.\n",
    "    * **Actions:**\n",
    "        * Use the initialized OpenAI client (`client`) to make a test call to the Embedding API (e.g., by embedding a sample text).\n",
    "        * Check the API response for validity.\n",
    "        * Log the API call details and the outcome (success or failure) in MLflow.\n",
    "    * **Importance:** This step ensures that you can successfully generate embeddings before proceeding to the next step.\n",
    "\n",
    "4.  **Step 4: Create Embeddings for the Dataset**\n",
    "\n",
    "    * **Purpose:** This step generates numerical represendiscions (embeddings) for the text data in the DISC dataset using the OpenAI Embedding API.\n",
    "    * **Actions:**\n",
    "        * Load the DISC dataset (created in Step 2).\n",
    "        * Use the OpenAI client (`client`) to generate embeddings for the relevant text fields (e.g., combining factor, adjective, synonym, verb, noun).\n",
    "        * Add the generated embeddings as a new column in the Pandas DataFrame.\n",
    "        * Save the DataFrame with embeddings to a new CSV file.\n",
    "        * Log embedding generation parameters (e.g., embedding model used), sdiscistics (e.g., embedding length), and the embeddings file as an artifact in MLflow.\n",
    "    * **Importance:** This step transforms the text data into a numerical format that can be used for machine learning models.\n",
    "\n",
    "5.  **Step 5: Create and Visualize a Label Encoder**\n",
    "\n",
    "    * **Purpose:** This step prepares the categorical labels (personality factors) for model training by encoding them into numerical values and provides a visualization of this encoding.\n",
    "    * **Actions:**\n",
    "        * Load the dataset with embeddings (created in Step 4).\n",
    "        * Initialize a `LabelEncoder` from scikit-learn.\n",
    "        * Fit the `LabelEncoder` to the 'Factor' column to create the mapping between personality factors and numerical codes.\n",
    "        * Transform the 'Factor' column using the fitted `LabelEncoder` to create a new 'Factor_Encoded' column.\n",
    "        * Save the fitted `LabelEncoder` object.\n",
    "        * Generate a visualization (e.g., a bar chart) to show the mapping between original factors and encoded values.\n",
    "        * Save the visualization as an image file.\n",
    "        * Log the label encoder object and the visualization as artifacts in MLflow.\n",
    "        * Log the mapping between original factors and encoded values as a dictionary in MLflow.\n",
    "    * **Importance:** This step prepares the target variable for model training and provides a clear represendiscion of the encoding.\n",
    "\n",
    "6.  **Step 6: Create our DISC Model (Model Training and Evaluation)**\n",
    "\n",
    "    * **Purpose:** This step trains a machine learning model on the generated embeddings to predict personality factors and evaluates its performance.\n",
    "    * **Actions:**\n",
    "        * Load the dataset with embeddings (created in Step 4).\n",
    "        * Load the saved `LabelEncoder` (created in Step 5).\n",
    "        * Prepare the data for model training:\n",
    "            * Extract the embeddings as features (`X`).\n",
    "            * Encode the 'Factor' column using the loaded `LabelEncoder` to get the target variable (`y`).\n",
    "            * Split the data into training and testing sets.\n",
    "        * Initialize a machine learning model (e.g., `RandomForestClassifier`).\n",
    "        * Train the model on the training data.\n",
    "        * Make predictions on the test data.\n",
    "        * Evaluate the model's performance using appropriate metrics (e.g., accuracy, classification report, confusion matrix).\n",
    "        * Generate visualizations of the evaluation results (e.g., confusion matrix plot).\n",
    "        * Save the trained model.\n",
    "        * Log model training parameters (e.g., hyperparameters), evaluation metrics, visualizations, and the trained model as artifacts in MLflow.\n",
    "    * **Importance:** This step is the core of the machine learning process, where the model learns to predict personality factors from the embeddings.\n",
    "\n",
    "7.  **Step 7: Model Testing (Inference on New Data)**\n",
    "\n",
    "    * **Purpose:** This step demonstrates how to use the trained model to predict personality factors for new, unseen text inputs.\n",
    "    * **Actions:**\n",
    "        * Load the trained model (saved in Step 6).\n",
    "        * Load the saved `LabelEncoder` (created in Step 5).\n",
    "        * Define a function that:\n",
    "            * Takes new text as input.\n",
    "            * Generates an embedding for the new text using the OpenAI API.\n",
    "            * Uses the loaded model to predict the personality factor.\n",
    "            * Uses the loaded `LabelEncoder` to decode the numerical prediction back to the original factor name.\n",
    "        * Provide example new text inputs.\n",
    "        * Use the function to predict personality factors for the example texts.\n",
    "        * Print the predictions.\n",
    "        * Log the test inputs and predictions in MLflow.\n",
    "    * **Importance:** This step demonstrates the practical application of the trained model for making predictions on new data.\n",
    "\n",
    "8.  **Step 8: Model Application, Visualization, and Analysis**\n",
    "\n",
    "    * **Purpose:** This step provides additional visualization and analysis of the data and model.\n",
    "    * **Actions:**\n",
    "        * Load the dataset with embeddings (created in Step 4).\n",
    "        * Apply PCA for dimensionality reduction and visualization of the embeddings.\n",
    "        * Generate and log PCA plots to visualize the embedding distribution.\n",
    "        * Perform K-Means clustering on the embeddings to identify potential groupings or clusters of similar personality traits.\n",
    "        * Add cluster labels to the dataset and save the clustered data.\n",
    "        * Log clustering parameters (e.g., number of clusters) and the clustered data as artifacts in MLflow.\n",
    "    * **Importance:** This step offers valuable insights into the data and model:\n",
    "        * PCA visualization helps understand the distribution of embeddings.\n",
    "        * Clustering can reveal underlying patterns in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b2a39-e66d-4a46-8f62-ad88cd36ce87",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 2: API key setup** <a class=\"anchor\" id=\"disc_page_2\"></a>\n",
    "\n",
    "[Back to Top](#disc_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a790191a-5760-45d1-a325-0cb2dcff5582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API key file found at: /Users/jsr/openai_api_key.txt\n",
      "üîë API key read successfully.\n",
      "ü§ñ OpenAI API client initialized.\n",
      "‚úÖ OpenAI API key verified successfully with a basic API call.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import mlflow\n",
    "\n",
    "# Start an MLFlow run for API key setup\n",
    "with mlflow.start_run(run_name=\"API Key Handling and Initialization\") as run:\n",
    "    try:\n",
    "        # Log the environment setup process\n",
    "        mlflow.log_param(\"Step\", \"API Key Handling and Initialization\")\n",
    "\n",
    "        # Define the path to your API key file\n",
    "        api_key_file_path = os.path.expanduser('~/openai_api_key.txt')\n",
    "        mlflow.log_param(\"API Key File Path\", api_key_file_path)\n",
    "\n",
    "        # Evaluation: Check if the API key file exists\n",
    "        if not os.path.exists(api_key_file_path):\n",
    "            error_message = f\"API key file not found at: {api_key_file_path}. Please ensure the file exists.\"\n",
    "            mlflow.log_param(\"API Key Sdiscus\", \"Error: File not found\")\n",
    "            mlflow.log_param(\"Error\", error_message)\n",
    "            raise FileNotFoundError(error_message)\n",
    "        else:\n",
    "            mlflow.log_param(\"API Key File Existence\", \"Confirmed\")\n",
    "            print(f\"‚úÖ API key file found at: {api_key_file_path}\")\n",
    "\n",
    "        # Read the API key from the file\n",
    "        with open(api_key_file_path, 'r') as file:\n",
    "            api_key = file.read().strip()\n",
    "\n",
    "        # Evaluation: Check if the read API key is empty\n",
    "        if not api_key:\n",
    "            error_message = f\"API key file at: {api_key_file_path} is empty. Please ensure your API key is in the file.\"\n",
    "            mlflow.log_param(\"API Key Sdiscus\", \"Error: Empty file\")\n",
    "            mlflow.log_param(\"Error\", error_message)\n",
    "            raise ValueError(error_message)\n",
    "        else:\n",
    "            mlflow.log_param(\"API Key Sdiscus\", \"Read successfully\")\n",
    "            mlflow.log_param(\"API Key Length\", len(api_key)) # Log the length as a basic sanity check\n",
    "            print(\"üîë API key read successfully.\")\n",
    "\n",
    "        # Set up your OpenAI API key\n",
    "        openai.api_key = api_key\n",
    "        client = openai.OpenAI(api_key=api_key)\n",
    "        mlflow.log_param(\"OpenAI API Client\", \"Initialized successfully\")\n",
    "        print(\"ü§ñ OpenAI API client initialized.\")\n",
    "\n",
    "        # Evaluation: Attempt a basic API call to verify the key (optional, but recommended for immediate feedback)\n",
    "        try:\n",
    "            response = client.models.list()  # Removed the 'limit' argument\n",
    "            mlflow.log_param(\"API Key Verification\", \"Successful (models list)\")\n",
    "            print(\"‚úÖ OpenAI API key verified successfully with a basic API call.\")\n",
    "        except openai.AuthenticationError as auth_error:\n",
    "            mlflow.log_param(\"API Key Verification\", \"Failed (AuthenticationError)\")\n",
    "            mlflow.log_param(\"Error\", str(auth_error))\n",
    "            raise openai.AuthenticationError(f\"OpenAI API key authentication failed: {auth_error}\")\n",
    "        except openai.OpenAIError as general_error:\n",
    "            mlflow.log_param(\"API Key Verification\", \"Failed (OpenAIError)\")\n",
    "            mlflow.log_param(\"Error\", str(general_error))\n",
    "            print(f\"‚ö†Ô∏è Warning: OpenAI API client initialized, but a test call failed with: {general_error}. Further API calls might fail.\")\n",
    "            mlflow.log_param(\"API Key Verification Warning\", str(general_error))\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"FileNotFoundError\")\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        raise\n",
    "    except ValueError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"ValueError\")\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        raise\n",
    "    except openai.AuthenticationError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"AuthenticationError\")\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        raise\n",
    "    except openai.OpenAIError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"OpenAIError\")\n",
    "        print(f\"‚ö†Ô∏è Warning during API initialization: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        # Log the error if any other unexpected issue occurs\n",
    "        mlflow.log_param(\"Error Type\", type(e).__name__)\n",
    "        mlflow.log_param(\"Error\", str(e))\n",
    "        print(f\"‚ùå An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        # End the MLFlow run\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d949ba3-7cf4-4bda-9e56-6a4f43cb8882",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 3: Test Embedding** <a class=\"anchor\" id=\"disc_page_2\"></a>\n",
    "\n",
    "[Back to Top](#disc_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8da8f526-a61f-4805-9d71-2a20383e45f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI client found and ready.\n",
      "üìù Testing embedding for text: 'The quick brown fox jumps over the lazy dog.'\n",
      "‚úÖ Embedding model 'text-embedding-3-small' is available.\n",
      "Embedding length: 1536\n",
      "Embedding snippet: [-0.01842353865504265, -0.00725775770843029, 0.0036669441033154726, -0.0542047917842865, -0.022724902257323265, 0.03694858402013779, 0.02903103083372116, 0.023866858333349228, 0.011229223571717739, -0.020618630573153496]\n",
      "‚úÖ Embedding API test successful.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import mlflow\n",
    "\n",
    "# Function to test the OpenAI Embedding API\n",
    "def test_openai_embedding_api():\n",
    "    with mlflow.start_run(run_name=\"Test Embedding API\") as run:\n",
    "        try:\n",
    "            # Log the step name\n",
    "            mlflow.log_param(\"Step\", \"Test Embedding API\")\n",
    "\n",
    "            # Evaluation: Check if the OpenAI client is initialized\n",
    "            if 'client' not in globals() or not isinstance(client, openai.OpenAI):\n",
    "                error_message = \"OpenAI client is not initialized. Ensure the API key setup step was executed successfully.\"\n",
    "                mlflow.log_param(\"API Client Sdiscus\", \"Not Initialized\")\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                raise RuntimeError(error_message)\n",
    "            else:\n",
    "                mlflow.log_param(\"API Client Sdiscus\", \"Initialized\")\n",
    "                print(\"‚úÖ OpenAI client found and ready.\")\n",
    "\n",
    "            # Example text to embed\n",
    "            text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "            mlflow.log_param(\"Test Text\", text)\n",
    "            print(f\"üìù Testing embedding for text: '{text}'\")\n",
    "\n",
    "            # Evaluation: Check if the specified embedding model is available (optional, but good practice)\n",
    "            embedding_model = \"text-embedding-3-small\"\n",
    "            mlflow.log_param(\"Embedding Model\", embedding_model)\n",
    "            try:\n",
    "                model_info = client.models.retrieve(embedding_model)\n",
    "                mlflow.log_param(\"Embedding Model Availability\", \"Confirmed\")\n",
    "                print(f\"‚úÖ Embedding model '{embedding_model}' is available.\")\n",
    "            except openai.NotFoundError:\n",
    "                error_message = f\"Embedding model '{embedding_model}' not found. Please check the model name.\"\n",
    "                mlflow.log_param(\"Embedding Model Availability\", \"Not Found\")\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                raise ValueError(error_message)\n",
    "            except Exception as e:\n",
    "                error_message = f\"Error checking embedding model availability: {e}\"\n",
    "                mlflow.log_param(\"Embedding Model Availability Check Error\", str(e))\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                print(f\"‚ö†Ô∏è Warning: Error checking model availability: {e}. Proceeding with embedding request.\")\n",
    "\n",
    "            # Request to generate embeddings\n",
    "            response = client.embeddings.create(\n",
    "                input=[text],  # The input should be a list of strings\n",
    "                model=embedding_model\n",
    "            )\n",
    "\n",
    "            # Evaluation: Check if the embedding response contains data\n",
    "            if not response.data:\n",
    "                error_message = \"Embedding API response does not contain any data.\"\n",
    "                mlflow.log_param(\"Embedding API Response Sdiscus\", \"No Data\")\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                raise ValueError(error_message)\n",
    "            else:\n",
    "                mlflow.log_param(\"Embedding API Response Sdiscus\", \"Data Received\")\n",
    "\n",
    "            # Extract the embedding\n",
    "            embedding = response.data[0].embedding\n",
    "\n",
    "            # Evaluation: Check if the extracted embedding is not empty\n",
    "            if not embedding:\n",
    "                error_message = \"Extracted embedding is empty.\"\n",
    "                mlflow.log_param(\"Embedding Extraction Sdiscus\", \"Empty Embedding\")\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                raise ValueError(error_message)\n",
    "            else:\n",
    "                mlflow.log_param(\"Embedding Extraction Sdiscus\", \"Success\")\n",
    "\n",
    "            # Log the embedding length and a snippet\n",
    "            embedding_length = len(embedding)\n",
    "            mlflow.log_param(\"Embedding Length\", embedding_length)\n",
    "            mlflow.log_param(\"Embedding Snippet\", embedding[:10])\n",
    "\n",
    "            # Print the embedding length and a snippet\n",
    "            print(f\"Embedding length: {embedding_length}\")\n",
    "            print(f\"Embedding snippet: {embedding[:10]}\")  # Print the first 10 elements of the embedding\n",
    "\n",
    "            print(\"‚úÖ Embedding API test successful.\")\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            mlflow.log_param(\"Error Type\", \"RuntimeError\")\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            raise\n",
    "        except ValueError as e:\n",
    "            mlflow.log_param(\"Error Type\", \"ValueError\")\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            raise\n",
    "        except openai.NotFoundError as e:\n",
    "            mlflow.log_param(\"Error Type\", \"NotFoundError\")\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            raise\n",
    "        except openai.OpenAIError as e:\n",
    "            mlflow.log_param(\"Error Type\", \"OpenAIError\")\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"‚ùå OpenAI API error: {e}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            # Log the error if any other unexpected issue occurs\n",
    "            mlflow.log_param(\"Error Type\", type(e).__name__)\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"‚ùå An unexpected error occurred: {e}\")\n",
    "            raise\n",
    "\n",
    "        finally:\n",
    "            # End the MLFlow run\n",
    "            mlflow.end_run()\n",
    "\n",
    "# Test the OpenAI Embedding API\n",
    "test_openai_embedding_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c144305-f45d-4bd8-bb64-b5873d8b1029",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 4: Create DISC Embeddings** <a class=\"anchor\" id=\"disc_page_3\"></a>\n",
    "\n",
    "[Back to Top](#disc_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fbcfbc8-c245-4b72-b1c0-37c5cc8f57ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI client initialized.\n",
      "‚úÖ Dataset loaded: ../Datasets/disc.csv (31 rows)\n",
      "‚è≥ Started embeddings at 2025-05-25 15:07:08.368312\n",
      "‚úÖ Finished embeddings at 2025-05-25 15:07:25.427137 (took 0:00:17.058825)\n",
      "üíæ Embeddings saved to ../Embeddings/disc_embeddings.csv\n",
      "\n",
      "Sample rows:\n",
      "  Domain Subcategory         Factor  Adjective        Synonym  \\\n",
      "0   Type   Dominance  Assertiveness  Assertive       Decisive   \n",
      "1   Type   Dominance    Competitive  Confident         Direct   \n",
      "2   Type   Dominance    Adventurous  Impatient  Strong-willed   \n",
      "3   Type   Dominance    Independent   Dominant      Ambitious   \n",
      "4   Type   Influence    Sociability   Sociable   Enthusiastic   \n",
      "\n",
      "                   Verb           Noun  \\\n",
      "0                Assert  Assertiveness   \n",
      "1               Compete    Competition   \n",
      "2               Explore      Adventure   \n",
      "3  Independently decide   Independence   \n",
      "4             Influence    Sociability   \n",
      "\n",
      "                                           Embedding  \n",
      "0  [0.03276152163743973, -0.006916790269315243, 0...  \n",
      "1  [0.05954815447330475, -0.03967878967523575, 0....  \n",
      "2  [0.04693169519305229, 0.0115776676684618, 0.04...  \n",
      "3  [0.04467296972870827, -0.031774021685123444, 0...  \n",
      "4  [0.031310323625802994, -0.04407253488898277, -...  \n",
      "üèÉ View run Generate DISC Embeddings at: http://127.0.0.1:5000/#/experiments/0/runs/303b380d19b34e68ab9aabf536a5daa1\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "\n",
    "def get_openai_api_key_from_file(filepath='~/openai_api_key.txt'):\n",
    "    filepath = os.path.expanduser(filepath)\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            api_key = f.read().strip()\n",
    "        if not api_key:\n",
    "            raise ValueError(f\"API key file at '{filepath}' is empty.\")\n",
    "        return api_key\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"API key file not found at '{filepath}'.\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error reading API key from file '{filepath}': {e}\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "try:\n",
    "    openai_api_key = get_openai_api_key_from_file()\n",
    "    client = OpenAI(api_key=openai_api_key)\n",
    "    print(\"‚úÖ OpenAI client initialized.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing OpenAI client: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Load dataset ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "dataset_path = '../Datasets/disc.csv'\n",
    "try:\n",
    "    disc_df = pd.read_csv(dataset_path)\n",
    "    print(f\"‚úÖ Dataset loaded: {dataset_path} ({disc_df.shape[0]} rows)\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"Dataset not found at {dataset_path}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Embedding helper ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    try:\n",
    "        resp = client.embeddings.create(input=[text], model=model)\n",
    "        return resp.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating embedding for '{text}': {e}\")\n",
    "        raise\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Generate & log embeddings ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"Generate DISC Embeddings\") as run:\n",
    "    mlflow.log_param(\"model\", \"text-embedding-3-small\")\n",
    "    mlflow.log_param(\"dataset\", dataset_path)\n",
    "    start = datetime.now()\n",
    "    mlflow.log_param(\"start_time\", str(start))\n",
    "    print(f\"‚è≥ Started embeddings at {start}\")\n",
    "\n",
    "    if disc_df.empty:\n",
    "        raise ValueError(\"Loaded dataset is empty.\")\n",
    "\n",
    "    # Build a prompt string from each row‚Äôs full taxonomy\n",
    "    disc_df['Embedding'] = disc_df.apply(\n",
    "        lambda r: get_embedding(\n",
    "            f\"{r['Domain']} {r['Subcategory']} {r['Factor']} \"\n",
    "            f\"{r['Adjective']} {r['Synonym']} {r['Verb']} {r['Noun']}\"\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    end = datetime.now()\n",
    "    mlflow.log_param(\"end_time\", str(end))\n",
    "    print(f\"‚úÖ Finished embeddings at {end} (took {end - start})\")\n",
    "\n",
    "    # Save and log embeddings CSV\n",
    "    out_path = '../Embeddings/disc_embeddings.csv'\n",
    "    disc_df[\n",
    "        ['Domain','Subcategory','Factor','Adjective','Synonym','Verb','Noun','Embedding']\n",
    "    ].to_csv(out_path, index=False)\n",
    "    mlflow.log_artifact(out_path, artifact_path=\"embeddings\")\n",
    "    print(f\"üíæ Embeddings saved to {out_path}\")\n",
    "\n",
    "    # Log run statistics\n",
    "    mlflow.log_param(\"num_rows\",        disc_df.shape[0])\n",
    "    mlflow.log_param(\"num_columns\",     disc_df.shape[1])\n",
    "    mlflow.log_param(\"embedding_length\", len(disc_df['Embedding'].iloc[0]))\n",
    "\n",
    "    print(\"\\nSample rows:\")\n",
    "    print(disc_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34b9502-e9f9-4b20-bbb4-813e3e5dd54a",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 5: Create Label Embeddings** <a class=\"anchor\" id=\"disc_page_3\"></a>\n",
    "\n",
    "[Back to Top](#disc_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddfe5c0b-fda2-439c-9348-ac797b5eb29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/25 15:08:00 INFO mlflow.tracking.fluent: Experiment with name 'DISC' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings dataset loaded from: ../Embeddings/disc_embeddings.csv\n",
      "üíæ Label encoder saved to: ../Models/disc_label_encoder.pkl\n",
      "          Factor  Factor_Encoded\n",
      "0  Assertiveness               5\n",
      "1    Competitive               8\n",
      "2    Adventurous               2\n",
      "3    Independent              19\n",
      "4    Sociability              28\n",
      "\n",
      "Mapping:\n",
      "  Accommodating ‚Üí 0\n",
      "  Active Listening ‚Üí 1\n",
      "  Adventurous ‚Üí 2\n",
      "  Analytical ‚Üí 3\n",
      "  Analytical Nature ‚Üí 4\n",
      "  Assertiveness ‚Üí 5\n",
      "  Cautious ‚Üí 6\n",
      "  Clarity ‚Üí 7\n",
      "  Competitive ‚Üí 8\n",
      "  Cooperativeness ‚Üí 9\n",
      "  Empathy ‚Üí 10\n",
      "  Enthusiastic ‚Üí 11\n",
      "  Even-tempered ‚Üí 12\n",
      "  Experience ‚Üí 13\n",
      "  Expressive ‚Üí 14\n",
      "  Extrinsic Motivators ‚Üí 15\n",
      "  Hierarchy ‚Üí 16\n",
      "  Identification ‚Üí 17\n",
      "  Identity ‚Üí 18\n",
      "  Independent ‚Üí 19\n",
      "  Inspirational ‚Üí 20\n",
      "  Interpersonal Skills ‚Üí 21\n",
      "  Intrinsic Motivators ‚Üí 22\n",
      "  Motivators ‚Üí 23\n",
      "  Organization ‚Üí 24\n",
      "  Patient ‚Üí 25\n",
      "  Personal Motivators ‚Üí 26\n",
      "  Precise ‚Üí 27\n",
      "  Sociability ‚Üí 28\n",
      "‚úÖ Plot saved to /Users/jsr/Downloads/GitHub/Personality-Trait-Models/Notebooks/disc_label_encoder_mapping.png\n",
      "üèÉ View run Create & Visualize DISC Label Encoder at: http://127.0.0.1:5000/#/experiments/886681214121108750/runs/95606b2bdd2d4bec93a96c3008da796d\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/886681214121108750\n",
      "‚úÖ Label encoding and visualization complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"DISC\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Load embeddings dataset ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "embeddings_csv_path = '../Embeddings/disc_embeddings.csv'\n",
    "try:\n",
    "    df = pd.read_csv(embeddings_csv_path)\n",
    "    print(f\"‚úÖ Embeddings dataset loaded from: {embeddings_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: Embeddings dataset not found at: {embeddings_csv_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Fit LabelEncoder on the 'Factor' column ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "label_encoder = LabelEncoder()\n",
    "df['Factor_Encoded'] = label_encoder.fit_transform(df['Factor'])\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Save the encoder to disk ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "os.makedirs(\"../Models\", exist_ok=True)\n",
    "label_encoder_path = \"../Models/disc_label_encoder.pkl\"\n",
    "joblib.dump(label_encoder, label_encoder_path)\n",
    "print(f\"üíæ Label encoder saved to: {label_encoder_path}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Visualization helper ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def visualize_label_encoder(le, artifact_path=\"visualization\"):\n",
    "    classes = le.classes_\n",
    "    values  = le.transform(classes)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.barplot(x=classes, y=values)\n",
    "    plt.xlabel(\"DISC Factor\")\n",
    "    plt.ylabel(\"Encoded Value\")\n",
    "    plt.title(\"DISC Factors ‚Üí Encoded Mapping\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    out_file = \"disc_label_encoder_mapping.png\"\n",
    "    plt.savefig(out_file)\n",
    "    plt.close()\n",
    "    print(f\"‚úÖ Plot saved to {os.path.abspath(out_file)}\")\n",
    "    mlflow.log_artifact(out_file, artifact_path=artifact_path)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 5) Log everything in MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"Create & Visualize DISC Label Encoder\"):\n",
    "    mlflow.log_param(\"step\", \"label_encoding\")\n",
    "    mlflow.log_artifact(label_encoder_path, artifact_path=\"label_encoder\")\n",
    "\n",
    "    # Preview first few mappings\n",
    "    preview = df[['Factor', 'Factor_Encoded']].drop_duplicates().reset_index(drop=True)\n",
    "    print(preview.head())\n",
    "\n",
    "    mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    print(\"\\nMapping:\")\n",
    "    for style, code in mapping.items():\n",
    "        print(f\"  {style} ‚Üí {code}\")\n",
    "    mlflow.log_dict(mapping, \"label_encoder/mapping.json\")\n",
    "\n",
    "    # Generate and log bar chart\n",
    "    visualize_label_encoder(label_encoder)\n",
    "\n",
    "print(\"‚úÖ Label encoding and visualization complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a5fde5-2c9a-46dc-998a-ca01c356e80e",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 6: Create Model** <a class=\"anchor\" id=\"disc_page_3\"></a>\n",
    "\n",
    "[Back to Top](#disc_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc4b4c49-a90c-4b4e-9235-6a2036f6cb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings dataset loaded from: ../Embeddings/disc_embeddings.csv\n",
      "‚úÖ Label encoder loaded from: ../Models/disc_label_encoder.pkl\n",
      "Train samples: 18, Test samples: 13\n",
      "‚ö†Ô∏è  Skipped stratification because at least one class has only 1 sample.\n",
      "‚è≥ Training started at 2025-05-25 15:12:04.314626\n",
      "‚úÖ Training finished at 2025-05-25 15:12:04.381962 (Duration: 0:00:00.067336)\n",
      "üîç Test accuracy: 0.0000\n",
      "üìä Classification report saved to disc_classification_report.csv\n",
      "üìä Confusion matrix saved to disc_confusion_matrix.csv\n",
      "üñºÔ∏è Saved confusion matrix plot to disc_confusion_matrix.png\n",
      "üíæ Trained model saved to ../Models/disc_rf_model.pkl\n",
      "\n",
      "Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Accommodating       0.00      0.00      0.00       0.0\n",
      "    Active Listening       0.00      0.00      0.00       2.0\n",
      "          Analytical       0.00      0.00      0.00       1.0\n",
      "   Analytical Nature       0.00      0.00      0.00       1.0\n",
      "       Assertiveness       0.00      0.00      0.00       1.0\n",
      "             Clarity       0.00      0.00      0.00       0.0\n",
      "         Competitive       0.00      0.00      0.00       0.0\n",
      "     Cooperativeness       0.00      0.00      0.00       1.0\n",
      "             Empathy       0.00      0.00      0.00       0.0\n",
      "        Enthusiastic       0.00      0.00      0.00       0.0\n",
      "       Even-tempered       0.00      0.00      0.00       1.0\n",
      "          Expressive       0.00      0.00      0.00       1.0\n",
      "Extrinsic Motivators       0.00      0.00      0.00       1.0\n",
      "      Identification       0.00      0.00      0.00       1.0\n",
      "            Identity       0.00      0.00      0.00       1.0\n",
      "       Inspirational       0.00      0.00      0.00       0.0\n",
      "Intrinsic Motivators       0.00      0.00      0.00       0.0\n",
      "          Motivators       0.00      0.00      0.00       0.0\n",
      "        Organization       0.00      0.00      0.00       0.0\n",
      " Personal Motivators       0.00      0.00      0.00       1.0\n",
      "             Precise       0.00      0.00      0.00       0.0\n",
      "         Sociability       0.00      0.00      0.00       1.0\n",
      "\n",
      "            accuracy                           0.00      13.0\n",
      "           macro avg       0.00      0.00      0.00      13.0\n",
      "        weighted avg       0.00      0.00      0.00      13.0\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "                       Accommodating  Active Listening  Analytical  \\\n",
      "Accommodating                     0                 0           0   \n",
      "Active Listening                  0                 0           0   \n",
      "Analytical                        0                 0           0   \n",
      "Analytical Nature                 0                 0           0   \n",
      "Assertiveness                     0                 0           0   \n",
      "Clarity                           0                 0           0   \n",
      "Competitive                       0                 0           0   \n",
      "Cooperativeness                   1                 0           0   \n",
      "Empathy                           0                 0           0   \n",
      "Enthusiastic                      0                 0           0   \n",
      "Even-tempered                     1                 0           0   \n",
      "Expressive                        0                 0           0   \n",
      "Extrinsic Motivators              0                 0           0   \n",
      "Identification                    0                 0           0   \n",
      "Identity                          0                 0           0   \n",
      "Inspirational                     0                 0           0   \n",
      "Intrinsic Motivators              0                 0           0   \n",
      "Motivators                        0                 0           0   \n",
      "Organization                      0                 0           0   \n",
      "Personal Motivators               0                 0           0   \n",
      "Precise                           0                 0           0   \n",
      "Sociability                       0                 0           0   \n",
      "\n",
      "                      Analytical Nature  Assertiveness  Clarity  Competitive  \\\n",
      "Accommodating                         0              0        0            0   \n",
      "Active Listening                      0              0        1            0   \n",
      "Analytical                            0              0        0            0   \n",
      "Analytical Nature                     0              0        1            0   \n",
      "Assertiveness                         0              0        0            1   \n",
      "Clarity                               0              0        0            0   \n",
      "Competitive                           0              0        0            0   \n",
      "Cooperativeness                       0              0        0            0   \n",
      "Empathy                               0              0        0            0   \n",
      "Enthusiastic                          0              0        0            0   \n",
      "Even-tempered                         0              0        0            0   \n",
      "Expressive                            0              0        0            0   \n",
      "Extrinsic Motivators                  0              0        0            0   \n",
      "Identification                        0              0        0            0   \n",
      "Identity                              0              1        0            0   \n",
      "Inspirational                         0              0        0            0   \n",
      "Intrinsic Motivators                  0              0        0            0   \n",
      "Motivators                            0              0        0            0   \n",
      "Organization                          0              0        0            0   \n",
      "Personal Motivators                   0              0        0            0   \n",
      "Precise                               0              0        0            0   \n",
      "Sociability                           0              0        0            0   \n",
      "\n",
      "                      Cooperativeness  Empathy  Enthusiastic  ...  \\\n",
      "Accommodating                       0        0             0  ...   \n",
      "Active Listening                    0        1             0  ...   \n",
      "Analytical                          0        0             0  ...   \n",
      "Analytical Nature                   0        0             0  ...   \n",
      "Assertiveness                       0        0             0  ...   \n",
      "Clarity                             0        0             0  ...   \n",
      "Competitive                         0        0             0  ...   \n",
      "Cooperativeness                     0        0             0  ...   \n",
      "Empathy                             0        0             0  ...   \n",
      "Enthusiastic                        0        0             0  ...   \n",
      "Even-tempered                       0        0             0  ...   \n",
      "Expressive                          0        0             0  ...   \n",
      "Extrinsic Motivators                0        0             0  ...   \n",
      "Identification                      0        0             0  ...   \n",
      "Identity                            0        0             0  ...   \n",
      "Inspirational                       0        0             0  ...   \n",
      "Intrinsic Motivators                0        0             0  ...   \n",
      "Motivators                          0        0             0  ...   \n",
      "Organization                        0        0             0  ...   \n",
      "Personal Motivators                 0        0             0  ...   \n",
      "Precise                             0        0             0  ...   \n",
      "Sociability                         0        0             1  ...   \n",
      "\n",
      "                      Extrinsic Motivators  Identification  Identity  \\\n",
      "Accommodating                            0               0         0   \n",
      "Active Listening                         0               0         0   \n",
      "Analytical                               0               0         0   \n",
      "Analytical Nature                        0               0         0   \n",
      "Assertiveness                            0               0         0   \n",
      "Clarity                                  0               0         0   \n",
      "Competitive                              0               0         0   \n",
      "Cooperativeness                          0               0         0   \n",
      "Empathy                                  0               0         0   \n",
      "Enthusiastic                             0               0         0   \n",
      "Even-tempered                            0               0         0   \n",
      "Expressive                               0               0         0   \n",
      "Extrinsic Motivators                     0               0         0   \n",
      "Identification                           0               0         0   \n",
      "Identity                                 0               0         0   \n",
      "Inspirational                            0               0         0   \n",
      "Intrinsic Motivators                     0               0         0   \n",
      "Motivators                               0               0         0   \n",
      "Organization                             0               0         0   \n",
      "Personal Motivators                      0               0         0   \n",
      "Precise                                  0               0         0   \n",
      "Sociability                              0               0         0   \n",
      "\n",
      "                      Inspirational  Intrinsic Motivators  Motivators  \\\n",
      "Accommodating                     0                     0           0   \n",
      "Active Listening                  0                     0           0   \n",
      "Analytical                        0                     0           0   \n",
      "Analytical Nature                 0                     0           0   \n",
      "Assertiveness                     0                     0           0   \n",
      "Clarity                           0                     0           0   \n",
      "Competitive                       0                     0           0   \n",
      "Cooperativeness                   0                     0           0   \n",
      "Empathy                           0                     0           0   \n",
      "Enthusiastic                      0                     0           0   \n",
      "Even-tempered                     0                     0           0   \n",
      "Expressive                        1                     0           0   \n",
      "Extrinsic Motivators              0                     1           0   \n",
      "Identification                    0                     0           0   \n",
      "Identity                          0                     0           0   \n",
      "Inspirational                     0                     0           0   \n",
      "Intrinsic Motivators              0                     0           0   \n",
      "Motivators                        0                     0           0   \n",
      "Organization                      0                     0           0   \n",
      "Personal Motivators               0                     0           1   \n",
      "Precise                           0                     0           0   \n",
      "Sociability                       0                     0           0   \n",
      "\n",
      "                      Organization  Personal Motivators  Precise  Sociability  \n",
      "Accommodating                    0                    0        0            0  \n",
      "Active Listening                 0                    0        0            0  \n",
      "Analytical                       0                    0        1            0  \n",
      "Analytical Nature                0                    0        0            0  \n",
      "Assertiveness                    0                    0        0            0  \n",
      "Clarity                          0                    0        0            0  \n",
      "Competitive                      0                    0        0            0  \n",
      "Cooperativeness                  0                    0        0            0  \n",
      "Empathy                          0                    0        0            0  \n",
      "Enthusiastic                     0                    0        0            0  \n",
      "Even-tempered                    0                    0        0            0  \n",
      "Expressive                       0                    0        0            0  \n",
      "Extrinsic Motivators             0                    0        0            0  \n",
      "Identification                   1                    0        0            0  \n",
      "Identity                         0                    0        0            0  \n",
      "Inspirational                    0                    0        0            0  \n",
      "Intrinsic Motivators             0                    0        0            0  \n",
      "Motivators                       0                    0        0            0  \n",
      "Organization                     0                    0        0            0  \n",
      "Personal Motivators              0                    0        0            0  \n",
      "Precise                          0                    0        0            0  \n",
      "Sociability                      0                    0        0            0  \n",
      "\n",
      "[22 rows x 22 columns]\n",
      "üèÉ View run DISC_RF_Training at: http://127.0.0.1:5000/#/experiments/886681214121108750/runs/8e2f1ffcb4d54c05b393998555b6bb4e\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/886681214121108750\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"DISC\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Load embeddings dataset ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "embeddings_csv_path = '../Embeddings/disc_embeddings.csv'\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        embeddings_csv_path,\n",
    "        converters={'Embedding': lambda s: np.array(eval(s)) if isinstance(s, str) else np.array(s)}\n",
    "    )\n",
    "    print(f\"‚úÖ Embeddings dataset loaded from: {embeddings_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: Embeddings dataset not found at: {embeddings_csv_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Load the pre-fitted label encoder ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "label_encoder_path = \"../Models/disc_label_encoder.pkl\"\n",
    "try:\n",
    "    label_encoder = joblib.load(label_encoder_path)\n",
    "    print(f\"‚úÖ Label encoder loaded from: {label_encoder_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: Label encoder not found at: {label_encoder_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Prepare features and labels ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df['Embedding'].values)      # (n_samples, embedding_dim)\n",
    "y = df['Factor'].values                   # DISC factor labels\n",
    "y_encoded = label_encoder.transform(y)    # numeric labels\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Split into train/test ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "counts = pd.Series(y_encoded).value_counts()\n",
    "stratify_param = y_encoded if counts.min() >= 2 else None\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded,\n",
    "    test_size=0.4,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=stratify_param\n",
    ")\n",
    "print(f\"Train samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
    "if stratify_param is None:\n",
    "    print(\"‚ö†Ô∏è  Skipped stratification because at least one class has only 1 sample.\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 5) Start MLflow run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"DISC_RF_Training\") as run:\n",
    "    mlflow.log_param(\"model_type\", \"RandomForestClassifier\")\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"test_size\", 0.4)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_artifact(label_encoder_path, artifact_path=\"label_encoder\")\n",
    "\n",
    "    start_ts = datetime.now()\n",
    "    mlflow.log_param(\"start_time\", str(start_ts))\n",
    "    print(f\"‚è≥ Training started at {start_ts}\")\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    end_ts = datetime.now()\n",
    "    mlflow.log_param(\"end_time\", str(end_ts))\n",
    "    print(f\"‚úÖ Training finished at {end_ts} (Duration: {end_ts - start_ts})\")\n",
    "\n",
    "    # Predict & evaluate\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    print(f\"üîç Test accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Only include labels actually present\n",
    "    present = np.unique(np.concatenate([y_test, y_pred]))\n",
    "    names   = [label_encoder.classes_[i] for i in present]\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(\n",
    "        y_test, y_pred,\n",
    "        labels=present,\n",
    "        target_names=names,\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_path = \"disc_classification_report.csv\"\n",
    "    report_df.to_csv(report_path, index=True)\n",
    "    mlflow.log_artifact(report_path, artifact_path=\"metrics\")\n",
    "    print(f\"üìä Classification report saved to {report_path}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=present)\n",
    "    cm_df = pd.DataFrame(cm, index=names, columns=names)\n",
    "    cm_csv = \"disc_confusion_matrix.csv\"\n",
    "    cm_df.to_csv(cm_csv, index=True)\n",
    "    mlflow.log_artifact(cm_csv, artifact_path=\"metrics\")\n",
    "    print(f\"üìä Confusion matrix saved to {cm_csv}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"DISC RandomForest Confusion Matrix\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.tight_layout()\n",
    "    cm_img = \"disc_confusion_matrix.png\"\n",
    "    plt.savefig(cm_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cm_img, artifact_path=\"metrics\")\n",
    "    print(f\"üñºÔ∏è Saved confusion matrix plot to {cm_img}\")\n",
    "\n",
    "    # Save trained model\n",
    "    os.makedirs(\"../Models\", exist_ok=True)\n",
    "    model_path = \"../Models/disc_rf_model.pkl\"\n",
    "    joblib.dump(clf, model_path)\n",
    "    mlflow.log_artifact(model_path, artifact_path=\"models\")\n",
    "    print(f\"üíæ Trained model saved to {model_path}\")\n",
    "\n",
    "    # Final printout\n",
    "    print(\"\\nClassification Report:\\n\",\n",
    "          classification_report(y_test, y_pred, labels=present, target_names=names, zero_division=0))\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3656c2b1-5d3d-489d-9759-ed219e20d2b5",
   "metadata": {},
   "source": [
    "This block of code is a comprehensive step-by-step process focusing specifically on:\n",
    "1. **Data Loading and Preprocessing**: Parsing and preparing embeddings from a CSV file for machine learning.\n",
    "2. **Model Training**: Using a RandomForestClassifier to train on the embeddings.\n",
    "3. **Model Evaluation**: Calculating and logging metrics such as accuracy, alongside detailed classification reports and confusion matrices.\n",
    "4. **Visualization and Logging**: Visualizing the confusion matrix and logging both the visual represendiscion and numerical data as artifacts in MLflow.\n",
    "5. **Model Persistence**: Saving the trained model for future use or deployment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b586cb-65eb-4f24-9726-c7b61611182c",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 7: Evaluate Model** <a class=\"anchor\" id=\"disc_page_3\"></a>\n",
    "\n",
    "[Back to Top](#disc_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bbc78ca-7e53-4ab5-8c7c-c2d2848d4367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings dataset loaded from: ../Embeddings/disc_embeddings.csv\n",
      "‚úÖ Label encoder loaded from: ../Models/disc_label_encoder.pkl\n",
      "‚úÖ Trained model loaded from: ../Models/disc_rf_model.pkl\n",
      "Train size: 18, Test size: 13\n",
      "‚ö†Ô∏è  Skipped stratification because at least one class has only 1 sample.\n",
      "üîç Test accuracy: 0.0000\n",
      "üìä Classification report saved to disc_evaluation_classification_report.csv\n",
      "üìä Confusion matrix saved to disc_evaluation_confusion_matrix.csv\n",
      "üñºÔ∏è Saved confusion matrix plot to disc_evaluation_confusion_matrix.png\n",
      "üèÉ View run DISC_Model_Evaluation at: http://127.0.0.1:5000/#/experiments/886681214121108750/runs/d6766ffe473b4f7791fbbd0ea127d3b8\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/886681214121108750\n",
      "‚úÖ DISC model evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import mlflow\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"DISC\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Paths ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "embeddings_csv_path = '../Embeddings/disc_embeddings.csv'\n",
    "label_encoder_path  = '../Models/disc_label_encoder.pkl'\n",
    "model_path          = '../Models/disc_rf_model.pkl'\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Load embeddings with converter ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        embeddings_csv_path,\n",
    "        converters={'Embedding': lambda s: np.array(ast.literal_eval(s)) if isinstance(s, str) else np.array(s)}\n",
    "    )\n",
    "    print(f\"‚úÖ Embeddings dataset loaded from: {embeddings_csv_path}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Error loading embeddings: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Load label encoder ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    label_encoder = joblib.load(label_encoder_path)\n",
    "    print(f\"‚úÖ Label encoder loaded from: {label_encoder_path}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Error loading label encoder: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Load trained model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    loaded_clf = joblib.load(model_path)\n",
    "    print(f\"‚úÖ Trained model loaded from: {model_path}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Error loading model: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Prepare features & labels ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df['Embedding'].values)\n",
    "y = df['Factor'].values\n",
    "y_encoded = label_encoder.transform(y)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 5) Train/test split ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Only stratify if every class has at least 2 examples\n",
    "counts = pd.Series(y_encoded).value_counts()\n",
    "stratify_param = y_encoded if counts.min() >= 2 else None\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded,\n",
    "    test_size=0.4,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=stratify_param\n",
    ")\n",
    "print(f\"Train size: {X_train.shape[0]}, Test size: {X_test.shape[0]}\")\n",
    "if stratify_param is None:\n",
    "    print(\"‚ö†Ô∏è  Skipped stratification because at least one class has only 1 sample.\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 6) Evaluate under MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"DISC_Model_Evaluation\"):\n",
    "    mlflow.log_param(\"step\", \"evaluate_model\")\n",
    "    mlflow.log_artifact(label_encoder_path, artifact_path=\"label_encoder\")\n",
    "    mlflow.log_artifact(model_path, artifact_path=\"model\")\n",
    "    mlflow.log_param(\"test_samples\", X_test.shape[0])\n",
    "\n",
    "    # Predict\n",
    "    y_pred = loaded_clf.predict(X_test)\n",
    "\n",
    "    # Accuracy\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    print(f\"üîç Test accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Limit to labels actually present\n",
    "    present = np.unique(np.concatenate([y_test, y_pred]))\n",
    "    names   = [label_encoder.classes_[i] for i in present]\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(\n",
    "        y_test, y_pred,\n",
    "        labels=present,\n",
    "        target_names=names,\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_path = \"disc_evaluation_classification_report.csv\"\n",
    "    report_df.to_csv(report_path, index=True)\n",
    "    mlflow.log_artifact(report_path, artifact_path=\"evaluation\")\n",
    "    print(f\"üìä Classification report saved to {report_path}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=present)\n",
    "    cm_df = pd.DataFrame(cm, index=names, columns=names)\n",
    "    cm_csv = \"disc_evaluation_confusion_matrix.csv\"\n",
    "    cm_df.to_csv(cm_csv, index=True)\n",
    "    mlflow.log_artifact(cm_csv, artifact_path=\"evaluation\")\n",
    "    print(f\"üìä Confusion matrix saved to {cm_csv}\")\n",
    "\n",
    "    # Plot & log confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"DISC Confusion Matrix (Test Set)\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.tight_layout()\n",
    "    cm_img = \"disc_evaluation_confusion_matrix.png\"\n",
    "    plt.savefig(cm_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cm_img, artifact_path=\"evaluation\")\n",
    "    print(f\"üñºÔ∏è Saved confusion matrix plot to {cm_img}\")\n",
    "\n",
    "print(\"‚úÖ DISC model evaluation complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af80057-6c04-4228-ae9b-ed84b87fa9a6",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 8: Test and Evaluate Model** <a class=\"anchor\" id=\"disc_page_3\"></a>\n",
    "\n",
    "[Back to Top](#disc_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe70d8f9-a9eb-4908-bbf9-db62ee23023b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded label encoder from ../Models/disc_label_encoder.pkl\n",
      "‚úÖ Loaded model from ../Models/disc_rf_model.pkl\n",
      "\n",
      "--- Inference on New Data ---\n",
      "1. \"I love going to parties and meeting new people....\" ‚Üí Predicted Factor: Clarity\n",
      "2. \"I prefer staying home with a good book....\" ‚Üí Predicted Factor: Enthusiastic\n",
      "3. \"I often feel anxious and worried....\" ‚Üí Predicted Factor: Experience\n",
      "4. \"I am generally calm and relaxed....\" ‚Üí Predicted Factor: Adventurous\n",
      "5. \"I enjoy taking risks and trying new things....\" ‚Üí Predicted Factor: Enthusiastic\n",
      "üèÉ View run Step 7: Model Testing (Inference on New Data) at: http://127.0.0.1:5000/#/experiments/886681214121108750/runs/1fca36fc0704403391ebad11a290d3d2\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/886681214121108750\n",
      "‚úÖ Model testing (inference) complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import mlflow\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"DISC\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Initialize OpenAI client ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def get_openai_api_key_from_file(filepath='~/openai_api_key.txt'):\n",
    "    filepath = os.path.expanduser(filepath)\n",
    "    with open(filepath, 'r') as f:\n",
    "        key = f.read().strip()\n",
    "    if not key:\n",
    "        raise ValueError(f\"No API key in {filepath}\")\n",
    "    return key\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", None) or get_openai_api_key_from_file()\n",
    "client  = OpenAI(api_key=api_key)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Paths ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "label_encoder_path = \"../Models/disc_label_encoder.pkl\"\n",
    "model_path         = \"../Models/disc_rf_model.pkl\"\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Helper: generate embedding ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    resp = client.embeddings.create(input=[text], model=model)\n",
    "    return resp.data[0].embedding\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Start MLflow run for inference ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"Step 7: Model Testing (Inference on New Data)\"):\n",
    "    mlflow.log_param(\"step\", \"Model Testing\")\n",
    "    mlflow.log_artifact(label_encoder_path, artifact_path=\"label_encoder\")\n",
    "    mlflow.log_artifact(model_path, artifact_path=\"model\")\n",
    "\n",
    "    # Load artifacts\n",
    "    label_encoder = joblib.load(label_encoder_path)\n",
    "    print(f\"‚úÖ Loaded label encoder from {label_encoder_path}\")\n",
    "    clf = joblib.load(model_path)\n",
    "    print(f\"‚úÖ Loaded model from {model_path}\")\n",
    "\n",
    "    # Inference function\n",
    "    def predict_factor(text: str) -> str:\n",
    "        emb = get_embedding(text)\n",
    "        code = clf.predict([emb])[0]\n",
    "        return label_encoder.inverse_transform([code])[0]\n",
    "\n",
    "    # Example inputs\n",
    "    test_texts = [\n",
    "        \"I love going to parties and meeting new people.\",\n",
    "        \"I prefer staying home with a good book.\",\n",
    "        \"I often feel anxious and worried.\",\n",
    "        \"I am generally calm and relaxed.\",\n",
    "        \"I enjoy taking risks and trying new things.\"\n",
    "    ]\n",
    "    mlflow.log_param(\"num_test_texts\", len(test_texts))\n",
    "\n",
    "    print(\"\\n--- Inference on New Data ---\")\n",
    "    for idx, txt in enumerate(test_texts, start=1):\n",
    "        try:\n",
    "            pred = predict_factor(txt)\n",
    "            print(f\"{idx}. \\\"{txt[:50]}...\\\" ‚Üí Predicted Factor: {pred}\")\n",
    "            mlflow.log_param(f\"text_{idx}\", txt)\n",
    "            mlflow.log_param(f\"predicted_factor_{idx}\", pred)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error on input {idx}: {e}\")\n",
    "            mlflow.log_param(f\"error_text_{idx}\", str(e))\n",
    "\n",
    "print(\"‚úÖ Model testing (inference) complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dc0d50-5e9f-4b73-bb5f-f8e64b2c1f62",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 9: Visualize and Evaluate Model** <a class=\"anchor\" id=\"disc_page_3\"></a>\n",
    "\n",
    "[Back to Top](#disc_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02e69b18-6364-4067-98b8-4c144511dee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded embeddings from: ../Embeddings/disc_embeddings.csv\n",
      "‚è≥ Run started at 2025-05-25 15:14:58.100339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/05/25 15:15:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç In-sample accuracy: 1.0000\n",
      "‚úÖ Run finished at 2025-05-25 15:15:01.844748 (Duration: 0:00:03.744409)\n",
      "\n",
      "Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Accommodating       1.00      1.00      1.00         1\n",
      "    Active Listening       1.00      1.00      1.00         2\n",
      "         Adventurous       1.00      1.00      1.00         1\n",
      "          Analytical       1.00      1.00      1.00         1\n",
      "   Analytical Nature       1.00      1.00      1.00         1\n",
      "       Assertiveness       1.00      1.00      1.00         2\n",
      "            Cautious       1.00      1.00      1.00         1\n",
      "             Clarity       1.00      1.00      1.00         1\n",
      "         Competitive       1.00      1.00      1.00         1\n",
      "     Cooperativeness       1.00      1.00      1.00         1\n",
      "             Empathy       1.00      1.00      1.00         1\n",
      "        Enthusiastic       1.00      1.00      1.00         1\n",
      "       Even-tempered       1.00      1.00      1.00         1\n",
      "          Experience       1.00      1.00      1.00         1\n",
      "          Expressive       1.00      1.00      1.00         1\n",
      "Extrinsic Motivators       1.00      1.00      1.00         1\n",
      "           Hierarchy       1.00      1.00      1.00         1\n",
      "      Identification       1.00      1.00      1.00         1\n",
      "            Identity       1.00      1.00      1.00         1\n",
      "         Independent       1.00      1.00      1.00         1\n",
      "       Inspirational       1.00      1.00      1.00         1\n",
      "Interpersonal Skills       1.00      1.00      1.00         1\n",
      "Intrinsic Motivators       1.00      1.00      1.00         1\n",
      "          Motivators       1.00      1.00      1.00         1\n",
      "        Organization       1.00      1.00      1.00         1\n",
      "             Patient       1.00      1.00      1.00         1\n",
      " Personal Motivators       1.00      1.00      1.00         1\n",
      "             Precise       1.00      1.00      1.00         1\n",
      "         Sociability       1.00      1.00      1.00         1\n",
      "\n",
      "            accuracy                           1.00        31\n",
      "           macro avg       1.00      1.00      1.00        31\n",
      "        weighted avg       1.00      1.00      1.00        31\n",
      "\n",
      "üèÉ View run DISC_Visualization_and_Eval at: http://127.0.0.1:5000/#/experiments/886681214121108750/runs/47cf47ea1c664b84b3bae9f828673e99\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/886681214121108750\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"DISC\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Load embeddings with safe parsing ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "embeddings_csv_path = '../Embeddings/disc_embeddings.csv'\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        embeddings_csv_path,\n",
    "        converters={'Embedding': lambda s: np.array(ast.literal_eval(s)) if isinstance(s, str) else np.array(s)}\n",
    "    )\n",
    "    print(f\"‚úÖ Loaded embeddings from: {embeddings_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå File not found: {embeddings_csv_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Prepare features and labels ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df['Embedding'].values)\n",
    "y = df['Factor'].values\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Start MLflow run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"DISC_Visualization_and_Eval\"):\n",
    "    mlflow.log_param(\"step\", \"visualize_and_evaluate\")\n",
    "    mlflow.log_param(\"dataset\", embeddings_csv_path)\n",
    "    start_ts = datetime.now()\n",
    "    mlflow.log_param(\"start_time\", str(start_ts))\n",
    "    print(f\"‚è≥ Run started at {start_ts}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 4) Train a RandomForest on full data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X, y_encoded)\n",
    "    mlflow.sklearn.log_model(clf, \"disc_rf_model\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 5) In-sample evaluation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    y_pred = clf.predict(X)\n",
    "    acc = accuracy_score(y_encoded, y_pred)\n",
    "    mlflow.log_metric(\"in_sample_accuracy\", acc)\n",
    "    print(f\"üîç In-sample accuracy: {acc:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(y_encoded, y_pred)\n",
    "    cm_df = pd.DataFrame(cm, index=le.classes_, columns=le.classes_)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"Confusion Matrix (In-Sample)\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.tight_layout()\n",
    "    cm_img = \"disc_confusion_matrix.png\"\n",
    "    plt.savefig(cm_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cm_img, artifact_path=\"evaluation\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 6) PCA visualization ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    scatter = plt.scatter(X_pca[:,0], X_pca[:,1], c=y_encoded, cmap='viridis', alpha=0.7)\n",
    "    handles, _ = scatter.legend_elements()\n",
    "    plt.legend(handles, le.classes_, title=\"Factor\")\n",
    "    plt.title(\"PCA of DiSC Embeddings\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.tight_layout()\n",
    "    pca_img = \"disc_pca.png\"\n",
    "    plt.savefig(pca_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(pca_img, artifact_path=\"visualization\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 7) K-Means clustering ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X)\n",
    "    df['Cluster'] = clusters\n",
    "    clustered_path = '../Embeddings/disc_clustered_embeddings.csv'\n",
    "    os.makedirs(os.path.dirname(clustered_path), exist_ok=True)\n",
    "    df.to_csv(clustered_path, index=False)\n",
    "    mlflow.log_artifact(clustered_path, artifact_path=\"clustered_data\")\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    scatter = plt.scatter(X_pca[:,0], X_pca[:,1], c=clusters, cmap='tab10', alpha=0.7)\n",
    "    plt.title(\"K-Means Clusters of DiSC Embeddings\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.tight_layout()\n",
    "    cluster_img = \"disc_clusters.png\"\n",
    "    plt.savefig(cluster_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cluster_img, artifact_path=\"visualization\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 8) Log end time ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    end_ts = datetime.now()\n",
    "    mlflow.log_param(\"end_time\", str(end_ts))\n",
    "    print(f\"‚úÖ Run finished at {end_ts} (Duration: {end_ts - start_ts})\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 9) Optional: print classification report ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    report = classification_report(y_encoded, y_pred, target_names=le.classes_, zero_division=0)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d6c46-cbed-44b1-acd1-f36a71195fca",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 10: Save Visualization and Evaluation of Model** <a class=\"anchor\" id=\"disc_page_3\"></a>\n",
    "\n",
    "[Back to Top](#disc_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b7e7cb8-ba04-4b99-b982-7dde60729478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded embeddings from: ../Embeddings/disc_embeddings.csv\n",
      "‚úÖ LabelEncoder loaded from: ../Models/disc_label_encoder.pkl\n",
      "‚úÖ RandomForest model loaded from: ../Models/disc_rf_model.pkl\n",
      "‚è≥ Run started at 2025-05-25 15:16:04.176401\n",
      "‚úÖ PCA plot saved: disc_pca.png\n",
      "‚úÖ Clustered data saved: ../Embeddings/disc_clustered_embeddings.csv\n",
      "‚úÖ Cluster plot saved: disc_clusters.png\n",
      "‚úÖ Run finished at 2025-05-25 15:16:04.326327 (Duration: 0:00:00.149926)\n",
      "üèÉ View run DISC_PCA_and_Clustering at: http://127.0.0.1:5000/#/experiments/886681214121108750/runs/88192e298f2d46e980b4a96847d460a6\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/886681214121108750\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import joblib\n",
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"DISC\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Paths ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "EMBEDDINGS_CSV       = '../Embeddings/disc_embeddings.csv'\n",
    "LABEL_ENCODER_PKL    = '../Models/disc_label_encoder.pkl'\n",
    "RF_MODEL_PKL         = '../Models/disc_rf_model.pkl'\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Load embeddings with safe parsing ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        EMBEDDINGS_CSV,\n",
    "        converters={'Embedding': lambda s: np.array(ast.literal_eval(s)) if isinstance(s, str) else np.array(s)}\n",
    "    )\n",
    "    print(f\"‚úÖ Loaded embeddings from: {EMBEDDINGS_CSV}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Embeddings CSV not found: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Load artifacts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    label_encoder = joblib.load(LABEL_ENCODER_PKL)\n",
    "    print(f\"‚úÖ LabelEncoder loaded from: {LABEL_ENCODER_PKL}\")\n",
    "    rf_model       = joblib.load(RF_MODEL_PKL)\n",
    "    print(f\"‚úÖ RandomForest model loaded from: {RF_MODEL_PKL}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Artifact missing: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Prepare data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df['Embedding'].values)\n",
    "y = df['Factor'].values\n",
    "y_encoded = label_encoder.transform(y)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 5) Begin MLflow run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"DISC_PCA_and_Clustering\") as run:\n",
    "    mlflow.log_param(\"step\", \"PCA_and_KMeans\")\n",
    "    mlflow.log_param(\"embeddings_csv\", EMBEDDINGS_CSV)\n",
    "    start_ts = datetime.now()\n",
    "    mlflow.log_param(\"start_time\", str(start_ts))\n",
    "    print(f\"‚è≥ Run started at {start_ts}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 6) PCA visualization ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    scatter = plt.scatter(X_pca[:,0], X_pca[:,1], c=y_encoded, cmap='viridis', alpha=0.7)\n",
    "    handles, _ = scatter.legend_elements()\n",
    "    plt.legend(handles, label_encoder.classes_, title=\"Factor\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.title(\"PCA of DiSC Embeddings\")\n",
    "    plt.tight_layout()\n",
    "    pca_img = \"disc_pca.png\"\n",
    "    plt.savefig(pca_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(pca_img, artifact_path=\"visualization\")\n",
    "    print(f\"‚úÖ PCA plot saved: {pca_img}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 7) K-Means clustering ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    n_clusters = 4\n",
    "    mlflow.log_param(\"n_clusters\", n_clusters)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X)\n",
    "    df['Cluster'] = clusters\n",
    "\n",
    "    clustered_csv = '../Embeddings/disc_clustered_embeddings.csv'\n",
    "    os.makedirs(os.path.dirname(clustered_csv), exist_ok=True)\n",
    "    df.to_csv(clustered_csv, index=False)\n",
    "    mlflow.log_artifact(clustered_csv, artifact_path=\"clustered_data\")\n",
    "    print(f\"‚úÖ Clustered data saved: {clustered_csv}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    scatter = plt.scatter(X_pca[:,0], X_pca[:,1], c=clusters, cmap='tab10', alpha=0.7)\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.title(\"K-Means Clusters of DiSC Embeddings\")\n",
    "    plt.tight_layout()\n",
    "    cluster_img = \"disc_clusters.png\"\n",
    "    plt.savefig(cluster_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cluster_img, artifact_path=\"visualization\")\n",
    "    print(f\"‚úÖ Cluster plot saved: {cluster_img}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 8) End run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    end_ts = datetime.now()\n",
    "    mlflow.log_param(\"end_time\", str(end_ts))\n",
    "    print(f\"‚úÖ Run finished at {end_ts} (Duration: {end_ts - start_ts})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013ba63c-ce13-4667-a5d9-a799ab883b97",
   "metadata": {},
   "source": [
    "This block of code integrates several stages that not only include training but also applying the model to new data and exploring the data through clustering:\n",
    "1. **Data Loading and Feature Parsing**: Similar to Block 1, with an additional step of displaying the parsed data.\n",
    "2. **Model Creation and Logging**: Training a RandomForestClassifier and logging the model directly with MLflow for possibly immediate deployment.\n",
    "3. **Model Evaluation and Reporting**: Assessing model performance with metrics and detailed reports, and logging these evaluations.\n",
    "4. **Clustering Analysis**: Utilizing KMeans to perform clustering on the embeddings, which adds an exploratory data analysis component.\n",
    "5. **Model Application on New Data**: Demonstrating a practical application of the trained model to predict factors for new text inputs.\n",
    "6. **End-to-End Experiment Tracking**: From the beginning of the run to its completion, tracking all parameters, artifacts, and outcomes, emphasizing a full-cycle view of the modeling process.\n",
    "\n",
    "This provides a broader overview of how a model can be developed and applied within a workflow that includes prediction and clustering alongside the fundamental steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f3cfce-24bd-4f6c-a748-54b1fe39d107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5916893-8b0f-450f-9ce6-09015901f5eb",
   "metadata": {},
   "source": [
    "The results show that the RandomForestClassifier model trained on the dataset of embeddings has achieved an accuracy of 1.0 on the test set, which means it has correctly classified all the test samples. Here is the breakdown of the evaluation:\n",
    "\n",
    "### Accuracy:\n",
    "- **1.0**: The model has 100% accuracy, meaning it correctly classified every instance in the test set.\n",
    "\n",
    "### Classification Report:\n",
    "- **Precision, Recall, and F1-score** for each class (0 through 4) are all 1.00.\n",
    "- **Support** indicates the number of actual occurrences of each class in the test set.\n",
    "\n",
    "### Interprediscion:\n",
    "- **Precision**: This is the ratio of true positive predictions to the total predicted positives. A precision of 1.0 means that all instances predicted as a specific class were actually of that class.\n",
    "- **Recall**: This is the ratio of true positive predictions to the total actual positives. A recall of 1.0 means that all actual instances of a specific class were correctly predicted.\n",
    "- **F1-score**: This is the harmonic mean of precision and recall. An F1-score of 1.0 indicates perfect precision and recall.\n",
    "- **Support**: This indicates the number of true instances for each label in the test set. \n",
    "\n",
    "### Considerations:\n",
    "1. **Model Overfitting**: The perfect score could indicate overfitting, especially if the test set is small or not represendiscive of unseen data.\n",
    "2. **Test Set Size**: The test set has only 24 samples, which is relatively small. It's important to ensure that the test set is large enough and represendiscive to get a reliable estimate of model performance.\n",
    "3. **Data Leakage**: Double-check that there's no data leakage, meaning that no information from the test set was used during training.\n",
    "4. **Cross-Validation**: To better assess the model's performance, consider using cross-validation to ensure the model performs well across different subsets of the data.\n",
    "\n",
    "### Next Steps:\n",
    "- **Cross-validation**: Implement cross-validation to get a more robust evaluation of model performance.\n",
    "- **Larger Test Set**: If possible, increase the size of the test set to ensure the performance metrics are reliable.\n",
    "- **Feature Analysis**: Examine feature importance scores from the RandomForestClassifier to understand which parts of the embeddings contribute most to the predictions.\n",
    "\n",
    "### Updated Code for Cross-Validation:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(clf, X, y_encoded, cv=5)  # 5-fold cross-validation\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean cross-validation score: {np.mean(cv_scores)}\")\n",
    "```\n",
    "\n",
    "We added this cross-validation step will help us verify that the model generalizes well and is not just performing well on a small or potentially non-represendiscive test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16fac8dd-46d3-4595-99f0-f15b83e244a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂ Class counts (encoded ‚Üí factor):\n",
      "  0 (Accommodating): 1 samples\n",
      "  1 (Active Listening): 2 samples\n",
      "  2 (Adventurous): 1 samples\n",
      "  3 (Analytical): 1 samples\n",
      "  4 (Analytical Nature): 1 samples\n",
      "  5 (Assertiveness): 2 samples\n",
      "  6 (Cautious): 1 samples\n",
      "  7 (Clarity): 1 samples\n",
      "  8 (Competitive): 1 samples\n",
      "  9 (Cooperativeness): 1 samples\n",
      "  10 (Empathy): 1 samples\n",
      "  11 (Enthusiastic): 1 samples\n",
      "  12 (Even-tempered): 1 samples\n",
      "  13 (Experience): 1 samples\n",
      "  14 (Expressive): 1 samples\n",
      "  15 (Extrinsic Motivators): 1 samples\n",
      "  16 (Hierarchy): 1 samples\n",
      "  17 (Identification): 1 samples\n",
      "  18 (Identity): 1 samples\n",
      "  19 (Independent): 1 samples\n",
      "  20 (Inspirational): 1 samples\n",
      "  21 (Interpersonal Skills): 1 samples\n",
      "  22 (Intrinsic Motivators): 1 samples\n",
      "  23 (Motivators): 1 samples\n",
      "  24 (Organization): 1 samples\n",
      "  25 (Patient): 1 samples\n",
      "  26 (Personal Motivators): 1 samples\n",
      "  27 (Precise): 1 samples\n",
      "  28 (Sociability): 1 samples\n",
      "‚ñ∂ Using LeaveOneOut CV (31 splits)\n",
      "Leave-One-Out accuracy scores: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]‚Ä¶  (31 total)\n",
      "Mean LOO accuracy: 0.0323\n",
      "Std  LOO accuracy: 0.1767\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "\n",
    "# 1) Inspect class distribution\n",
    "dist = pd.Series(y_encoded).value_counts().sort_index()\n",
    "print(\"‚ñ∂ Class counts (encoded ‚Üí factor):\")\n",
    "for code, cnt in dist.items():\n",
    "    print(f\"  {code} ({label_encoder.inverse_transform([code])[0]}): {cnt} samples\")\n",
    "\n",
    "# 2) Choose Leave-One-Out CV (forces train on all but one sample)\n",
    "loo = LeaveOneOut()\n",
    "print(f\"‚ñ∂ Using LeaveOneOut CV ({loo.get_n_splits(X)} splits)\")\n",
    "\n",
    "# 3) Compute CV accuracy\n",
    "cv_scores = cross_val_score(\n",
    "    clf,\n",
    "    X,\n",
    "    y_encoded,\n",
    "    cv=loo,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 4) Summarize results\n",
    "print(f\"Leave-One-Out accuracy scores: {cv_scores[:10]}‚Ä¶  ({len(cv_scores)} total)\")\n",
    "print(f\"Mean LOO accuracy: {cv_scores.mean():.4f}\")\n",
    "print(f\"Std  LOO accuracy: {cv_scores.std():.4f}\")\n",
    "\n",
    "# 5) Log to MLflow\n",
    "mlflow.log_param(\"cv_method\", \"LeaveOneOut\")\n",
    "mlflow.log_metric(\"loo_mean_accuracy\", cv_scores.mean())\n",
    "mlflow.log_metric(\"loo_std_accuracy\", cv_scores.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adf2f5ea-3181-4f0f-8a62-c95784cac78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded embeddings.\n",
      "‚úÖ Loaded existing RandomForest model.\n",
      "Domains: ['Person', 'Type', 'Workplace Priorities']\n",
      "Train/test sizes: 18/13\n",
      "‚úÖ Trained new RandomForest on Domain target.\n",
      "Test accuracy (Domain): 0.846\n",
      "‚úÖ Confusion matrix saved to domain_cm.png\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "              Person       0.00      0.00      0.00         2\n",
      "                Type       0.78      1.00      0.88         7\n",
      "Workplace Priorities       1.00      1.00      1.00         4\n",
      "\n",
      "            accuracy                           0.85        13\n",
      "           macro avg       0.59      0.67      0.62        13\n",
      "        weighted avg       0.73      0.85      0.78        13\n",
      "\n",
      "\n",
      "5-fold CV accuracy: [1.    0.833 0.833 1.    1.   ]\n",
      "Mean CV acc: 0.933 ¬± 0.082\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Load embeddings ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "df = pd.read_csv(\n",
    "    '../Embeddings/disc_embeddings.csv',\n",
    "    converters={'Embedding': lambda s: np.array(eval(s)) if isinstance(s, str) else np.array(s)}\n",
    ")\n",
    "print(\"‚úÖ Loaded embeddings.\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Load the original RF model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "rf = joblib.load(\"../Models/disc_rf_model.pkl\")\n",
    "print(\"‚úÖ Loaded existing RandomForest model.\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Prepare features & Domain labels ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df['Embedding'].values)\n",
    "y_dom = df['Domain'].values\n",
    "le_dom = LabelEncoder()\n",
    "y = le_dom.fit_transform(y_dom)\n",
    "print(\"Domains:\", list(le_dom.classes_))\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Train/test split (stratified on Domain) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Train/test sizes: {X_train.shape[0]}/{X_test.shape[0]}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 5) Train a fresh RF on Domain ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"‚úÖ Trained new RandomForest on Domain target.\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 6) Evaluate on hold-out set ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test accuracy (Domain): {acc:.3f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=le_dom.classes_, columns=le_dom.classes_)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix (Domain)\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"domain_cm.png\")\n",
    "plt.close()\n",
    "print(\"‚úÖ Confusion matrix saved to domain_cm.png\")\n",
    "\n",
    "# Classification report with zero_division=0\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    target_names=le_dom.classes_,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 7) Stratified 5-fold CV on Domain ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(clf, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"\\n5-fold CV accuracy: {cv_scores.round(3)}\")\n",
    "print(f\"Mean CV acc: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d8667c-30e8-4db0-8fca-03ccb53d773e",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 11: Test Model Directly** <a class=\"anchor\" id=\"disc_page_3\"></a>\n",
    "\n",
    "[Back to Top](#disc_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d8b6c39-c12d-4076-95e4-692d7a89371d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 31 rows from ../Embeddings/disc_embeddings.csv\n",
      "‚úÖ Loaded label encoder and RandomForest model.\n",
      "\n",
      "--- Model Predictions on New Examples ---\n",
      "Dominance / Competitiveness:\n",
      "  Input: \"Assertive Competitive Win Achieve\"\n",
      "  ‚Üí Predicted Factor: Assertiveness\n",
      "\n",
      "Influence / Sociability:\n",
      "  Input: \"Friendly Talkative Enthusiastic Engage\"\n",
      "  ‚Üí Predicted Factor: Accommodating\n",
      "\n",
      "Steadiness / Patience:\n",
      "  Input: \"Calm Patient Supportive Stable\"\n",
      "  ‚Üí Predicted Factor: Accommodating\n",
      "\n",
      "Conscientiousness / Precision:\n",
      "  Input: \"Meticulous Analytical Structured Detail\"\n",
      "  ‚Üí Predicted Factor: Clarity\n",
      "\n",
      "Risk-Taking / Adventure:\n",
      "  Input: \"Bold Adventurous Dare Explore\"\n",
      "  ‚Üí Predicted Factor: Adventurous\n",
      "\n",
      "Analytical Thinking / Logic:\n",
      "  Input: \"Logical Systematic Reason Evaluate\"\n",
      "  ‚Üí Predicted Factor: Competitive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Setup OpenAI client ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "def get_openai_api_key_from_file(filepath='~/openai_api_key.txt'):\n",
    "    filepath = os.path.expanduser(filepath)\n",
    "    with open(filepath, 'r') as f:\n",
    "        key = f.read().strip()\n",
    "    if not key:\n",
    "        raise ValueError(f\"No API key found in {filepath}\")\n",
    "    return key\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\") or get_openai_api_key_from_file()\n",
    "client  = OpenAI(api_key=api_key)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Load embeddings CSV ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "embeddings_csv = '../Embeddings/disc_embeddings.csv'\n",
    "df = pd.read_csv(\n",
    "    embeddings_csv,\n",
    "    converters={'Embedding': lambda s: np.array(ast.literal_eval(s)) if isinstance(s, str) else np.array(s)}\n",
    ")\n",
    "print(f\"‚úÖ Loaded {len(df)} rows from {embeddings_csv}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Prepare features ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X = np.stack(df['Embedding'].values)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Load pretrained artifacts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "label_encoder = joblib.load('../Models/disc_label_encoder.pkl')\n",
    "clf           = joblib.load('../Models/disc_rf_model.pkl')\n",
    "print(\"‚úÖ Loaded label encoder and RandomForest model.\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def get_embedding(text: str, model=\"text-embedding-3-small\") -> list:\n",
    "    resp = client.embeddings.create(input=[text], model=model)\n",
    "    return resp.data[0].embedding\n",
    "\n",
    "def predict_factor(text: str) -> str:\n",
    "    emb       = get_embedding(text)\n",
    "    code      = clf.predict([emb])[0]\n",
    "    factor    = label_encoder.inverse_transform([code])[0]\n",
    "    return factor\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Test on meaningful examples ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "test_texts = {\n",
    "    \"Dominance / Competitiveness\":       \"Assertive Competitive Win Achieve\",\n",
    "    \"Influence / Sociability\":           \"Friendly Talkative Enthusiastic Engage\",\n",
    "    \"Steadiness / Patience\":             \"Calm Patient Supportive Stable\",\n",
    "    \"Conscientiousness / Precision\":     \"Meticulous Analytical Structured Detail\",\n",
    "    \"Risk-Taking / Adventure\":           \"Bold Adventurous Dare Explore\",\n",
    "    \"Analytical Thinking / Logic\":       \"Logical Systematic Reason Evaluate\"\n",
    "}\n",
    "\n",
    "print(\"\\n--- Model Predictions on New Examples ---\")\n",
    "for desc, txt in test_texts.items():\n",
    "    try:\n",
    "        pred = predict_factor(txt)\n",
    "        print(f\"{desc}:\\n  Input: \\\"{txt}\\\"\\n  ‚Üí Predicted Factor: {pred}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error on \\\"{txt}\\\": {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab54c21-ee36-4c0e-b9c4-445b11fa65ed",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 12: Test Neo4j Connection** <a class=\"anchor\" id=\"DISC_page_4\"></a>\n",
    "\n",
    "\n",
    "[Back to Top](#DISC_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce3fd307-5fcf-46d7-867d-78ecd5a83887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://localhost:7474/browser/\" target=\"_blank\">üîó Open Neo4j Bolt Connection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Define Neo4j Browser URL\n",
    "neo4j_browser_url = \"http://localhost:7474/browser/\"\n",
    "\n",
    "# Create a clickable link\n",
    "html_code = f'<a href=\"{neo4j_browser_url}\" target=\"_blank\">üîó Open Neo4j Bolt Connection</a>'\n",
    "\n",
    "# Display the clickable link in Jupyter Notebook\n",
    "display(HTML(html_code))\n",
    "\n",
    "# Open the Neo4j Browser in a new tab automatically\n",
    "webbrowser.open_new_tab(neo4j_browser_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a12796f0-11cb-40cb-8c48-e9e20760ed42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bolt port 7687 is reachable!\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "HOST = \"localhost\"\n",
    "PORT = 7687\n",
    "\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "result = sock.connect_ex((HOST, PORT))\n",
    "\n",
    "if result == 0:\n",
    "    print(f\"‚úÖ Bolt port {PORT} is reachable!\")\n",
    "else:\n",
    "    print(f\"‚ùå Bolt port {PORT} is NOT reachable!\")\n",
    "\n",
    "sock.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3abeb19a-7681-4c01-bb52-3b567513142a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Python Connection Failed: Unknown protocol 'neo4j'\n"
     ]
    }
   ],
   "source": [
    "from py2neo import Graph\n",
    "import mlflow\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ End any active MLflow run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Original URI (using neo4j://) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "raw_uri      = \"neo4j://localhost:7687\"\n",
    "NEO4J_USER   = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"mypassword\"\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Rewrite to bolt:// for py2neo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if raw_uri.startswith(\"neo4j://\"):\n",
    "    uri = \"bolt://\" + raw_uri[len(\"neo4j://\"):]\n",
    "else:\n",
    "    uri = raw_uri\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Attempt connection ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    graph = Graph(uri, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    # run a simple test query\n",
    "    message = graph.run(\"RETURN 'Connection successful!' AS message\").evaluate()\n",
    "    print(\"‚úÖ Python Connected Successfully:\", message)\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Python Connection Failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1142a99b-5cc2-4917-b423-5b8d52a45c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Connecting to Bolt URI: bolt://localhost:7687\n",
      "‚ùå Connection failed: Unknown protocol 'neo4j'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown protocol 'neo4j'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 4) Attempt connection\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[43mGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbolt_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpwd\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     greeting \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETURN \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124müéâ Bolt connection successful!\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m AS msg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ\u001b[39m\u001b[38;5;124m\"\u001b[39m, greeting)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/database.py:288\u001b[0m, in \u001b[0;36mGraph.__init__\u001b[0;34m(self, profile, name, **settings)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, profile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings):\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice \u001b[38;5;241m=\u001b[39m \u001b[43mGraphService\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m=\u001b[39m Schema(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/database.py:119\u001b[0m, in \u001b[0;36mGraphService.__init__\u001b[0;34m(self, profile, **settings)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connector_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m profile\u001b[38;5;241m.\u001b[39mrouting:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Ensures credentials are checked on construction\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     connector_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connector \u001b[38;5;241m=\u001b[39m \u001b[43mConnector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconnector_settings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graphs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/client/__init__.py:948\u001b[0m, in \u001b[0;36mConnector.__init__\u001b[0;34m(self, profile, user_agent, init_size, max_size, max_age, routing_refresh_ttl)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, profile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_agent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    946\u001b[0m              max_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_age\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, routing_refresh_ttl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile \u001b[38;5;241m=\u001b[39m ServiceProfile(profile)\n\u001b[0;32m--> 948\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_routers \u001b[38;5;241m=\u001b[39m [\u001b[43mConnectionProfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_agent \u001b[38;5;241m=\u001b[39m user_agent\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server_agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:176\u001b[0m, in \u001b[0;36mConnectionProfile.__init__\u001b[0;34m(self, profile, **settings)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__password \u001b[38;5;241m=\u001b[39m DEFAULT_PASSWORD\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__address \u001b[38;5;241m=\u001b[39m Address\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_env_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:220\u001b[0m, in \u001b[0;36mConnectionProfile._apply_env_vars\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply_env_vars\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m NEO4J_URI:\n\u001b[0;32m--> 220\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNEO4J_URI\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m NEO4J_AUTH:\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_settings(auth\u001b[38;5;241m=\u001b[39mNEO4J_AUTH)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:232\u001b[0m, in \u001b[0;36mConnectionProfile._apply_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    230\u001b[0m parsed \u001b[38;5;241m=\u001b[39m urlsplit(uri)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_scheme\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheme\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mnetloc:\n\u001b[1;32m    234\u001b[0m     settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m parsed\u001b[38;5;241m.\u001b[39mnetloc\u001b[38;5;241m.\u001b[39mpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:249\u001b[0m, in \u001b[0;36mConnectionProfile._apply_scheme\u001b[0;34m(self, scheme)\u001b[0m\n\u001b[1;32m    247\u001b[0m     protocol, _, ext \u001b[38;5;241m=\u001b[39m scheme\u001b[38;5;241m.\u001b[39mpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_settings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_settings(protocol\u001b[38;5;241m=\u001b[39mprotocol, secure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:266\u001b[0m, in \u001b[0;36mConnectionProfile._apply_settings\u001b[0;34m(self, uri, scheme, protocol, secure, verify, address, host, port, port_number, auth, user, password, **other)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_scheme(scheme)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol:\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_protocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m secure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__secure \u001b[38;5;241m=\u001b[39m secure\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:297\u001b[0m, in \u001b[0;36mConnectionProfile._apply_protocol\u001b[0;34m(self, protocol)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply_protocol\u001b[39m(\u001b[38;5;28mself\u001b[39m, protocol):\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbolt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown protocol \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m protocol)\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__protocol \u001b[38;5;241m=\u001b[39m protocol\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown protocol 'neo4j'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from py2neo import Graph\n",
    "import mlflow\n",
    "\n",
    "# 1) Tear down any active MLflow run\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "# 2) Load env\n",
    "load_dotenv(override=True)\n",
    "raw_uri = os.getenv(\"NEO4J_URI\", \"\")\n",
    "user    = os.getenv(\"NEO4J_USERNAME\")\n",
    "pwd     = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "if not raw_uri:\n",
    "    raise RuntimeError(\"‚ùå NEO4J_URI is not set in .env\")\n",
    "if not user or not pwd:\n",
    "    raise RuntimeError(\"‚ùå NEO4J_USERNAME or NEO4J_PASSWORD not set in .env\")\n",
    "\n",
    "# 3) Rewrite protocol\n",
    "if raw_uri.startswith(\"neo4j://\"):\n",
    "    bolt_uri = \"bolt://\" + raw_uri[len(\"neo4j://\"):]\n",
    "else:\n",
    "    bolt_uri = raw_uri\n",
    "\n",
    "print(f\"üîç Connecting to Bolt URI: {bolt_uri}\")\n",
    "\n",
    "# 4) Attempt connection\n",
    "try:\n",
    "    graph = Graph(bolt_uri, auth=(user, pwd))\n",
    "    greeting = graph.run(\"RETURN 'üéâ Bolt connection successful!' AS msg\").evaluate()\n",
    "    print(\"‚úÖ\", greeting)\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Connection failed:\", e)\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54f9b222-dd9d-4205-b4ab-3221085fbe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection failed: Unknown protocol 'neo4j'\n",
      "üèÉ View run Test Neo4j Connection at: http://127.0.0.1:5000/#/experiments/886681214121108750/runs/8f80dd79628a4cda85587faa4064eb8b\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/886681214121108750\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from py2neo import Graph\n",
    "import mlflow\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Load environment ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv()\n",
    "raw_uri       = os.getenv(\"NEO4J_URI\", \"\")\n",
    "NEO4J_USER    = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD= os.getenv(\"NEO4J_PASSWORD\")\n",
    "MLFLOW_URI    = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Fix URI for py2neo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if raw_uri.startswith(\"neo4j://\"):\n",
    "    bolt_uri = \"bolt://\" + raw_uri[len(\"neo4j://\"):]\n",
    "else:\n",
    "    bolt_uri = raw_uri\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Configure MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "mlflow.set_experiment(\"DISC\")\n",
    "\n",
    "def test_neo4j_connection(uri, user, pwd):\n",
    "    graph = Graph(uri, auth=(user, pwd))\n",
    "    return graph.run(\"RETURN 'Connection successful!' AS greeting\").evaluate()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Run the connection test under MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"Test Neo4j Connection\"):\n",
    "    mlflow.log_param(\"Test\", \"Neo4j Connection\")\n",
    "    \n",
    "    try:\n",
    "        result = test_neo4j_connection(bolt_uri, NEO4J_USER, NEO4J_PASSWORD)\n",
    "    except Exception as e:\n",
    "        result = f\"Connection failed: {e}\"\n",
    "    \n",
    "    mlflow.log_param(\"Connection Result\", result)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0ce307e-9ad1-4891-9f4f-8966af9ce07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Test & Clear Neo4j at: http://127.0.0.1:5000/#/experiments/616263351584470447/runs/eb4f1679680a413cbdb421c5375ec9ef\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/616263351584470447\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown protocol 'neo4j'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# ‚îÄ‚îÄ‚îÄ Test & Clear Neo4j inside an MLflow run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run(run_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest & Clear Neo4j\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# 1) Test connection\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtest_neo4j_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNEO4J_URI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNEO4J_USER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNEO4J_PASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection Test\u001b[39m\u001b[38;5;124m\"\u001b[39m, result)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müîó Connection test result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[29], line 26\u001b[0m, in \u001b[0;36mtest_neo4j_connection\u001b[0;34m(uri, user, password)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtest_neo4j_connection\u001b[39m(uri, user, password):\n\u001b[0;32m---> 26\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[43mGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETURN \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConnection successful!\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m AS greeting\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/database.py:288\u001b[0m, in \u001b[0;36mGraph.__init__\u001b[0;34m(self, profile, name, **settings)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, profile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings):\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice \u001b[38;5;241m=\u001b[39m \u001b[43mGraphService\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m=\u001b[39m Schema(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/database.py:119\u001b[0m, in \u001b[0;36mGraphService.__init__\u001b[0;34m(self, profile, **settings)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connector_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m profile\u001b[38;5;241m.\u001b[39mrouting:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Ensures credentials are checked on construction\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     connector_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connector \u001b[38;5;241m=\u001b[39m \u001b[43mConnector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconnector_settings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graphs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/client/__init__.py:948\u001b[0m, in \u001b[0;36mConnector.__init__\u001b[0;34m(self, profile, user_agent, init_size, max_size, max_age, routing_refresh_ttl)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, profile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_agent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    946\u001b[0m              max_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_age\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, routing_refresh_ttl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile \u001b[38;5;241m=\u001b[39m ServiceProfile(profile)\n\u001b[0;32m--> 948\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_routers \u001b[38;5;241m=\u001b[39m [\u001b[43mConnectionProfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_agent \u001b[38;5;241m=\u001b[39m user_agent\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server_agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:176\u001b[0m, in \u001b[0;36mConnectionProfile.__init__\u001b[0;34m(self, profile, **settings)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__password \u001b[38;5;241m=\u001b[39m DEFAULT_PASSWORD\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__address \u001b[38;5;241m=\u001b[39m Address\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_env_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:220\u001b[0m, in \u001b[0;36mConnectionProfile._apply_env_vars\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply_env_vars\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m NEO4J_URI:\n\u001b[0;32m--> 220\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNEO4J_URI\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m NEO4J_AUTH:\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_settings(auth\u001b[38;5;241m=\u001b[39mNEO4J_AUTH)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:232\u001b[0m, in \u001b[0;36mConnectionProfile._apply_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    230\u001b[0m parsed \u001b[38;5;241m=\u001b[39m urlsplit(uri)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_scheme\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheme\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mnetloc:\n\u001b[1;32m    234\u001b[0m     settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m parsed\u001b[38;5;241m.\u001b[39mnetloc\u001b[38;5;241m.\u001b[39mpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:249\u001b[0m, in \u001b[0;36mConnectionProfile._apply_scheme\u001b[0;34m(self, scheme)\u001b[0m\n\u001b[1;32m    247\u001b[0m     protocol, _, ext \u001b[38;5;241m=\u001b[39m scheme\u001b[38;5;241m.\u001b[39mpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_settings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_settings(protocol\u001b[38;5;241m=\u001b[39mprotocol, secure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:266\u001b[0m, in \u001b[0;36mConnectionProfile._apply_settings\u001b[0;34m(self, uri, scheme, protocol, secure, verify, address, host, port, port_number, auth, user, password, **other)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_scheme(scheme)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol:\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_protocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m secure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__secure \u001b[38;5;241m=\u001b[39m secure\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/py2neo/__init__.py:297\u001b[0m, in \u001b[0;36mConnectionProfile._apply_protocol\u001b[0;34m(self, protocol)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply_protocol\u001b[39m(\u001b[38;5;28mself\u001b[39m, protocol):\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbolt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown protocol \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m protocol)\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__protocol \u001b[38;5;241m=\u001b[39m protocol\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown protocol 'neo4j'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from py2neo import Graph\n",
    "import mlflow\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Load environment variables ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Neo4j connection settings ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "raw_uri    = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASS = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "# Normalize URI: use bolt:// if someone set neo4j://\n",
    "if raw_uri and raw_uri.startswith(\"neo4j://\"):\n",
    "    NEO4J_URI = raw_uri.replace(\"neo4j://\", \"bolt://\", 1)\n",
    "else:\n",
    "    NEO4J_URI = raw_uri\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ MLflow tracking setup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(\"MCMI\")\n",
    "\n",
    "def test_neo4j_connection(uri, user, password):\n",
    "    graph = Graph(uri, auth=(user, password))\n",
    "    return graph.run(\"RETURN 'Connection successful!' AS greeting\").evaluate()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Test & Clear Neo4j inside an MLflow run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"Test & Clear Neo4j\"):\n",
    "    # 1) Test connection\n",
    "    result = test_neo4j_connection(NEO4J_URI, NEO4J_USER, NEO4J_PASS)\n",
    "    mlflow.log_param(\"Connection Test\", result)\n",
    "    print(f\"üîó Connection test result: {result}\")\n",
    "\n",
    "    # 2) Clear the entire database\n",
    "    graph = Graph(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASS))\n",
    "    graph.delete_all()\n",
    "    mlflow.log_param(\"Database Cleared\", True)\n",
    "    print(\"üóëÔ∏è  All nodes and relationships have been deleted.\")\n",
    "\n",
    "    # 3) Confirm it's empty\n",
    "    remaining = graph.run(\"MATCH (n) RETURN count(n) AS nodes\").evaluate()\n",
    "    mlflow.log_param(\"Remaining Nodes\", remaining)\n",
    "    print(f\"üìä Remaining node count after clear: {remaining}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a2d41d-2f56-4b50-b4b1-77ebcd2c7279",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 13: Create DISC Schema in Neo4j** <a class=\"anchor\" id=\"DISC_page_4\"></a>\n",
    "\n",
    "\n",
    "[Back to Top](#DISC_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "957e5833-d44d-401d-8df7-0b430efac4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Category         Factor  \\\n",
      "0  Conflict Mode      Competing   \n",
      "1  Conflict Mode      Competing   \n",
      "2  Conflict Mode      Competing   \n",
      "3  Conflict Mode      Competing   \n",
      "4  Conflict Mode  Collaborating   \n",
      "\n",
      "                                           Adjective      Synonym  \\\n",
      "0  Assertive and uncooperative mode, pursuing own...   Aggressive   \n",
      "1  Assertive and uncooperative mode, pursuing own...    Assertive   \n",
      "2  Assertive and uncooperative mode, pursuing own...     Dominant   \n",
      "3  Assertive and uncooperative mode, pursuing own...  Controlling   \n",
      "4  Assertive and cooperative mode, finding mutual...  Cooperative   \n",
      "\n",
      "          Verb           Noun  \\\n",
      "0      Compete    Competition   \n",
      "1       Assert      Assertion   \n",
      "2     Dominate      Dominance   \n",
      "3      Control        Control   \n",
      "4  Collaborate  Collaboration   \n",
      "\n",
      "                                           Embedding  \n",
      "0  [0.018110601231455803, 0.010554433800280094, 0...  \n",
      "1  [0.01708870381116867, 0.009367242455482483, 0....  \n",
      "2  [0.015169601887464523, 0.018460361286997795, 0...  \n",
      "3  [0.017812145873904228, 0.025348054245114326, 0...  \n",
      "4  [0.0023178826086223125, 0.013064720667898655, ...  \n",
      "üèÉ View run Create TKI Schema in Neo4j at: http://127.0.0.1:5000/#/experiments/576605481746526355/runs/fa1d5d1f152047259ec008b102b2a897\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/576605481746526355\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from py2neo import Graph\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Load environment ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv(override=True)\n",
    "NEO4J_URI      = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USER     = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "MLFLOW_URI     = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "mlflow.set_experiment(\"DISC\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Load the flattened DISCembeddings CSV ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "dataset_path = \"../Embeddings/disc_embeddings.csv\"\n",
    "disc_df = pd.read_csv(\n",
    "    dataset_path,\n",
    "    converters={'Embedding': lambda x: ast.literal_eval(x) if isinstance(x, str) else x}\n",
    ")\n",
    "\n",
    "def create_disc_schema(graph: Graph, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Build Neo4j graph with taxonomy:\n",
    "      DISC_Domain -> DISC_Factor -> DISC_Adjective -> {Synonym, Verb, Noun, Embedding}\n",
    "    \"\"\"\n",
    "    for _, row in df.iterrows():\n",
    "        category  = row.get('Domain',  'Unknown')\n",
    "        factor    = row.get('Factor',    'Unknown')\n",
    "        adjective = row.get('Adjective', 'Unknown')\n",
    "        synonym   = row.get('Synonym',   '')\n",
    "        verb      = row.get('Verb',      '')\n",
    "        noun      = row.get('Noun',      '')\n",
    "        embedding = row.get('Embedding') or []\n",
    "\n",
    "        # Skip if core fields missing\n",
    "        if not (category and factor and adjective):\n",
    "            continue\n",
    "\n",
    "        # 1) MERGE Domain node\n",
    "        graph.run(\n",
    "            \"MERGE (c:DISC_Domain {name:$category})\",\n",
    "            category=category\n",
    "        )\n",
    "\n",
    "        # 2) MERGE Factor node + link to Domain\n",
    "        graph.run(\n",
    "            \"MERGE (f:DISC_Factor {name:$factor})\",\n",
    "            factor=factor\n",
    "        )\n",
    "        graph.run(\n",
    "            \"\"\"\n",
    "            MATCH (c:DISC_Domain {name:$category}), (f:DISC_Factor {name:$factor})\n",
    "            MERGE (c)-[:DISC_HAS_FACTOR]->(f)\n",
    "            \"\"\",\n",
    "            category=category, factor=factor\n",
    "        )\n",
    "\n",
    "        # 3) MERGE Adjective node + link to Factor\n",
    "        graph.run(\n",
    "            \"MERGE (a:DISC_Adjective {name:$adjective})\",\n",
    "            adjective=adjective\n",
    "        )\n",
    "        graph.run(\n",
    "            \"\"\"\n",
    "            MATCH (f:DISC_Factor {name:$factor}), (a:DISC_Adjective {name:$adjective})\n",
    "            MERGE (f)-[:DISC_HAS_ADJECTIVE]->(a)\n",
    "            \"\"\",\n",
    "            factor=factor, adjective=adjective\n",
    "        )\n",
    "\n",
    "        # 4) MERGE Synonym, Verb, Noun under Adjective\n",
    "        if synonym:\n",
    "            graph.run(\"MERGE (s:DISC_Synonym {name:$synonym})\", synonym=synonym)\n",
    "            graph.run(\n",
    "                \"\"\"\n",
    "                MATCH (a:DISC_Adjective {name:$adjective}), (s:DISC_Synonym {name:$synonym})\n",
    "                MERGE (a)-[:DISC_HAS_SYNONYM]->(s)\n",
    "                \"\"\",\n",
    "                adjective=adjective, synonym=synonym\n",
    "            )\n",
    "        if verb:\n",
    "            graph.run(\"MERGE (v:DISC_Verb {name:$verb})\", verb=verb)\n",
    "            graph.run(\n",
    "                \"\"\"\n",
    "                MATCH (a:DISC_Adjective {name:$adjective}), (v:DISC_Verb {name:$verb})\n",
    "                MERGE (a)-[:DISC_HAS_VERB]->(v)\n",
    "                \"\"\",\n",
    "                adjective=adjective, verb=verb\n",
    "            )\n",
    "        if noun:\n",
    "            graph.run(\"MERGE (n:DISC_Noun {name:$noun})\", noun=noun)\n",
    "            graph.run(\n",
    "                \"\"\"\n",
    "                MATCH (a:DISC_Adjective {name:$adjective}), (n:DISC_Noun {name:$noun})\n",
    "                MERGE (a)-[:DISC_HAS_NOUN]->(n)\n",
    "                \"\"\",\n",
    "                adjective=adjective, noun=noun\n",
    "            )\n",
    "\n",
    "        # 5) Optionally attach Embedding to the Adjective\n",
    "        if embedding:\n",
    "            graph.run(\n",
    "                \"\"\"\n",
    "                MATCH (a:DISC_Adjective {name:$adjective})\n",
    "                MERGE (e:DISC_Embedding {value:$embedding})\n",
    "                MERGE (a)-[:DISC_HAS_EMBEDDING]->(e)\n",
    "                \"\"\",\n",
    "                adjective=adjective, embedding=embedding\n",
    "            )\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Execute under MLflow run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "with mlflow.start_run(run_name=\"Create DISCSchema in Neo4j\"):\n",
    "    graph = Graph(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    create_disc_schema(graph, disc_df)\n",
    "\n",
    "    mlflow.log_artifact(dataset_path, artifact_path=\"datasets\")\n",
    "    mlflow.log_param(\"rows\", disc_df.shape[0])\n",
    "    mlflow.log_param(\"cols\", disc_df.shape[1])\n",
    "\n",
    "    print(disc_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14d5d0e-5256-4f3b-94b6-6655bb4ac1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from py2neo import Graph\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Load env & set up connection ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv()\n",
    "raw = os.getenv(\"NEO4J_URI\", \"\")\n",
    "if raw.startswith(\"neo4j://\"):\n",
    "    bolt_uri = \"bolt://\" + raw[len(\"neo4j://\"):]\n",
    "else:\n",
    "    bolt_uri = raw\n",
    "\n",
    "user = os.getenv(\"NEO4J_USERNAME\")\n",
    "pwd  = os.getenv(\"NEO4J_PASSWORD\")\n",
    "if not all([bolt_uri, user, pwd]):\n",
    "    raise RuntimeError(\"Make sure NEO4J_URI, NEO4J_USERNAME & NEO4J_PASSWORD are set\")\n",
    "\n",
    "graph = Graph(bolt_uri, auth=(user, pwd))\n",
    "print(\"üîó Connected to Neo4j via\", bolt_uri)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Load your DiSC dataset ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "csv_path = \"../Datasets/disc.csv\"\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"{csv_path} not found\")\n",
    "\n",
    "disc_df = pd.read_csv(\n",
    "    csv_path,\n",
    "    converters={'Embedding': lambda s: ast.literal_eval(s) if isinstance(s, str) else s}\n",
    ")\n",
    "print(f\"‚úÖ Loaded {len(disc_df)} rows from {csv_path}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Clear the database ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "graph.delete_all()\n",
    "print(\"üóëÔ∏è  Cleared all existing nodes & relationships\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Function to build the graph ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def create_disc_graph(g: Graph, df: pd.DataFrame):\n",
    "    for _, row in df.iterrows():\n",
    "        domain      = row['Domain']\n",
    "        subcat      = row['Subcategory']\n",
    "        factor      = row['Factor']\n",
    "        adjective   = row['Adjective']\n",
    "        synonym     = row['Synonym']\n",
    "        verb        = row['Verb']\n",
    "        noun        = row['Noun']\n",
    "\n",
    "        # 1) MERGE each node\n",
    "        g.run(\"MERGE (D:Domain {name:$domain})\",      domain=domain)\n",
    "        g.run(\"MERGE (S:Subcategory {name:$subcat})\", subcat=subcat)\n",
    "        g.run(\"MERGE (F:Factor      {name:$factor})\", factor=factor)\n",
    "        g.run(\"MERGE (A:Adjective   {name:$adjective})\", adjective=adjective)\n",
    "\n",
    "        # 2) Link them\n",
    "        g.run(\"\"\"\n",
    "            MATCH (D:Domain{name:$domain}), (S:Subcategory{name:$subcat})\n",
    "            MERGE (D)-[:HAS_SUBCATEGORY]->(S)\n",
    "        \"\"\", domain=domain, subcat=subcat)\n",
    "\n",
    "        g.run(\"\"\"\n",
    "            MATCH (S:Subcategory{name:$subcat}), (F:Factor{name:$factor})\n",
    "            MERGE (S)-[:HAS_FACTOR]->(F)\n",
    "        \"\"\", subcat=subcat, factor=factor)\n",
    "\n",
    "        g.run(\"\"\"\n",
    "            MATCH (F:Factor{name:$factor}), (A:Adjective{name:$adjective})\n",
    "            MERGE (F)-[:HAS_ADJECTIVE]->(A)\n",
    "        \"\"\", factor=factor, adjective=adjective)\n",
    "\n",
    "        # 3) Under Adjective, add Synonym, Verb, Noun\n",
    "        if synonym:\n",
    "            g.run(\"MERGE (Y:Synonym {name:$synonym})\", synonym=synonym)\n",
    "            g.run(\"\"\"\n",
    "                MATCH (A:Adjective{name:$adjective}), (Y:Synonym{name:$synonym})\n",
    "                MERGE (A)-[:HAS_SYNONYM]->(Y)\n",
    "            \"\"\", adjective=adjective, synonym=synonym)\n",
    "\n",
    "        if verb:\n",
    "            g.run(\"MERGE (V:Verb {name:$verb})\", verb=verb)\n",
    "            g.run(\"\"\"\n",
    "                MATCH (A:Adjective{name:$adjective}), (V:Verb{name:$verb})\n",
    "                MERGE (A)-[:HAS_VERB]->(V)\n",
    "            \"\"\", adjective=adjective, verb=verb)\n",
    "\n",
    "        if noun:\n",
    "            g.run(\"MERGE (N:Noun {name:$noun})\", noun=noun)\n",
    "            g.run(\"\"\"\n",
    "                MATCH (A:Adjective{name:$adjective}), (N:Noun{name:$noun})\n",
    "                MERGE (A)-[:HAS_NOUN]->(N)\n",
    "            \"\"\", adjective=adjective, noun=noun)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Build it! ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "create_disc_graph(graph, disc_df)\n",
    "print(\"üéâ Completed building the DiSC taxonomy graph in Neo4j.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5da5e04-52b0-432d-9324-ba465af1865b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "746cc0fc-8e2f-4f59-b0e8-75b663e2802b",
   "metadata": {},
   "source": [
    "```cypher\n",
    "MATCH p=(d:Domain)-[:HAS_SUBCATEGORY]->(s:Subcategory)\n",
    "         -[:HAS_FACTOR]->(f:Factor)\n",
    "         -[:HAS_ADJECTIVE]->(a:Adjective)\n",
    "OPTIONAL MATCH leaf=(a)-[:HAS_SYNONYM|HAS_VERB|HAS_NOUN]->(x)\n",
    "RETURN p, leaf\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca5e75-3b9b-45a1-997b-a5fe4b4b4d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (personality-models-env)",
   "language": "python",
   "name": "personality-models-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
