{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fab40f5-a45a-4587-8c2a-e627a93825fe",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "## Thomas-Kilmann conflict model instrument<a class=\"anchor\" id=\"PTMD_page_21\"></a>\n",
    "\n",
    "[Back to Top](#PTMD_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efe1360-063a-450f-8829-71b647a9b735",
   "metadata": {},
   "source": [
    "The **Thomas-Kilmann Conflict Model Instrument**, often referred to as the TKI assessment, is a well-known and widely used tool for understanding and managing interpersonal conflicts. Developed by Kenneth W. Thomas and Ralph H. Kilmann, this model provides valuable insights into how individuals approach and handle conflicts in various situations.\n",
    "\n",
    "**Key Features and Purpose:**\n",
    "\n",
    "1. **Five Conflict Handling Styles:** The TKI assessment identifies five primary conflict-handling styles or modes, each reflecting a different approach to resolving conflicts:\n",
    "   - **Competing:** This style is characterized by assertiveness and a desire to win the conflict at any cost.\n",
    "   - **Collaborating:** It emphasizes cooperation and finding mutually beneficial solutions.\n",
    "   - **Compromising:** This style involves seeking middle-ground solutions where both parties make concessions.\n",
    "   - **Avoiding:** It focuses on sidestepping conflicts or postponing their resolution.\n",
    "   - **Accommodating:** This style prioritizes maintaining harmony and giving in to the other party's wishes.\n",
    "\n",
    "2. **Conflict Mode Assessment:** Individuals take the TKI assessment to determine their preferred conflict-handling style. The assessment provides scores that indicate the relative strength of each style for the individual.\n",
    "\n",
    "3. **Conflict Resolution Guidance:** The TKI model offers guidance on when to use each conflict-handling style effectively based on the nature of the conflict and the desired outcome.\n",
    "\n",
    "4. **Practical Application:** The TKI model is widely used in organizational and interpersonal contexts, helping individuals and teams understand their natural conflict-handling tendencies and learn how to adapt their approaches to achieve more favorable results.\n",
    "\n",
    "**Practical Applications:**\n",
    "\n",
    "- **Workplace Conflict Resolution:** The TKI model is often used in organizational settings to improve conflict management and foster better collaboration among team members. It helps employees and leaders understand their preferred styles and how to address workplace conflicts more constructively.\n",
    "\n",
    "- **Leadership Development:** The TKI assessment is a valuable tool for leadership development programs, enabling leaders to enhance their conflict resolution skills and make informed decisions about when to use specific conflict-handling styles.\n",
    "\n",
    "- **Team Building:** Teams can use the TKI model to assess and discuss their collective conflict-handling preferences, which can lead to improved teamwork and communication.\n",
    "\n",
    "- **Negotiation Training:** Negotiators and mediators benefit from understanding the TKI model to tailor their approaches to different negotiation situations effectively.\n",
    "\n",
    "In summary, the Thomas-Kilmann Conflict Model Instrument (TKI) is a practical and widely used tool for assessing and managing interpersonal conflicts. Developed by Kenneth W. Thomas and Ralph H. Kilmann, this model provides individuals and organizations with valuable insights into their conflict-handling styles and offers guidance on how to adapt these styles to achieve more successful conflict resolutions. Its practical applications span from workplace conflict resolution to leadership development and negotiation training.\n",
    "\n",
    "Timeline and reference table for the Thomas-Kilmann Conflict Mode Instrument (TKI) involves outlining the key developments of this tool. The TKI, developed by Kenneth W. Thomas and Ralph H. Kilmann, is a widely used assessment for determining an individual's conflict handling style. Here's a hypothetical timeline and reference table:\n",
    "\n",
    "### Thomas-Kilmann Conflict Mode Instrument (TKI) Timeline and Reference Table\n",
    "\n",
    "| Year       | Milestone                               | Contributor(s)                     | Original Work Reference                                     | Key Contributions                                                                      | Additional Information                                                                |\n",
    "|------------|-----------------------------------------|-------------------------------------|------------------------------------------------------------|--------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------|\n",
    "| 1974       | Introduction of the TKI.                | Kenneth W. Thomas and Ralph H. Kilmann | Thomas, K. W., & Kilmann, R. H. (1974). \"Thomas-Kilmann Conflict Mode Instrument\". Tuxedo, NY: Xicom. | Original development of the instrument, featuring five conflict styles: competing, collaborating, compromising, avoiding, and accommodating. | Designed to assess how individuals respond to conflict, balancing assertiveness and cooperativeness. |\n",
    "| 2000s      | Adaptations and Widespread Use.         | Various Practitioners              | Applications in organizational development, team building, and leadership training. | TKI became a standard tool for conflict resolution training in various organizational contexts. | Its usage extended beyond psychology into business, education, and mediation.         |\n",
    "| 2010s-Present | Ongoing Research and Application.   | Various Scholars and Practitioners | Recent studies exploring the use of TKI in diverse cultural settings and its integration with modern conflict resolution strategies. | Further exploration of the TKI's utility in organizational and interpersonal conflict management. | Demonstrates the continued relevance of the TKI in understanding and addressing conflict in various settings. |\n",
    "\n",
    "\n",
    "| **#** | **Author(s)**            | **Year** | **Title**                                                                                         | **Journal/Source**                 | **Volume** | **Pages**            | **DOI/URL**                              |\n",
    "|-------|---------------------------|----------|---------------------------------------------------------------------------------------------------|-------------------------------------|------------|----------------------|-------------------------------------------|\n",
    "| 1     | John E. Jones             | 1976     | Thomas-Kilmann Conflict Mode Instrument                                                           | Group & Organization Management    | 1          | 249-251             | [DOI](https://doi.org/10.1177/105960117600100214) |\n",
    "| 2     | K. Thomas, R. Kilmann     | 1975     | The Social Desirability Variable in Organizational Research: An Alternative Explanation           | Academy of Management Journal      | 18         | 741-752             | [DOI](https://doi.org/10.5465/255376)    |\n",
    "| 3     | Michael A. Gross, L. Guerrero | 2000 | Managing Conflict Appropriately and Effectively: An Application of the Competence Model           | International Journal of Conflict Management | 11 | 200-226 | [DOI](https://doi.org/10.1108/EB022840) |\n",
    "| 4     | Pruitt, G. Dean, Rubin, Z. Jeffrey, Kim, Sung Hee | 1986 | Social Conflict: Escalation, Stalemate, and Settlement                                             | -                                   | -          | -                    | [URL](https://www.semanticscholar.org/paper/3cb759361f7932dd46693ca71ced70cda244c737) |\n",
    "| 5     | R. Campbell, F. Fiedler   | 1968     | A Theory of Leadership Effectiveness                                                              | Administrative Science Quarterly   | 13         | 344                 | [DOI](https://doi.org/10.2307/2391461)   |\n",
    "| 6     | M. A. Rahim               | 1983     | A Measure of Styles of Handling Interpersonal Conflict                                            | Academy of Management Journal      | 26         | 368-376             | [DOI](https://doi.org/10.5465/255985)    |\n",
    "| 7     | D. G. Pruitt              | 1983     | Strategic Choice in Negotiation                                                                   | American Behavioral Scientist      | 27         | 167-194             | [DOI](https://doi.org/10.1177/000276483027002005) |\n",
    "| 8     | K. Thomas                 | 1992     | Conflict and Conflict Management: Reflections and Update                                          | Journal of Organizational Behavior | 13         | 265-274             | [DOI](https://doi.org/10.1002/JOB.4030130307) |\n",
    "| 9     | David Antonioni           | 1998     | Relationship Between the Big Five Personality Factors and Conflict Management Styles              | International Journal of Conflict Management | 9 | 336-355 | [DOI](https://doi.org/10.1108/EB022814) |\n",
    "| 10    | R. Kilmann, K. Thomas     | 1977     | Developing a Forced-Choice Measure of Conflict-Handling Behavior: The \"Mode\" Instrument           | Educational and Psychological Measurement | 37 | 309-325 | [DOI](https://doi.org/10.1177/001316447703700204)\n",
    "| 11    | R. Friedman, S. T. Tidd, S. C. Currall, J. Tsai | 2006 | What Goes Around Comes Around: the Impact of Personal Conflict Style on Work Conflict and Stress | International Journal of Conflict Management | - | - | [DOI](https://doi.org/10.1108/eb022834) |\n",
    "| 12    | R. Kilmann, K. Thomas         | 1975     | Interpersonal Conflict-Handling Behavior as Reflections of Jungian Personality Dimensions         | Psychological Reports               | 37         | 971-980             | [DOI](https://doi.org/10.2466/pr0.1975.37.3.971) |\n",
    "| 13    | S. Ting-Toomey, G. Gao, P. Trubisky, et al. | 1991 | Culture, Face Maintenance, and Styles of Handling Interpersonal Conflict: A Study in Five Cultures | International Journal of Conflict Management | 2 | 275-296 | [DOI](https://doi.org/10.1108/EB022702) |\n",
    "| 14    | T. L. Ruble, K. Thomas        | 1976     | Support for a Two-Dimensional Model of Conflict Behavior                                         | Organizational Behavior and Human Performance | 16 | 143-155 | [DOI](https://doi.org/10.1016/0030-5073(76)90010-6) |\n",
    "| 15    | M. A. Rahim                   | 1986     | Referent Role and Styles of Handling Interpersonal Conflict                                     | Journal of Social Psychology        | 126        | 79-86               | [DOI](https://doi.org/10.1080/00224545.1986.9713573) |\n",
    "| 16    | S. R. Wilson, M. Waltman      | 1988     | Assessing the Putnam-Wilson Organizational Communication Conflict Instrument (OCCI)              | Management Communication Quarterly  | 1          | 367-388             | [DOI](https://doi.org/10.1177/0893318988001003006) |\n",
    "| 17    | J. Holt, C. J. DeVore         | 2005     | Culture, Gender, Organizational Role, and Styles of Conflict Resolution: A Meta-Analysis        | International Journal of Intercultural Relations | 29 | 165-196 | [DOI](https://doi.org/10.1016/J.IJINTREL.2005.06.002) |\n",
    "| 18    | K. Jehn                      | 1995     | A Multimethod Examination of the Benefits and Detriments of Intragroup Conflict                 | Administrative Science Quarterly    | 40         | 256                 | [DOI](https://doi.org/10.2307/2393638) |\n",
    "| 19    | D. Weider-Hatfield           | 1988     | Assessing the Rahim Organizational Conflict Inventory-II (ROCI-II)                              | Management Communication Quarterly  | 1          | 350-366             | [DOI](https://doi.org/10.1177/0893318988001003005) |\n",
    "| 20    | J. S. Himes                   | 1980     | Conflict and Conflict Management                                                              | -                                 | -          | -                    | [DOI](https://doi.org/10.2307/2578465)     |\n",
    "| 21    | L. L. Putnam, C. E. Wilson    | 1982     | Communicative Strategies in Organizational Conflicts: Reliability and Validity of a Measurement Scale | Annals of the International Communication Association | 6 | 629-652 | [DOI](https://doi.org/10.1080/23808985.1982.11678515) |\n",
    "| 22    | C. D. De Dreu, L. Weingart    | 2003     | Task versus Relationship Conflict, Team Performance, and Team Member Satisfaction: A Meta-Analysis | The Journal of Applied Psychology  | 88         | 741-749             | [DOI](https://doi.org/10.1037/0021-9010.88.4.741) |\n",
    "| 23    | L. A. DeChurch, M. Marks      | 2001     | Maximizing the Benefits of Task Conflict: The Role of Conflict Management                       | International Journal of Conflict Management | 12 | 4-22 | [DOI](https://doi.org/10.1108/EB022847) |\n",
    "| 24    | D. Womack                     | 1988     | A Review of Conflict Instruments in Organizational Settings                                    | Management Communication Quarterly  | 1          | 437-445             | [DOI](https://doi.org/10.1177/0893318988001003010) |\n",
    "| 25    | K. Thomas, R. Kilmann         | 1978     | Comparison of Four Instruments Measuring Conflict Behavior                                     | Psychological Reports               | 42         | 1139-1145           | [DOI](https://doi.org/10.2466/pr0.1978.42.3c.1139) |\n",
    "| 26    | H. Barki, J. Hartwick         | 2004     | Conceptualizing the Construct of Interpersonal Conflict                                       | International Journal of Conflict Management | 15 | 216-244 | [DOI](https://doi.org/10.1108/EB022913) |\n",
    "| 27    | J. Mouton, R. R. Blake        | 1994     | The Managerial Grid                                                                           | -                                 | -          | -                    | -                                           |\n",
    "| 28    | D. Womack                     | 1988     | Assessing the Thomas-Kilmann Conflict Mode Survey                                             | Management Communication Quarterly  | 1          | 321-349             | [DOI](https://doi.org/10.1177/0893318988001003004) |\n",
    "| 29    | M. A. Rahim                   | 1985     | A Strategy for Managing Conflict in Complex Organizations                                     | Human Relations                     | 38         | 81-89               | [DOI](https://doi.org/10.1177/001872678503800105) |\n",
    "| 30    | K. Thomas                     | 1992     | Conflict and Negotiation Processes in Organizations                                           | -                                 | -          | -                    | -                                           |\n",
    "| 31    | D. Thakore                    | 2013     | Conflict and Conflict Management                                                              | IOSR Journal of Business and Management | 8    | 7-16 | [DOI](https://doi.org/10.9790/487X-0860716) |\n",
    "| 32    | E. Vliert, B. Kabanoff        | 1990     | Toward Theory-Based Measures of Conflict Management                                           | Academy of Management Journal       | 33         | 199-209             | [DOI](https://doi.org/10.5465/256359) |\n",
    "| 33    | P. Trubisky, S. Ting-Toomey, S.-L. Lin | 1991 | The Influence of Individualism-Collectivism and Self-Monitoring on Conflict Styles            | International Journal of Intercultural Relations | 15 | 65-84 | [DOI](https://doi.org/10.1016/0147-1767(91)90074-Q) |\n",
    "| 34    | C.-W. Lee                     | 1990     | Relative Status of Employees and Styles of Handling Interpersonal Conflict: An Experimental Study with Korean Managers | International Journal of Conflict Management | 1 | 327-340 | [DOI](https://doi.org/10.1108/EB022687) |\n",
    "| 35    | M. A. Rahim                   | 2002     | Toward a Theory of Managing Organizational Conflict                                           | International Journal of Conflict Management | 13 | 206-235 | [DOI](https://doi.org/10.1108/EB022874) |\n",
    "| 36    | M. A. Rahim, D. Antonioni, C. Psenicka | 2001 | A Structural Equations Model of Leader Power, Subordinates' Styles of Handling Conflict, and Job Performance | International Journal of Conflict Management | 12 | 191-211 | [DOI](https://doi.org/10.1108/EB022855) |\n",
    "| 37    | C. D. De Dreu, A. Evers, B. Beersma, E. Kluwer, A. Nauta | 2001 | A Theory-Based Measure of Conflict Management Strategies in the Workplace                       | History of Political Economy        | -          | -                    | [DOI](https://doi.org/10.1002/JOB.107) |\n",
    "| 38    | A. Rahim, T. Bonoma           | 1979     | Managing Organizational Conflict: A Model for Diagnosis and Intervention                       | Psychological Reports               | 44         | 1323-1344           | [DOI](https://doi.org/10.2466/pr0.1979.44.3c.1323) |\n",
    "| 39    | M. A. Rahim, N. Magner        | 1995     | Confirmatory Factor Analysis of the Styles of Handling Interpersonal Conflict: First-Order Factor Model and Its Invariance Across Groups | The Journal of Applied Psychology | 80 | 122-132 | [DOI](https://doi.org/10.1037/0021-9010.80.1.122) |\n",
    "| 40    | N. Brewer, P. Mitchell, N. Weber | 2002 | Gender Role, Organizational Status, and Conflict Management Styles                             | International Journal of Conflict Management | 13 | 78-94 | [DOI](https://doi.org/10.1108/EB022868) |\n",
    "| 41    | J. Wall, R. Callister         | 1995     | Conflict and Its Management                                                                   | Journal of Management               | 21         | 515-558             | [DOI](https://doi.org/10.1177/014920639502100306) |\n",
    "\n",
    "\n",
    "This table provides an overview of the major developments in the Thomas-Kilmann Conflict Mode Instrument, highlighting key contributions and milestones. Each row represents a significant event in the history of the TKI, detailing the year, milestone, contributors, original work references, key contributions, and additional information.\n",
    "\n",
    "The TKI has been influential in the field of conflict resolution and organizational psychology, offering a framework for understanding individual differences in conflict handling styles. Its application has helped numerous organizations and individuals in effectively managing and resolving conflicts.\n",
    "\n",
    "### Taxonomy\n",
    "```\n",
    "- Category\n",
    "    |__ Factor\n",
    "        |__ Adjective\n",
    "              |__ Synonyn\n",
    "              |__ Verb\n",
    "              |__ Noun\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d931fe8d-537d-48d1-9f8a-79670ef29866",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 1: Create Dataset** <a class=\"anchor\" id=\"OCEAN_page_1\"></a>\n",
    "\n",
    "Data Preparation and Cleaning: Ensure the dataset is cleaned and preprocessed properly. Handle missing values, duplicates, and outliers.\n",
    "\n",
    "[Back to Top](#OCEAN_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e173202c-b28e-42a7-b6dd-6e52b52625e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Factor</th>\n",
       "      <th>Adjective</th>\n",
       "      <th>Synonym</th>\n",
       "      <th>Verb</th>\n",
       "      <th>Noun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Conflict Mode</td>\n",
       "      <td>Competing</td>\n",
       "      <td>Assertive and uncooperative mode, pursuing own...</td>\n",
       "      <td>Aggressive</td>\n",
       "      <td>Compete</td>\n",
       "      <td>Competition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Conflict Mode</td>\n",
       "      <td>Competing</td>\n",
       "      <td>Assertive and uncooperative mode, pursuing own...</td>\n",
       "      <td>Assertive</td>\n",
       "      <td>Assert</td>\n",
       "      <td>Assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Conflict Mode</td>\n",
       "      <td>Competing</td>\n",
       "      <td>Assertive and uncooperative mode, pursuing own...</td>\n",
       "      <td>Dominant</td>\n",
       "      <td>Dominate</td>\n",
       "      <td>Dominance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conflict Mode</td>\n",
       "      <td>Competing</td>\n",
       "      <td>Assertive and uncooperative mode, pursuing own...</td>\n",
       "      <td>Controlling</td>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Conflict Mode</td>\n",
       "      <td>Collaborating</td>\n",
       "      <td>Assertive and cooperative mode, finding mutual...</td>\n",
       "      <td>Cooperative</td>\n",
       "      <td>Collaborate</td>\n",
       "      <td>Collaboration</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category         Factor  \\\n",
       "0  Conflict Mode      Competing   \n",
       "1  Conflict Mode      Competing   \n",
       "2  Conflict Mode      Competing   \n",
       "3  Conflict Mode      Competing   \n",
       "4  Conflict Mode  Collaborating   \n",
       "\n",
       "                                           Adjective      Synonym  \\\n",
       "0  Assertive and uncooperative mode, pursuing own...   Aggressive   \n",
       "1  Assertive and uncooperative mode, pursuing own...    Assertive   \n",
       "2  Assertive and uncooperative mode, pursuing own...     Dominant   \n",
       "3  Assertive and uncooperative mode, pursuing own...  Controlling   \n",
       "4  Assertive and cooperative mode, finding mutual...  Cooperative   \n",
       "\n",
       "          Verb           Noun  \n",
       "0      Compete    Competition  \n",
       "1       Assert      Assertion  \n",
       "2     Dominate      Dominance  \n",
       "3      Control        Control  \n",
       "4  Collaborate  Collaboration  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize a list to store the data\n",
    "data = []\n",
    "\n",
    "# Thomas-Kilmann Conflict Mode Instrument dataset structure\n",
    "tki_dataset = {\n",
    "    'Conflict Modes': {\n",
    "        'Competing': {\n",
    "            'Description': 'Assertive and uncooperative mode, pursuing own concerns at the expense of others.',\n",
    "            'Synonyms': ['Aggressive', 'Assertive', 'Dominant', 'Controlling'],\n",
    "            'Verbs': ['Compete', 'Assert', 'Dominate', 'Control'],\n",
    "            'Nouns': ['Competition', 'Assertion', 'Dominance', 'Control']\n",
    "        },\n",
    "        'Collaborating': {\n",
    "            'Description': 'Assertive and cooperative mode, finding mutually beneficial solutions.',\n",
    "            'Synonyms': ['Cooperative', 'Teamwork', 'Mutual gain', 'Synergy'],\n",
    "            'Verbs': ['Collaborate', 'Cooperate', 'Work together', 'Find synergy'],\n",
    "            'Nouns': ['Collaboration', 'Cooperation', 'Teamwork', 'Synergy']\n",
    "        },\n",
    "        'Compromising': {\n",
    "            'Description': 'Moderate in assertiveness and cooperation, finding an acceptable middle ground.',\n",
    "            'Synonyms': ['Mediating', 'Moderating', 'Balancing', 'Negotiating'],\n",
    "            'Verbs': ['Compromise', 'Mediate', 'Balance', 'Negotiate'],\n",
    "            'Nouns': ['Compromise', 'Mediation', 'Balance', 'Negotiation']\n",
    "        },\n",
    "        'Avoiding': {\n",
    "            'Description': 'Unassertive and uncooperative mode, sidestepping or withdrawing from conflict.',\n",
    "            'Synonyms': ['Sidestepping', 'Withdrawing', 'Ignoring', 'Evading'],\n",
    "            'Verbs': ['Avoid', 'Withdraw', 'Ignore', 'Evade'],\n",
    "            'Nouns': ['Avoidance', 'Withdrawal', 'Ignorance', 'Evasion']\n",
    "        },\n",
    "        'Accommodating': {\n",
    "            'Description': 'Unassertive and cooperative mode, yielding to the other party’s concerns.',\n",
    "            'Synonyms': ['Yielding', 'Complying', 'Submitting', 'Obliging'],\n",
    "            'Verbs': ['Accommodate', 'Yield', 'Comply', 'Submit'],\n",
    "            'Nouns': ['Accommodation', 'Yielding', 'Compliance', 'Submission']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Process the TKI dataset to structure the data\n",
    "for mode, traits in tki_dataset['Conflict Modes'].items():\n",
    "    synonyms = traits.get('Synonyms', [])\n",
    "    verbs = traits.get('Verbs', [])\n",
    "    nouns = traits.get('Nouns', [])\n",
    "    description = traits.get('Description', '')\n",
    "\n",
    "    # Normalize the lists to match each other in length\n",
    "    max_len = max(len(synonyms), len(verbs), len(nouns))\n",
    "    synonyms += [''] * (max_len - len(synonyms))\n",
    "    verbs += [''] * (max_len - len(verbs))\n",
    "    nouns += [''] * (max_len - len(nouns))\n",
    "\n",
    "    # Add data for each synonym-verb-noun combination\n",
    "    for synonym, verb, noun in zip(synonyms, verbs, nouns):\n",
    "        data.append(('Conflict Mode', mode, description, synonym, verb, noun))\n",
    "\n",
    "# Create a DataFrame from the structured data\n",
    "tki_df = pd.DataFrame(data, columns=['Category', 'Factor', 'Adjective', 'Synonym', 'Verb', 'Noun'])\n",
    "\n",
    "# Save to CSV\n",
    "tki_df.to_csv('../Datasets/tki.csv', index=False)\n",
    "\n",
    "# Display the first few rows\n",
    "tki_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286e8c9f-fc3b-4e56-a72a-04bea5b5d432",
   "metadata": {},
   "source": [
    "The **Wechsler Adult Intelligence Scale (TKI)** is a standardized assessment that measures the intelligence of adults and older adolescents. Developed by David Wechsler, it is one of the most commonly used tests to evaluate cognitive abilities and generate an intelligence quotient (IQ) score. Over time, the TKI has undergone several revisions to remain current and reflect new understanding of cognitive abilities.\n",
    "\n",
    "### TKI Milestones Timeline\n",
    "\n",
    "| Year | Milestone                                          | Contributor(s)    | Original Work Reference                                          | Key Contributions                                                                                  |\n",
    "|------|----------------------------------------------------|-------------------|------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|\n",
    "| 1955 | Introduction of the first Wechsler Adult Intelligence Scale | David Wechsler    | Wechsler, D. (1955). \"Wechsler Adult Intelligence Scale.\"        | Provided a comprehensive measure of adult intelligence based on both verbal and performance scores. |\n",
    "| 1981 | Development of TKI-R (Revised Edition)            | David Wechsler    | Wechsler, D. (1981). \"TKI-R Manual.\"                            | Updated the test to improve reliability and cultural relevance.                                    |\n",
    "| 1997 | TKI-III                                           | David Wechsler    | Wechsler, D. (1997). \"TKI-III Manual.\"                          | Introduced the Working Memory Index and Processing Speed Index as new components.                  |\n",
    "| 2008 | TKI-IV                                            | David Wechsler    | Wechsler, D. (2008). \"TKI-IV Manual.\"                           | Added the General Ability Index (GAI) to provide an alternative score excluding working memory and processing speed. |\n",
    "| 2020 | TKI-V Development and Refinement                  | Various scholars  | Academic research and publications                               | Updated the structure and norms to reflect recent psychometric findings.                           |\n",
    "\n",
    "### TKI Dataset Structure\n",
    "\n",
    "The TKI dataset can be structured according to its indices and subtests. Each index represents a primary cognitive ability, with subtests that provide detailed scores:\n",
    "\n",
    "- **Verbal Comprehension Index (VCI)**: Assesses verbal reasoning, comprehension, and expression.\n",
    "  - Subtests: Similarities, Vocabulary, Information, Comprehension.\n",
    "  \n",
    "- **Perceptual Reasoning Index (PRI)**: Evaluates visual-spatial reasoning, problem-solving, and perceptual organization.\n",
    "  - Subtests: Block Design, Matrix Reasoning, Visual Puzzles, Figure Weights.\n",
    "  \n",
    "- **Working Memory Index (WMI)**: Measures short-term memory and attention.\n",
    "  - Subtests: Digit Span, Arithmetic, Letter-Number Sequencing.\n",
    "  \n",
    "- **Processing Speed Index (PSI)**: Assesses cognitive processing speed and efficiency.\n",
    "  - Subtests: Symbol Search, Coding, Cancellation.\n",
    "\n",
    "- **Scoring Information**: Interpretation guidelines include index scores, subtest scores, and optional composite scores like the Full-Scale IQ and General Ability Index.\n",
    "\n",
    "### TKI Reference Table:\n",
    "\n",
    "| **#** | **Author(s)**                                  | **Year** | **Title**                                                                                  | **Journal/Source**                  | **Volume** | **Pages**    | **DOI/URL**                                       |\n",
    "|-------|-----------------------------------------------|----------|----------------------------------------------------------------------------------------------|--------------------------------------|------------|--------------|--------------------------------------------------|\n",
    "| 1     | D. Wechsler                                   | 2021     | Wechsler Adult Intelligence Scale                                                          | Encyclopedia of Evolutionary Psychological Science | - | - | [DOI](https://doi.org/10.4135/9781412952644.n478) |\n",
    "| 2     | J. Nigg, E. Willcutt, A. Doyle, E. Sonuga-Barke | 2005 | Causal Heterogeneity in Attention-Deficit/Hyperactivity Disorder: Do We Need Neuropsychologically Impaired Subtypes? | Biological Psychiatry | 57 | 1224-1230 | [DOI](https://doi.org/10.1016/j.biopsych.2004.08.025) |\n",
    "| 3     | E. Kaplan, H. Goodglass, S. Weintraub, O. Segal | 2001 | Boston Naming Test | - | - | - | [DOI](https://doi.org/10.1007/springerreference_183640) |\n",
    "| 4     | J. Ryan, S. Lopez                             | 2001     | Wechsler Adult Intelligence Scale-III                                                      | -                                    | -          | -            | [DOI](https://doi.org/10.1007/978-1-4615-1185-4_2) |\n",
    "| 5     | S. Freeman                                   | 2021     | Wechsler Preschool and Primary Scale of Intelligence                                       | Encyclopedia of Autism Spectrum Disorders | - | - | [DOI](https://doi.org/10.1007/springerreference_184297) |\n",
    "| 6     | S. Warschausky, S. E. Raiford                 | 2018     | Wechsler Preschool and Primary Scale of Intelligence                                       | -                                    | -          | -            | [DOI](https://doi.org/10.1007/978-3-319-57111-9_1606) |\n",
    "| 7     | R. Reitan                                    | 1958     | Validity of the Trail Making Test as an Indicator of Organic Brain Damage                   | Perceptual and Motor Skills          | 8          | 271-276      | [DOI](https://doi.org/10.2466/pms.1958.8.3.271)   |\n",
    "| 8     | A. Kertesz                                   | 1982     | The Western Aphasia Battery                                                               | -                                    | -          | -            | [DOI](https://doi.org/10.1007/springerreference_183701) |\n",
    "| 9     | R. Dumont, J. O. Willis, K. D. Viezel, J. Zibulsky | 2014  | California Verbal Learning Test, Second Edition | - | - | - | [DOI](https://doi.org/10.1002/9781118660584.ESE0399) |\n",
    "| 10    | D. Delis, J. Kramer, E. Kaplan, B. Ober       | 2016     | California Verbal Learning Test--Second Edition                                           | -                                    | -          | -            | [DOI](https://doi.org/10.1037/T15072-000)         |\n",
    "| 11    | L. Cohen                                     | 1993     | Wechsler Individual Achievement Test                                                      | -                                    | -          | -            | [DOI](https://doi.org/10.4135/9781412952644.n479) |\n",
    "| 12    | -                                            | 2020     | Behavior Rating Inventory of Executive Function                                           | Definitions                          | -          | -            | [DOI](https://doi.org/10.32388/ygkcwf)             |\n",
    "| 13    | R. Dumont, J. O. Willis                       | 2008     | Behavior Rating Inventory of Executive Function                                           | -                                    | -          | -            | [DOI](https://doi.org/10.1002/9780470373699.SPECED0263) |\n",
    "| 14    | D. Wechsler                                  | 2018     | Wechsler Preschool and Primary Scale of Intelligence--Revised                             | -                                    | -          | -            | [DOI](https://doi.org/10.1037/T48859-000)         |\n",
    "| 15    | M. Schlossberg                              | 1986     | The Halstead-Reitan Neuropsychological Test Battery: Theory and Clinical Interpretation   | Psyccritiques                        | -          | -            | -                                                |\n",
    "| 16    | C. Reynolds, J. Powel                        | 1988     | Wechsler Memory Scale-Revised                                                             | Archives of Clinical Neuropsychology | 3          | 397-403      | [DOI](https://doi.org/10.1093/ARCLIN/3.4.397)    |\n",
    "| 17    | R. Dumont, J. O. Willis, K. Veizel, J. Zibulsky | 2014 | Wechsler Intelligence Scale for Children–Fourth Edition | - | - | - | [DOI](https://doi.org/10.1002/9781118660584.ESE2522) |\n",
    "| 18    | Hyewon Park, 이정미                         | 2002     | The Performance of Autistic Children on the Korean Wechsler Preschool and Primary Scale of Intelligence | - | - | - | [URL](https://www.semanticscholar.org/paper/24edb84d86181b82e6da8596a7a48d4ddbffb968) |\n",
    "| 19    | W. F. Vonderhaar                             | 1977     | A Comparative Study of Performance Scale IQ's and Subtest Scores of Deaf Children on the Wechsler Intelligence Scale for Children and the Wechsler Intelligence Scale for Children-Revised | - | - | - | [URL](https://www.semanticscholar.org/paper/c2ac3a23e8d158f5d6cb7164e1e74d140c8c4ae9) |\n",
    "| 20    | M. A. Tipton                                | 2014     | Wechsler Adult Intelligence Scale (4th Edition) and the Validity of Supplementary/Core Subtest Substitution | - | - | - | [URL](https://www.semanticscholar.org/paper/bc4e1a7a85a311a27bf9b4acceaf76c65c0b4284) |\n",
    "| 21    | E. Willcutt, A. Doyle, J. Nigg, S. Faraone, B. Pennington | 2005 | Validity of the Executive Function Theory of Attention-Deficit/Hyperactivity Disorder: A Meta-Analytic Review | Biological Psychiatry | 57 | 1336-1346 | [DOI](https://doi.org/10.1016/j.biopsych.2005.02.006) |\n",
    "| 22    | F. Petermann, D. Wechsler                    | 2012     | Wechsler Adult Intelligence Scale - fourth edition                                      | - | - | - | [DOI](https://doi.org/10.1037/T15169-000) |\n",
    "| 23    | L. G. Weiss, V. Locke, T. Pan, J. G. Harris, D. Saklofske, A. Prifitera | 2019 | Wechsler Intelligence Scale for Children—Fifth Edition | WISC-V | - | - | [DOI](https://doi.org/10.1016/B978-0-12-815744-2.00005-7) |\n",
    "| 24    | D. Wechsler                                 | 2020     | Wechsler Intelligence Scale for Children                                                 | Definitions                          | -          | -            | [DOI](https://doi.org/10.4135/9781483392271.n537) |\n",
    "| 25    | D. Wechsler                                 | 2012     | Wechsler Preschool and Primary Scale of Intelligence—Fourth Edition                       | -                                    | -          | -            | [DOI](https://doi.org/10.1037/spq0000038.supp) |\n",
    "| 26    | J. Lani, D. Wechsler                        | 2010     | Wechsler Adult Intelligence Scale—Fourth Edition (TKI-IV)                               | -                                    | -          | -            | [URL](https://www.semanticscholar.org/paper/fa9b338ad64286f43a4f3f6da5420ffdbd2ba752) |\n",
    "| 27    | D. Delis, J. Kramer, E. Kaplan, B. Ober     | 2016     | The California Verbal Learning Test                                                      | -                                    | -          | -            | [DOI](https://doi.org/10.1037/T48844-000)         |\n",
    "| 28    | P. Yang, C. Cheng, C. Chang, T. Liu, H. Hsu, C. Yen | 2013 | Wechsler Intelligence Scale for Children 4th edition‐Chinese  version index scores in Taiwanese children with attention‐deficit/hyperactivity disorder | Psychiatry and Clinical Neurosciences | 67 | - | [DOI](https://doi.org/10.1111/pcn.12014) |\n",
    "| 29    | R. Dumont, J. O. Willis                     | 2008     | Delis‐Kaplan Executive Function System                                                   | -                                    | -          | -            | [DOI](https://doi.org/10.1002/9780470373699.SPECED0613) |\n",
    "| 30    | D. R. Smith                                | 2001     | Chapter 6 – Wechsler Individual Achievement Test                                         | -                                    | -          | -            | [DOI](https://doi.org/10.1016/B978-012058570-0/50008-2) |\n",
    "| 31    | R. Hogan, J. Hogan, P. Barrett                | 2008     | Good Judgment: The Intersection of Intelligence and Personality                            | -                                    | -          | -            | [DOI](https://doi.org/10.1201/9781420067019-28) |\n",
    "| 32    | R. Barkley                                   | 1997     | Behavioral Inhibition, Sustained Attention, and Executive Functions: Constructing a Unifying Theory of ADHD | Psychological Bulletin | 121 | 65-94 | [DOI](https://doi.org/10.1037/0033-2909.121.1.65) |\n",
    "| 33    | J. M. Hunt                                   | 1975     | Psychological Development and The Educational Enterprise                                  | Educational Theory                   | 25         | 333-353      | [DOI](https://doi.org/10.1111/J.1741-5446.1975.TB00697.X) |\n",
    "| 34    | B. Choi, C. Kim                              | 2006     | A Learning Attitude Evaluation System for Learning Concentration on Distance Education   | -                                    | -          | -            | [DOI](https://doi.org/10.1007/11751632_87)      |\n",
    "| 35    | J. Lautrey                                  | 2004     | Introduction: Hauts potentiels et talents: La position actuelle du problème              | Psychologie Francaise                | 49         | 219-232      | [DOI](https://doi.org/10.1016/J.PSFR.2004.03.001) |\n",
    "| 36    | E. Lichtenberger, A. Kaufman                 | 2000     | Essentials of WISC-IV Assessment                                                          | -                                    | -          | -            | [URL](https://www.semanticscholar.org/paper/9abebfa4ecd1263e93f21accea1dd5d018cea34a) |\n",
    "| 37    | P. Hagmann-von Arx, A. Grob, F. Petermann, M. Daseking | 2012 | [Concurrent Validity of the HAWIK-IV and the Intelligence and Development Scales (IDS)]  | Zeitschrift fur Kinder- und Jugendpsychiatrie und Psychotherapie | 40 | 41-50 | [DOI](https://doi.org/10.1024/1422-4917/a000148) |\n",
    "| 38    | D. Baczała                                  | 2016     | Social Skills of Individuals with Intellectual Disabilities                              | -                                    | -          | -            | [URL](https://www.semanticscholar.org/paper/4898c8d0a7530ae57acd2d82c535d7ab3d0421e5) |\n",
    "| 39    | B. Pennington, S. Ozonoff                    | 1996     | Executive Functions and Developmental Psychopathology                                   | Journal of Child Psychology and Psychiatry, and Allied Disciplines | 37 | 51-87 | [DOI](https://doi.org/10.1111/J.1469-7610.1996.TB01380.X) |\n",
    "| 40    | G. Gittler, M. Arendasy                      | 2005     | Menschliche Intelligenz — die Sichtweise der Psychologie                                | e & i Elektrotechnik und Informationstechnik | 122 | 227-231 | [DOI](https://doi.org/10.1007/BF03054433) |\n",
    "| 41    | R. Sternberg, E. Grigorenko, M. Ferrari, P. R. Clinkenbeard | 1999 | A Triarchic Analysis of an Aptitude-Treatment Interaction | European Journal of Psychological Assessment | 15 | 3-13 | [DOI](https://doi.org/10.1027//1015-5759.15.1.3) |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "index, subtest, description, synonym, verb, noun\n",
    "\n",
    "### Taxonomy\n",
    "```\n",
    "- Index\n",
    "    |__ Subtest\n",
    "        |__ Description\n",
    "            |__ Synonym\n",
    "            |__ Verb\n",
    "            |__ Noun\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c5b327-3d34-439f-8a75-9e9471a0e65e",
   "metadata": {},
   "source": [
    "##  Steps for TKI Personality Modeling Workflow \n",
    "\n",
    "1.  **Step 1: Create the Personality Dataset**\n",
    "\n",
    "    * **Purpose:** This initial step involves defining and generating the dataset that represents the (TKI) Personality Model .\n",
    "    * **Actions:**\n",
    "        * Define the TKI dataset structure (e.g., using a dictionary to represent factors, adjectives, synonyms, etc.).\n",
    "        * Generate the dataset by organizing the data into a Pandas DataFrame.\n",
    "        * Save the dataset to a CSV file.\n",
    "        * Log dataset metadata (e.g., number of rows, factors, data schema) and the dataset file itself as an artifact in MLflow.\n",
    "    * **Importance:** This step creates the raw data that will be used for embedding generation and model training.\n",
    "\n",
    "2.  **Step 2: API Key Handling and Initialization**\n",
    "\n",
    "    * **Purpose:** This ctkiical step ensures that your OpenAI API key is securely loaded and the OpenAI client is initialized. This sets the foundation for using the OpenAI API in subsequent steps.\n",
    "    * **Actions:**\n",
    "        * Load the OpenAI API key from a secure location (e.g., a file in the user's home directory).\n",
    "        * Validate the API key (e.g., check for existence, emptiness, and potentially a basic API call).\n",
    "        * Initialize the OpenAI client (`client`).\n",
    "        * Log the API key handling process and its outcome in MLflow.\n",
    "    * **Importance:** This step must succeed for the rest of the workflow that utilizes the OpenAI API (like embedding generation) to function. It's essential to handle potential errors (e.g., file not found, invalid key) gracefully.\n",
    "\n",
    "3.  **Step 3: Test Embedding API**\n",
    "\n",
    "    * **Purpose:** This step verifies that the OpenAI Embedding API is accessible and functioning correctly.\n",
    "    * **Actions:**\n",
    "        * Use the initialized OpenAI client (`client`) to make a test call to the Embedding API (e.g., by embedding a sample text).\n",
    "        * Check the API response for validity.\n",
    "        * Log the API call details and the outcome (success or failure) in MLflow.\n",
    "    * **Importance:** This step ensures that you can successfully generate embeddings before proceeding to the next step.\n",
    "\n",
    "4.  **Step 4: Create Embeddings for the Dataset**\n",
    "\n",
    "    * **Purpose:** This step generates numerical representkiions (embeddings) for the text data in the TKI dataset using the OpenAI Embedding API.\n",
    "    * **Actions:**\n",
    "        * Load the TKI dataset (created in Step 2).\n",
    "        * Use the OpenAI client (`client`) to generate embeddings for the relevant text fields (e.g., combining factor, adjective, synonym, verb, noun).\n",
    "        * Add the generated embeddings as a new column in the Pandas DataFrame.\n",
    "        * Save the DataFrame with embeddings to a new CSV file.\n",
    "        * Log embedding generation parameters (e.g., embedding model used), stkiistics (e.g., embedding length), and the embeddings file as an artifact in MLflow.\n",
    "    * **Importance:** This step transforms the text data into a numerical format that can be used for machine learning models.\n",
    "\n",
    "5.  **Step 5: Create and Visualize a Label Encoder**\n",
    "\n",
    "    * **Purpose:** This step prepares the categorical labels (personality factors) for model training by encoding them into numerical values and provides a visualization of this encoding.\n",
    "    * **Actions:**\n",
    "        * Load the dataset with embeddings (created in Step 4).\n",
    "        * Initialize a `LabelEncoder` from scikit-learn.\n",
    "        * Fit the `LabelEncoder` to the 'Factor' column to create the mapping between personality factors and numerical codes.\n",
    "        * Transform the 'Factor' column using the fitted `LabelEncoder` to create a new 'Factor_Encoded' column.\n",
    "        * Save the fitted `LabelEncoder` object.\n",
    "        * Generate a visualization (e.g., a bar chart) to show the mapping between original factors and encoded values.\n",
    "        * Save the visualization as an image file.\n",
    "        * Log the label encoder object and the visualization as artifacts in MLflow.\n",
    "        * Log the mapping between original factors and encoded values as a dictionary in MLflow.\n",
    "    * **Importance:** This step prepares the target variable for model training and provides a clear representkiion of the encoding.\n",
    "\n",
    "6.  **Step 6: Create our TKI Model (Model Training and Evaluation)**\n",
    "\n",
    "    * **Purpose:** This step trains a machine learning model on the generated embeddings to predict personality factors and evaluates its performance.\n",
    "    * **Actions:**\n",
    "        * Load the dataset with embeddings (created in Step 4).\n",
    "        * Load the saved `LabelEncoder` (created in Step 5).\n",
    "        * Prepare the data for model training:\n",
    "            * Extract the embeddings as features (`X`).\n",
    "            * Encode the 'Factor' column using the loaded `LabelEncoder` to get the target variable (`y`).\n",
    "            * Split the data into training and testing sets.\n",
    "        * Initialize a machine learning model (e.g., `RandomForestClassifier`).\n",
    "        * Train the model on the training data.\n",
    "        * Make predictions on the test data.\n",
    "        * Evaluate the model's performance using appropriate metrics (e.g., accuracy, classification report, confusion matrix).\n",
    "        * Generate visualizations of the evaluation results (e.g., confusion matrix plot).\n",
    "        * Save the trained model.\n",
    "        * Log model training parameters (e.g., hyperparameters), evaluation metrics, visualizations, and the trained model as artifacts in MLflow.\n",
    "    * **Importance:** This step is the core of the machine learning process, where the model learns to predict personality factors from the embeddings.\n",
    "\n",
    "7.  **Step 7: Model Testing (Inference on New Data)**\n",
    "\n",
    "    * **Purpose:** This step demonstrates how to use the trained model to predict personality factors for new, unseen text inputs.\n",
    "    * **Actions:**\n",
    "        * Load the trained model (saved in Step 6).\n",
    "        * Load the saved `LabelEncoder` (created in Step 5).\n",
    "        * Define a function that:\n",
    "            * Takes new text as input.\n",
    "            * Generates an embedding for the new text using the OpenAI API.\n",
    "            * Uses the loaded model to predict the personality factor.\n",
    "            * Uses the loaded `LabelEncoder` to decode the numerical prediction back to the original factor name.\n",
    "        * Provide example new text inputs.\n",
    "        * Use the function to predict personality factors for the example texts.\n",
    "        * Print the predictions.\n",
    "        * Log the test inputs and predictions in MLflow.\n",
    "    * **Importance:** This step demonstrates the practical application of the trained model for making predictions on new data.\n",
    "\n",
    "8.  **Step 8: Model Application, Visualization, and Analysis**\n",
    "\n",
    "    * **Purpose:** This step provides additional visualization and analysis of the data and model.\n",
    "    * **Actions:**\n",
    "        * Load the dataset with embeddings (created in Step 4).\n",
    "        * Apply PCA for dimensionality reduction and visualization of the embeddings.\n",
    "        * Generate and log PCA plots to visualize the embedding distribution.\n",
    "        * Perform K-Means clustering on the embeddings to identify potential groupings or clusters of similar personality traits.\n",
    "        * Add cluster labels to the dataset and save the clustered data.\n",
    "        * Log clustering parameters (e.g., number of clusters) and the clustered data as artifacts in MLflow.\n",
    "    * **Importance:** This step offers valuable insights into the data and model:\n",
    "        * PCA visualization helps understand the distribution of embeddings.\n",
    "        * Clustering can reveal underlying patterns in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b2a39-e66d-4a46-8f62-ad88cd36ce87",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 2: API key setup** <a class=\"anchor\" id=\"tki_page_2\"></a>\n",
    "\n",
    "[Back to Top](#tki_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a790191a-5760-45d1-a325-0cb2dcff5582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API key file found at: /Users/jsr/openai_api_key.txt\n",
      "🔑 API key read successfully.\n",
      "🤖 OpenAI API client initialized.\n",
      "✅ OpenAI API key verified successfully with a basic API call.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import mlflow\n",
    "\n",
    "# Start an MLFlow run for API key setup\n",
    "with mlflow.start_run(run_name=\"API Key Handling and Initialization\") as run:\n",
    "    try:\n",
    "        # Log the environment setup process\n",
    "        mlflow.log_param(\"Step\", \"API Key Handling and Initialization\")\n",
    "\n",
    "        # Define the path to your API key file\n",
    "        api_key_file_path = os.path.expanduser('~/openai_api_key.txt')\n",
    "        mlflow.log_param(\"API Key File Path\", api_key_file_path)\n",
    "\n",
    "        # Evaluation: Check if the API key file exists\n",
    "        if not os.path.exists(api_key_file_path):\n",
    "            error_message = f\"API key file not found at: {api_key_file_path}. Please ensure the file exists.\"\n",
    "            mlflow.log_param(\"API Key Stkius\", \"Error: File not found\")\n",
    "            mlflow.log_param(\"Error\", error_message)\n",
    "            raise FileNotFoundError(error_message)\n",
    "        else:\n",
    "            mlflow.log_param(\"API Key File Existence\", \"Confirmed\")\n",
    "            print(f\"✅ API key file found at: {api_key_file_path}\")\n",
    "\n",
    "        # Read the API key from the file\n",
    "        with open(api_key_file_path, 'r') as file:\n",
    "            api_key = file.read().strip()\n",
    "\n",
    "        # Evaluation: Check if the read API key is empty\n",
    "        if not api_key:\n",
    "            error_message = f\"API key file at: {api_key_file_path} is empty. Please ensure your API key is in the file.\"\n",
    "            mlflow.log_param(\"API Key Stkius\", \"Error: Empty file\")\n",
    "            mlflow.log_param(\"Error\", error_message)\n",
    "            raise ValueError(error_message)\n",
    "        else:\n",
    "            mlflow.log_param(\"API Key Stkius\", \"Read successfully\")\n",
    "            mlflow.log_param(\"API Key Length\", len(api_key)) # Log the length as a basic sanity check\n",
    "            print(\"🔑 API key read successfully.\")\n",
    "\n",
    "        # Set up your OpenAI API key\n",
    "        openai.api_key = api_key\n",
    "        client = openai.OpenAI(api_key=api_key)\n",
    "        mlflow.log_param(\"OpenAI API Client\", \"Initialized successfully\")\n",
    "        print(\"🤖 OpenAI API client initialized.\")\n",
    "\n",
    "        # Evaluation: Attempt a basic API call to verify the key (optional, but recommended for immediate feedback)\n",
    "        try:\n",
    "            response = client.models.list()  # Removed the 'limit' argument\n",
    "            mlflow.log_param(\"API Key Verification\", \"Successful (models list)\")\n",
    "            print(\"✅ OpenAI API key verified successfully with a basic API call.\")\n",
    "        except openai.AuthenticationError as auth_error:\n",
    "            mlflow.log_param(\"API Key Verification\", \"Failed (AuthenticationError)\")\n",
    "            mlflow.log_param(\"Error\", str(auth_error))\n",
    "            raise openai.AuthenticationError(f\"OpenAI API key authentication failed: {auth_error}\")\n",
    "        except openai.OpenAIError as general_error:\n",
    "            mlflow.log_param(\"API Key Verification\", \"Failed (OpenAIError)\")\n",
    "            mlflow.log_param(\"Error\", str(general_error))\n",
    "            print(f\"⚠️ Warning: OpenAI API client initialized, but a test call failed with: {general_error}. Further API calls might fail.\")\n",
    "            mlflow.log_param(\"API Key Verification Warning\", str(general_error))\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"FileNotFoundError\")\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        raise\n",
    "    except ValueError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"ValueError\")\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        raise\n",
    "    except openai.AuthenticationError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"AuthenticationError\")\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        raise\n",
    "    except openai.OpenAIError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"OpenAIError\")\n",
    "        print(f\"⚠️ Warning during API initialization: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        # Log the error if any other unexpected issue occurs\n",
    "        mlflow.log_param(\"Error Type\", type(e).__name__)\n",
    "        mlflow.log_param(\"Error\", str(e))\n",
    "        print(f\"❌ An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        # End the MLFlow run\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d949ba3-7cf4-4bda-9e56-6a4f43cb8882",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 3: Test Embedding** <a class=\"anchor\" id=\"tki_page_2\"></a>\n",
    "\n",
    "[Back to Top](#tki_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8da8f526-a61f-4805-9d71-2a20383e45f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenAI client found and ready.\n",
      "📝 Testing embedding for text: 'The quick brown fox jumps over the lazy dog.'\n",
      "✅ Embedding model 'text-embedding-3-small' is available.\n",
      "Embedding length: 1536\n",
      "Embedding snippet: [-0.01842353865504265, -0.00725775770843029, 0.0036669441033154726, -0.0542047917842865, -0.022724902257323265, 0.03694858402013779, 0.02903103083372116, 0.023866858333349228, 0.011229223571717739, -0.020618630573153496]\n",
      "✅ Embedding API test successful.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import mlflow\n",
    "\n",
    "# Function to test the OpenAI Embedding API\n",
    "def test_openai_embedding_api():\n",
    "    with mlflow.start_run(run_name=\"Test Embedding API\") as run:\n",
    "        try:\n",
    "            # Log the step name\n",
    "            mlflow.log_param(\"Step\", \"Test Embedding API\")\n",
    "\n",
    "            # Evaluation: Check if the OpenAI client is initialized\n",
    "            if 'client' not in globals() or not isinstance(client, openai.OpenAI):\n",
    "                error_message = \"OpenAI client is not initialized. Ensure the API key setup step was executed successfully.\"\n",
    "                mlflow.log_param(\"API Client Stkius\", \"Not Initialized\")\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                raise RuntimeError(error_message)\n",
    "            else:\n",
    "                mlflow.log_param(\"API Client Stkius\", \"Initialized\")\n",
    "                print(\"✅ OpenAI client found and ready.\")\n",
    "\n",
    "            # Example text to embed\n",
    "            text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "            mlflow.log_param(\"Test Text\", text)\n",
    "            print(f\"📝 Testing embedding for text: '{text}'\")\n",
    "\n",
    "            # Evaluation: Check if the specified embedding model is available (optional, but good practice)\n",
    "            embedding_model = \"text-embedding-3-small\"\n",
    "            mlflow.log_param(\"Embedding Model\", embedding_model)\n",
    "            try:\n",
    "                model_info = client.models.retrieve(embedding_model)\n",
    "                mlflow.log_param(\"Embedding Model Availability\", \"Confirmed\")\n",
    "                print(f\"✅ Embedding model '{embedding_model}' is available.\")\n",
    "            except openai.NotFoundError:\n",
    "                error_message = f\"Embedding model '{embedding_model}' not found. Please check the model name.\"\n",
    "                mlflow.log_param(\"Embedding Model Availability\", \"Not Found\")\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                raise ValueError(error_message)\n",
    "            except Exception as e:\n",
    "                error_message = f\"Error checking embedding model availability: {e}\"\n",
    "                mlflow.log_param(\"Embedding Model Availability Check Error\", str(e))\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                print(f\"⚠️ Warning: Error checking model availability: {e}. Proceeding with embedding request.\")\n",
    "\n",
    "            # Request to generate embeddings\n",
    "            response = client.embeddings.create(\n",
    "                input=[text],  # The input should be a list of strings\n",
    "                model=embedding_model\n",
    "            )\n",
    "\n",
    "            # Evaluation: Check if the embedding response contains data\n",
    "            if not response.data:\n",
    "                error_message = \"Embedding API response does not contain any data.\"\n",
    "                mlflow.log_param(\"Embedding API Response Stkius\", \"No Data\")\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                raise ValueError(error_message)\n",
    "            else:\n",
    "                mlflow.log_param(\"Embedding API Response Stkius\", \"Data Received\")\n",
    "\n",
    "            # Extract the embedding\n",
    "            embedding = response.data[0].embedding\n",
    "\n",
    "            # Evaluation: Check if the extracted embedding is not empty\n",
    "            if not embedding:\n",
    "                error_message = \"Extracted embedding is empty.\"\n",
    "                mlflow.log_param(\"Embedding Extraction Stkius\", \"Empty Embedding\")\n",
    "                mlflow.log_param(\"Error\", error_message)\n",
    "                raise ValueError(error_message)\n",
    "            else:\n",
    "                mlflow.log_param(\"Embedding Extraction Stkius\", \"Success\")\n",
    "\n",
    "            # Log the embedding length and a snippet\n",
    "            embedding_length = len(embedding)\n",
    "            mlflow.log_param(\"Embedding Length\", embedding_length)\n",
    "            mlflow.log_param(\"Embedding Snippet\", embedding[:10])\n",
    "\n",
    "            # Print the embedding length and a snippet\n",
    "            print(f\"Embedding length: {embedding_length}\")\n",
    "            print(f\"Embedding snippet: {embedding[:10]}\")  # Print the first 10 elements of the embedding\n",
    "\n",
    "            print(\"✅ Embedding API test successful.\")\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            mlflow.log_param(\"Error Type\", \"RuntimeError\")\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"❌ Error: {e}\")\n",
    "            raise\n",
    "        except ValueError as e:\n",
    "            mlflow.log_param(\"Error Type\", \"ValueError\")\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"❌ Error: {e}\")\n",
    "            raise\n",
    "        except openai.NotFoundError as e:\n",
    "            mlflow.log_param(\"Error Type\", \"NotFoundError\")\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"❌ Error: {e}\")\n",
    "            raise\n",
    "        except openai.OpenAIError as e:\n",
    "            mlflow.log_param(\"Error Type\", \"OpenAIError\")\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"❌ OpenAI API error: {e}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            # Log the error if any other unexpected issue occurs\n",
    "            mlflow.log_param(\"Error Type\", type(e).__name__)\n",
    "            mlflow.log_param(\"Error\", str(e))\n",
    "            print(f\"❌ An unexpected error occurred: {e}\")\n",
    "            raise\n",
    "\n",
    "        finally:\n",
    "            # End the MLFlow run\n",
    "            mlflow.end_run()\n",
    "\n",
    "# Test the OpenAI Embedding API\n",
    "test_openai_embedding_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c144305-f45d-4bd8-bb64-b5873d8b1029",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 4: Create TKI Embeddings** <a class=\"anchor\" id=\"tki_page_3\"></a>\n",
    "\n",
    "[Back to Top](#tki_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fbcfbc8-c245-4b72-b1c0-37c5cc8f57ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenAI client initialized.\n",
      "✅ Dataset loaded: ../Datasets/tki.csv (20 rows)\n",
      "⏳ Started embeddings at 2025-05-24 23:33:12.676615\n",
      "✅ Finished embeddings at 2025-05-24 23:33:24.774469 (took 0:00:12.097854)\n",
      "💾 Embeddings saved to ../Embeddings/tki_embeddings.csv\n",
      "\n",
      "Sample rows:\n",
      "        Category         Factor  \\\n",
      "0  Conflict Mode      Competing   \n",
      "1  Conflict Mode      Competing   \n",
      "2  Conflict Mode      Competing   \n",
      "3  Conflict Mode      Competing   \n",
      "4  Conflict Mode  Collaborating   \n",
      "\n",
      "                                           Adjective      Synonym  \\\n",
      "0  Assertive and uncooperative mode, pursuing own...   Aggressive   \n",
      "1  Assertive and uncooperative mode, pursuing own...    Assertive   \n",
      "2  Assertive and uncooperative mode, pursuing own...     Dominant   \n",
      "3  Assertive and uncooperative mode, pursuing own...  Controlling   \n",
      "4  Assertive and cooperative mode, finding mutual...  Cooperative   \n",
      "\n",
      "          Verb           Noun  \\\n",
      "0      Compete    Competition   \n",
      "1       Assert      Assertion   \n",
      "2     Dominate      Dominance   \n",
      "3      Control        Control   \n",
      "4  Collaborate  Collaboration   \n",
      "\n",
      "                                           Embedding  \n",
      "0  [0.018110601231455803, 0.010554433800280094, 0...  \n",
      "1  [0.01708870381116867, 0.009367242455482483, 0....  \n",
      "2  [0.015169601887464523, 0.018460361286997795, 0...  \n",
      "3  [0.017812145873904228, 0.025348054245114326, 0...  \n",
      "4  [0.0023178826086223125, 0.013064720667898655, ...  \n",
      "🏃 View run Generate TKI Embeddings at: http://127.0.0.1:5000/#/experiments/0/runs/4778a64efd6247f0b7541b21376929ab\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ─── Setup ─────────────────────────────────────────────────────────────────────\n",
    "load_dotenv(override=True)\n",
    "\n",
    "def get_openai_api_key_from_file(filepath='~/openai_api_key.txt'):\n",
    "    filepath = os.path.expanduser(filepath)\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            api_key = f.read().strip()\n",
    "        if not api_key:\n",
    "            raise ValueError(f\"API key file at '{filepath}' is empty.\")\n",
    "        return api_key\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"API key file not found at '{filepath}'.\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error reading API key from file '{filepath}': {e}\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "try:\n",
    "    openai_api_key = get_openai_api_key_from_file()\n",
    "    client = OpenAI(api_key=openai_api_key)\n",
    "    print(\"✅ OpenAI client initialized.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error initializing OpenAI client: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ─── Load dataset ────────────────────────────────────────────────────────────────\n",
    "dataset_path = '../Datasets/tki.csv'\n",
    "try:\n",
    "    tki_df = pd.read_csv(dataset_path)\n",
    "    print(f\"✅ Dataset loaded: {dataset_path} ({tki_df.shape[0]} rows)\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"Dataset not found at {dataset_path}\")\n",
    "\n",
    "# ─── Embedding helper ───────────────────────────────────────────────────────────\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    try:\n",
    "        resp = client.embeddings.create(input=[text], model=model)\n",
    "        return resp.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error generating embedding for '{text}': {e}\")\n",
    "        raise\n",
    "\n",
    "# ─── Generate & log embeddings ─────────────────────────────────────────────────\n",
    "with mlflow.start_run(run_name=\"Generate TKI Embeddings\") as run:\n",
    "    mlflow.log_param(\"model\", \"text-embedding-3-small\")\n",
    "    mlflow.log_param(\"dataset\", dataset_path)\n",
    "    start = datetime.now()\n",
    "    mlflow.log_param(\"start_time\", str(start))\n",
    "    print(f\"⏳ Started embeddings at {start}\")\n",
    "\n",
    "    if tki_df.empty:\n",
    "        raise ValueError(\"Loaded dataset is empty.\")\n",
    "\n",
    "    # Build a prompt string from each row’s columns\n",
    "    tki_df['Embedding'] = tki_df.apply(\n",
    "        lambda r: get_embedding(\n",
    "            f\"{r['Category']} {r['Factor']} {r['Adjective']} \"\n",
    "            f\"{r['Synonym']} {r['Verb']} {r['Noun']}\"\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    end = datetime.now()\n",
    "    mlflow.log_param(\"end_time\", str(end))\n",
    "    print(f\"✅ Finished embeddings at {end} (took {end - start})\")\n",
    "\n",
    "    # Save and log embeddings CSV\n",
    "    out_path = '../Embeddings/tki_embeddings.csv'\n",
    "    tki_df[\n",
    "        ['Category','Factor','Adjective','Synonym','Verb','Noun','Embedding']\n",
    "    ].to_csv(out_path, index=False)\n",
    "    mlflow.log_artifact(out_path, artifact_path=\"embeddings\")\n",
    "    print(f\"💾 Embeddings saved to {out_path}\")\n",
    "\n",
    "    # Log run statistics\n",
    "    mlflow.log_param(\"num_rows\",     tki_df.shape[0])\n",
    "    mlflow.log_param(\"num_columns\",  tki_df.shape[1])\n",
    "    mlflow.log_param(\"embedding_length\", len(tki_df['Embedding'].iloc[0]))\n",
    "\n",
    "    print(\"\\nSample rows:\")\n",
    "    print(tki_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34b9502-e9f9-4b20-bbb4-813e3e5dd54a",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 5: Create Label Embeddings** <a class=\"anchor\" id=\"tki_page_3\"></a>\n",
    "\n",
    "[Back to Top](#tki_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddfe5c0b-fda2-439c-9348-ac797b5eb29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embeddings dataset loaded from: ../Embeddings/tki_embeddings.csv\n",
      "💾 Label encoder saved to: ../Models/tki_label_encoder.pkl\n",
      "          Factor  Factor_Encoded\n",
      "0      Competing               3\n",
      "1      Competing               3\n",
      "2      Competing               3\n",
      "3      Competing               3\n",
      "4  Collaborating               2\n",
      "\n",
      "Mapping:\n",
      "  Accommodating → 0\n",
      "  Avoiding → 1\n",
      "  Collaborating → 2\n",
      "  Competing → 3\n",
      "  Compromising → 4\n",
      "✅ Plot saved to /Users/jsr/Downloads/GitHub/Personality-Trait-Models/Notebooks/tki_label_encoder_mapping.png\n",
      "🏃 View run Create and Visualize Label Encoder at: http://127.0.0.1:5000/#/experiments/0/runs/2bd04210217f4029ad31c1ea0670f7dc\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n",
      "✅ Label encoding and visualization complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#── 1) Load embeddings dataset ───────────────────────────────────────────────\n",
    "embeddings_csv_path = '../Embeddings/tki_embeddings.csv'\n",
    "try:\n",
    "    df = pd.read_csv(embeddings_csv_path)\n",
    "    print(f\"✅ Embeddings dataset loaded from: {embeddings_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: Embeddings dataset not found at: {embeddings_csv_path}\")\n",
    "    exit(1)\n",
    "\n",
    "#── 2) Fit LabelEncoder on the 'Factor' column ────────────────────────────────\n",
    "label_encoder = LabelEncoder()\n",
    "df['Factor_Encoded'] = label_encoder.fit_transform(df['Factor'])\n",
    "\n",
    "#── 3) Save the encoder to disk ───────────────────────────────────────────────\n",
    "os.makedirs(\"../Models\", exist_ok=True)\n",
    "label_encoder_path = \"../Models/tki_label_encoder.pkl\"\n",
    "joblib.dump(label_encoder, label_encoder_path)\n",
    "print(f\"💾 Label encoder saved to: {label_encoder_path}\")\n",
    "\n",
    "#── 4) Visualization helper ───────────────────────────────────────────────────\n",
    "def visualize_label_encoder(le, artifact_path=\"visualization\"):\n",
    "    classes = le.classes_\n",
    "    values  = le.transform(classes)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=classes, y=values)\n",
    "    plt.xlabel(\"Conflict Mode (Factor)\")\n",
    "    plt.ylabel(\"Encoded Value\")\n",
    "    plt.title(\"TKI Conflict Modes → Encoded Mapping\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    out_file = \"tki_label_encoder_mapping.png\"\n",
    "    plt.savefig(out_file)\n",
    "    plt.close()\n",
    "    print(f\"✅ Plot saved to {os.path.abspath(out_file)}\")\n",
    "    mlflow.log_artifact(out_file, artifact_path=artifact_path)\n",
    "\n",
    "#── 5) Log everything in MLflow ────────────────────────────────────────────────\n",
    "with mlflow.start_run(run_name=\"Create and Visualize Label Encoder\"):\n",
    "    mlflow.log_param(\"step\", \"label_encoding\")\n",
    "    mlflow.log_artifact(label_encoder_path, artifact_path=\"label_encoder\")\n",
    "\n",
    "    # preview\n",
    "    print(df[['Factor', 'Factor_Encoded']].head())\n",
    "    mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    print(\"\\nMapping:\")\n",
    "    for k, v in mapping.items():\n",
    "        print(f\"  {k} → {v}\")\n",
    "    mlflow.log_dict(mapping, \"label_encoder/mapping.json\")\n",
    "\n",
    "    # make & log the bar chart\n",
    "    visualize_label_encoder(label_encoder)\n",
    "\n",
    "print(\"✅ Label encoding and visualization complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a5fde5-2c9a-46dc-998a-ca01c356e80e",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 6: Create Model** <a class=\"anchor\" id=\"tki_page_3\"></a>\n",
    "\n",
    "[Back to Top](#tki_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc4b4c49-a90c-4b4e-9235-6a2036f6cb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embeddings dataset loaded from: ../Embeddings/tki_embeddings.csv\n",
      "✅ Label encoder loaded from: ../Models/tki_label_encoder.pkl\n",
      "Train samples: 12, Test samples: 8\n",
      "⏳ Training started at 2025-05-24 23:36:29.247798\n",
      "✅ Training finished at 2025-05-24 23:36:29.302274 (Duration: 0:00:00.054476)\n",
      "🔍 Test accuracy: 1.0000\n",
      "📊 Classification report saved to tki_classification_report.csv\n",
      "📊 Confusion matrix saved to tki_confusion_matrix.csv\n",
      "🖼️ Saved confusion matrix plot to tki_confusion_matrix.png\n",
      "💾 Trained model saved to ../Models/tki_rf_model.pkl\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Accommodating       1.00      1.00      1.00         2\n",
      "     Avoiding       1.00      1.00      1.00         1\n",
      "Collaborating       1.00      1.00      1.00         2\n",
      "    Competing       1.00      1.00      1.00         2\n",
      " Compromising       1.00      1.00      1.00         1\n",
      "\n",
      "     accuracy                           1.00         8\n",
      "    macro avg       1.00      1.00      1.00         8\n",
      " weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "                Accommodating  Avoiding  Collaborating  Competing  Compromising\n",
      "Accommodating              2         0              0          0             0\n",
      "Avoiding                   0         1              0          0             0\n",
      "Collaborating              0         0              2          0             0\n",
      "Competing                  0         0              0          2             0\n",
      "Compromising               0         0              0          0             1\n",
      "🏃 View run TKI_RF_Training at: http://127.0.0.1:5000/#/experiments/0/runs/fbfefed623bb491ca206cebf56b9e062\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#── 1) Load embeddings dataset ───────────────────────────────────────────────\n",
    "embeddings_csv_path = '../Embeddings/tki_embeddings.csv'\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        embeddings_csv_path,\n",
    "        converters={'Embedding': lambda s: np.array(eval(s)) if isinstance(s, str) else np.array(s)}\n",
    "    )\n",
    "    print(f\"✅ Embeddings dataset loaded from: {embeddings_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: Embeddings dataset not found at: {embeddings_csv_path}\")\n",
    "    exit(1)\n",
    "\n",
    "#── 2) Load the pre-fitted label encoder ───────────────────────────────────────\n",
    "label_encoder_path = \"../Models/tki_label_encoder.pkl\"\n",
    "try:\n",
    "    label_encoder = joblib.load(label_encoder_path)\n",
    "    print(f\"✅ Label encoder loaded from: {label_encoder_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: Label encoder not found at: {label_encoder_path}\")\n",
    "    exit(1)\n",
    "\n",
    "#── 3) Prepare features and labels ───────────────────────────────────────────\n",
    "X = np.stack(df['Embedding'].values)     # shape: (n_samples, embedding_dim)\n",
    "y = df['Factor'].values                  # target is the TKI Factor (mode)\n",
    "y_encoded = label_encoder.transform(y)   # numeric labels\n",
    "\n",
    "#── 4) Split into train/test ─────────────────────────────────────────────────\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded,\n",
    "    test_size=0.4,\n",
    "    random_state=42,\n",
    "    stratify=y_encoded\n",
    ")\n",
    "print(f\"Train samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "#── 5) Start MLflow run ──────────────────────────────────────────────────────\n",
    "with mlflow.start_run(run_name=\"TKI_RF_Training\") as run:\n",
    "    # Log params\n",
    "    mlflow.log_param(\"model_type\", \"RandomForestClassifier\")\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"test_size\", 0.4)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_artifact(label_encoder_path, artifact_path=\"label_encoder\")\n",
    "\n",
    "    start_ts = datetime.now()\n",
    "    mlflow.log_param(\"start_time\", str(start_ts))\n",
    "    print(f\"⏳ Training started at {start_ts}\")\n",
    "\n",
    "    # Train\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    end_ts = datetime.now()\n",
    "    mlflow.log_param(\"end_time\", str(end_ts))\n",
    "    print(f\"✅ Training finished at {end_ts} (Duration: {end_ts - start_ts})\")\n",
    "\n",
    "    # Predict & evaluate\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    print(f\"🔍 Test accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Classification report\n",
    "    report_dict = classification_report(\n",
    "        y_test, y_pred,\n",
    "        target_names=label_encoder.classes_,\n",
    "        output_dict=True\n",
    "    )\n",
    "    report_df = pd.DataFrame(report_dict).transpose()\n",
    "    report_path = \"tki_classification_report.csv\"\n",
    "    report_df.to_csv(report_path, index=True)\n",
    "    mlflow.log_artifact(report_path, artifact_path=\"metrics\")\n",
    "    print(f\"📊 Classification report saved to {report_path}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_df = pd.DataFrame(\n",
    "        cm,\n",
    "        index=label_encoder.classes_,\n",
    "        columns=label_encoder.classes_\n",
    "    )\n",
    "    cm_path = \"tki_confusion_matrix.csv\"\n",
    "    cm_df.to_csv(cm_path, index=True)\n",
    "    mlflow.log_artifact(cm_path, artifact_path=\"metrics\")\n",
    "    print(f\"📊 Confusion matrix saved to {cm_path}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"TKI RandomForest Confusion Matrix\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.tight_layout()\n",
    "    cm_img = \"tki_confusion_matrix.png\"\n",
    "    plt.savefig(cm_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cm_img, artifact_path=\"metrics\")\n",
    "    print(f\"🖼️ Saved confusion matrix plot to {cm_img}\")\n",
    "\n",
    "    # Save the trained model\n",
    "    os.makedirs(\"../Models\", exist_ok=True)\n",
    "    model_path = \"../Models/tki_rf_model.pkl\"\n",
    "    joblib.dump(clf, model_path)\n",
    "    mlflow.log_artifact(model_path, artifact_path=\"models\")\n",
    "    print(f\"💾 Trained model saved to {model_path}\")\n",
    "\n",
    "    # Final logs\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3656c2b1-5d3d-489d-9759-ed219e20d2b5",
   "metadata": {},
   "source": [
    "This block of code is a comprehensive step-by-step process focusing specifically on:\n",
    "1. **Data Loading and Preprocessing**: Parsing and preparing embeddings from a CSV file for machine learning.\n",
    "2. **Model Training**: Using a RandomForestClassifier to train on the embeddings.\n",
    "3. **Model Evaluation**: Calculating and logging metrics such as accuracy, alongside detailed classification reports and confusion matrices.\n",
    "4. **Visualization and Logging**: Visualizing the confusion matrix and logging both the visual representkiion and numerical data as artifacts in MLflow.\n",
    "5. **Model Persistence**: Saving the trained model for future use or deployment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b586cb-65eb-4f24-9726-c7b61611182c",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 7: Evaluate Model** <a class=\"anchor\" id=\"tki_page_3\"></a>\n",
    "\n",
    "[Back to Top](#tki_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bbc78ca-7e53-4ab5-8c7c-c2d2848d4367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embeddings dataset loaded from: ../Embeddings/tki_embeddings.csv\n",
      "✅ Label encoder loaded from: ../Models/tki_label_encoder.pkl\n",
      "✅ Trained model loaded from: ../Models/tki_rf_model.pkl\n",
      "Train size: 12, Test size: 8\n",
      "🔍 Test accuracy: 1.0000\n",
      "🏃 View run TKI Model Evaluation at: http://127.0.0.1:5000/#/experiments/0/runs/91c4a62256114107b6fe8e2d2eea31cb\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n",
      "✅ TKI model evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import mlflow\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#── Paths ─────────────────────────────────────────────────────────────────────\n",
    "embeddings_csv_path = '../Embeddings/tki_embeddings.csv'\n",
    "label_encoder_path  = '../Models/tki_label_encoder.pkl'\n",
    "model_path          = '../Models/tki_rf_model.pkl'\n",
    "\n",
    "#── 1) Load embeddings with converter ─────────────────────────────────────────\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        embeddings_csv_path,\n",
    "        converters={'Embedding': lambda s: np.array(ast.literal_eval(s)) if isinstance(s, str) else np.array(s)}\n",
    "    )\n",
    "    print(f\"✅ Embeddings dataset loaded from: {embeddings_csv_path}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ Error loading embeddings: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "#── 2) Load label encoder ─────────────────────────────────────────────────────\n",
    "try:\n",
    "    label_encoder = joblib.load(label_encoder_path)\n",
    "    print(f\"✅ Label encoder loaded from: {label_encoder_path}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ Error loading label encoder: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "#── 3) Load trained model ─────────────────────────────────────────────────────\n",
    "try:\n",
    "    loaded_clf = joblib.load(model_path)\n",
    "    print(f\"✅ Trained model loaded from: {model_path}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ Error loading model: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "#── 4) Prepare features & labels ──────────────────────────────────────────────\n",
    "X = np.stack(df['Embedding'].values)\n",
    "y = df['Factor'].values\n",
    "y_encoded = label_encoder.transform(y)\n",
    "\n",
    "#── 5) Train/test split ───────────────────────────────────────────────────────\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded,\n",
    "    test_size=0.4,\n",
    "    random_state=42,\n",
    "    stratify=y_encoded\n",
    ")\n",
    "print(f\"Train size: {X_train.shape[0]}, Test size: {X_test.shape[0]}\")\n",
    "\n",
    "#── 6) Evaluate under MLflow ─────────────────────────────────────────────────\n",
    "with mlflow.start_run(run_name=\"TKI Model Evaluation\"):\n",
    "    mlflow.log_param(\"step\", \"evaluate_model\")\n",
    "    mlflow.log_artifact(label_encoder_path, artifact_path=\"label_encoder\")\n",
    "    mlflow.log_artifact(model_path, artifact_path=\"model\")\n",
    "    mlflow.log_param(\"test_samples\", X_test.shape[0])\n",
    "\n",
    "    # Predict\n",
    "    y_pred = loaded_clf.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    print(f\"🔍 Test accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Classification report\n",
    "    report_dict = classification_report(\n",
    "        y_test, y_pred,\n",
    "        target_names=label_encoder.classes_,\n",
    "        output_dict=True\n",
    "    )\n",
    "    report_df = pd.DataFrame(report_dict).transpose()\n",
    "    report_path = \"tki_evaluation_classification_report.csv\"\n",
    "    report_df.to_csv(report_path, index=True)\n",
    "    mlflow.log_artifact(report_path, artifact_path=\"evaluation\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_df = pd.DataFrame(cm, index=label_encoder.classes_, columns=label_encoder.classes_)\n",
    "    cm_path = \"tki_evaluation_confusion_matrix.csv\"\n",
    "    cm_df.to_csv(cm_path, index=True)\n",
    "    mlflow.log_artifact(cm_path, artifact_path=\"evaluation\")\n",
    "\n",
    "    # Plot & log confusion matrix\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"Confusion Matrix (Test Set)\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.tight_layout()\n",
    "    cm_img = \"tki_evaluation_confusion_matrix.png\"\n",
    "    plt.savefig(cm_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cm_img, artifact_path=\"evaluation\")\n",
    "\n",
    "print(\"✅ TKI model evaluation complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af80057-6c04-4228-ae9b-ed84b87fa9a6",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 8: Test and Evaluate Model** <a class=\"anchor\" id=\"tki_page_3\"></a>\n",
    "\n",
    "[Back to Top](#tki_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe70d8f9-a9eb-4908-bbf9-db62ee23023b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Testing (Inference on New Data) ---\n",
      "✅ Label encoder loaded from: ../Models/tki_label_encoder.pkl\n",
      "✅ Trained model loaded from: ../Models/tki_rf_model.pkl\n",
      "\n",
      "--- Testing Model on New Data ---\n",
      "Predicted Factor for 'I love going to parties and meeting new people....': Compromising\n",
      "Predicted Factor for 'I prefer staying home with a good book....': Avoiding\n",
      "Predicted Factor for 'I often feel anxious and worried....': Collaborating\n",
      "Predicted Factor for 'I am generally calm and relaxed....': Compromising\n",
      "Predicted Factor for 'I enjoy taking risks and trying new things....': Compromising\n",
      "🏃 View run Step 7: Model Testing (Inference on New Data) at: http://127.0.0.1:5000/#/experiments/0/runs/094b6a53541a40e28f0332e4a078eeb8\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n",
      "\n",
      "✅ Model testing (inference on new data) complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import joblib\n",
    "from openai import OpenAI  # Keep this import for type hinting or other openai functions\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "label_encoder_path = \"../Models/tki_label_encoder.pkl\"\n",
    "model_path = \"../Models/tki_rf_model.pkl\"\n",
    "\n",
    "# -------------------- Utility Function --------------------\n",
    "\n",
    "def parse_embedding(embedding_str):\n",
    "    \"\"\"\n",
    "    Converts a string representkiion of an embedding (from the CSV)\n",
    "    into a NumPy array.\n",
    "\n",
    "    Args:\n",
    "        embedding_str: The string representkiion of the embedding.\n",
    "\n",
    "    Returns:\n",
    "        A NumPy array representing the embedding.\n",
    "    \"\"\"\n",
    "    return np.fromstring(embedding_str.strip(\"\"), sep=\", \")\n",
    "\n",
    "# -------------------- Embedding Function --------------------\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    \"\"\"\n",
    "    Generates an embedding for the given text using the OpenAI API.\n",
    "\n",
    "    Args:\n",
    "        text: The text to embed.\n",
    "        model: The name of the embedding model to use.\n",
    "\n",
    "    Returns:\n",
    "        The generated embedding as a list.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.embeddings.create(input=[text], model=model)\n",
    "        embedding = response.data[0].embedding\n",
    "        return embedding\n",
    "    except openai.OpenAIError as e:\n",
    "        print(f\"❌ OpenAI API error during embedding generation: {e}\")\n",
    "        raise\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=\"Step 7: Model Testing (Inference on New Data)\") as run:\n",
    "    try:\n",
    "        mlflow.log_param(\"Step\", \"Model Testing (Inference on New Data)\")\n",
    "        mlflow.log_artifact(label_encoder_path, artifact_path=\"label_encoder\")\n",
    "        mlflow.log_artifact(model_path, artifact_path=\"model\")\n",
    "\n",
    "        print(\"\\n--- Model Testing (Inference on New Data) ---\")\n",
    "\n",
    "        # Load the pre-fitted label encoder\n",
    "        try:\n",
    "            label_encoder = joblib.load(label_encoder_path)\n",
    "            print(f\"✅ Label encoder loaded from: {label_encoder_path}\")\n",
    "        except FileNotFoundError:\n",
    "            mlflow.log_param(\"Error Type\", \"FileNotFoundError\")\n",
    "            mlflow.log_param(\n",
    "                \"Error\", f\"Label encoder not found at: {label_encoder_path}\"\n",
    "            )\n",
    "            print(f\"❌ Error: Label encoder not found at: {label_encoder_path}\")\n",
    "            raise\n",
    "\n",
    "        # Load the trained model\n",
    "        try:\n",
    "            loaded_clf = joblib.load(model_path)\n",
    "            print(f\"✅ Trained model loaded from: {model_path}\")\n",
    "        except FileNotFoundError:\n",
    "            mlflow.log_param(\"Error Type\", \"FileNotFoundError\")\n",
    "            mlflow.log_param(\"Error\", f\"Model not found at: {model_path}\")\n",
    "            print(f\"❌ Error: {e}\")\n",
    "            raise\n",
    "\n",
    "        # -------------------- Model Application/Inference --------------------\n",
    "\n",
    "        def predict_factor(new_text):\n",
    "            \"\"\"\n",
    "            Predicts the personality factor for new text using the trained model\n",
    "            and the saved label encoder.\n",
    "\n",
    "            Args:\n",
    "                new_text: The text to predict the personality factor for.\n",
    "\n",
    "            Returns:\n",
    "                The predicted personality factor.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                # Get the embedding for the new text\n",
    "                new_embedding = get_embedding(new_text)\n",
    "\n",
    "                # Predict the factor\n",
    "                predicted_factor_encoded = loaded_clf.predict([new_embedding])\n",
    "\n",
    "                # Decode the prediction using the label encoder\n",
    "                predicted_factor = label_encoder.inverse_transform(\n",
    "                    predicted_factor_encoded\n",
    "                )[0]\n",
    "\n",
    "                return predicted_factor\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ An error occurred during prediction: {e}\")\n",
    "                raise\n",
    "\n",
    "        # Example usage:\n",
    "        test_texts = [\n",
    "            \"I love going to parties and meeting new people.\",\n",
    "            \"I prefer staying home with a good book.\",\n",
    "            \"I often feel anxious and worried.\",\n",
    "            \"I am generally calm and relaxed.\",\n",
    "            \"I enjoy taking risks and trying new things.\"\n",
    "        ]\n",
    "        mlflow.log_param(\"Number of Test Inputs\", len(test_texts))\n",
    "\n",
    "        print(\"\\n--- Testing Model on New Data ---\")\n",
    "        for i, text in enumerate(test_texts):\n",
    "            try:\n",
    "                predicted_factor = predict_factor(text)\n",
    "                print(f\"Predicted Factor for '{text[:50]}...': {predicted_factor}\")\n",
    "                mlflow.log_param(f\"New Text {i+1}\", text)\n",
    "                mlflow.log_param(f\"Predicted Factor {i+1}\", predicted_factor)\n",
    "            except Exception as e:\n",
    "                mlflow.log_param(\"Error Type\", type(e).__name__)\n",
    "                mlflow.log_param(\n",
    "                    \"Error\", f\"Error predicting for text: {text[:50]}...: {e}\"\n",
    "                )\n",
    "                print(f\"❌ Error predicting for text: {text[:50]}...: {e}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        mlflow.log_param(\"Error Type\", \"FileNotFoundError\")\n",
    "        mlflow.log_param(\"Error\", str(e))\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        mlflow.log_param(\"Error Type\", type(e).__name__)\n",
    "        mlflow.log_param(\"Error\", str(e))\n",
    "        print(f\"❌ An error occurred during model testing: {e}\")\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        mlflow.end_run()\n",
    "\n",
    "print(\"\\n✅ Model testing (inference on new data) complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dc0d50-5e9f-4b73-bb5f-f8e64b2c1f62",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 9: Visualize and Evaluate Model** <a class=\"anchor\" id=\"tki_page_3\"></a>\n",
    "\n",
    "[Back to Top](#tki_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02e69b18-6364-4067-98b8-4c144511dee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded embeddings from: ../Embeddings/tki_embeddings.csv\n",
      "⏳ Run started at 2025-05-24 23:37:45.892418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/05/24 23:37:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 In‑sample accuracy: 1.0000\n",
      "✅ Run finished at 2025-05-24 23:37:49.197028 (Duration: 0:00:03.304610)\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Accommodating       1.00      1.00      1.00         4\n",
      "     Avoiding       1.00      1.00      1.00         4\n",
      "Collaborating       1.00      1.00      1.00         4\n",
      "    Competing       1.00      1.00      1.00         4\n",
      " Compromising       1.00      1.00      1.00         4\n",
      "\n",
      "     accuracy                           1.00        20\n",
      "    macro avg       1.00      1.00      1.00        20\n",
      " weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "🏃 View run TKI Visualization & Eval at: http://127.0.0.1:5000/#/experiments/0/runs/0994f582900d4bc5926377df4714520c\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "#── 1) Load embeddings with safe parsing ───────────────────────────────────────\n",
    "embeddings_csv_path = '../Embeddings/tki_embeddings.csv'\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        embeddings_csv_path,\n",
    "        converters={'Embedding': lambda s: np.array(ast.literal_eval(s)) if isinstance(s, str) else np.array(s)}\n",
    "    )\n",
    "    print(f\"✅ Loaded embeddings from: {embeddings_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ File not found: {embeddings_csv_path}\")\n",
    "    exit(1)\n",
    "\n",
    "#── 2) Prepare features and labels ────────────────────────────────────────────\n",
    "X = np.stack(df['Embedding'].values)\n",
    "y = df['Factor'].values                       # use 'Index' (VCI, PRI, WMI, PSI)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "#── 3) Start MLflow run ───────────────────────────────────────────────────────\n",
    "with mlflow.start_run(run_name=\"TKI Visualization & Eval\") as run:\n",
    "    mlflow.log_param(\"step\", \"visualize_and_evaluate\")\n",
    "    mlflow.log_param(\"dataset\", embeddings_csv_path)\n",
    "    start_ts = datetime.now()\n",
    "    mlflow.log_param(\"start_time\", str(start_ts))\n",
    "    print(f\"⏳ Run started at {start_ts}\")\n",
    "\n",
    "    #── 4) Train a RandomForest on full data ────────────────────────────────\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X, y_encoded)\n",
    "    mlflow.sklearn.log_model(clf, \"tki_rf_model\")\n",
    "\n",
    "    #── 5) In‑sample evaluation ──────────────────────────────────────────────\n",
    "    y_pred = clf.predict(X)\n",
    "    acc = accuracy_score(y_encoded, y_pred)\n",
    "    mlflow.log_metric(\"in_sample_accuracy\", acc)\n",
    "    print(f\"🔍 In‑sample accuracy: {acc:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(y_encoded, y_pred)\n",
    "    cm_df = pd.DataFrame(cm, index=le.classes_, columns=le.classes_)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"Confusion Matrix (In‑Sample)\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    cm_img = \"tki_confusion_matrix.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cm_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cm_img, artifact_path=\"evaluation\")\n",
    "\n",
    "    #── 6) PCA visualization ────────────────────────────────────────────────\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    scatter = plt.scatter(X_pca[:,0], X_pca[:,1], c=y_encoded, cmap='viridis', alpha=0.7)\n",
    "    # correct legend call:\n",
    "    handles, _ = scatter.legend_elements()\n",
    "    plt.legend(handles, le.classes_, title=\"Factor\")\n",
    "    plt.title(\"PCA of TKI Embeddings\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    pca_img = \"tki_pca.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(pca_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(pca_img, artifact_path=\"visualization\")\n",
    "\n",
    "    #── 7) K‑Means clustering ────────────────────────────────────────────────\n",
    "    kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X)\n",
    "    df['Cluster'] = clusters\n",
    "    clustered_path = '../Embeddings/tki_clustered_embeddings.csv'\n",
    "    df.to_csv(clustered_path, index=False)\n",
    "    mlflow.log_artifact(clustered_path, artifact_path=\"clustered_data\")\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    scatter = plt.scatter(X_pca[:,0], X_pca[:,1], c=clusters, cmap='tab10', alpha=0.7)\n",
    "    plt.title(\"K‑Means Clusters of TKI Embeddings\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    cluster_img = \"tki_clusters.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cluster_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cluster_img, artifact_path=\"visualization\")\n",
    "\n",
    "    #── 8) Log end time ──────────────────────────────────────────────────────\n",
    "    end_ts = datetime.now()\n",
    "    mlflow.log_param(\"end_time\", str(end_ts))\n",
    "    print(f\"✅ Run finished at {end_ts} (Duration: {end_ts - start_ts})\")\n",
    "\n",
    "    #── 9) Optional: show classification report ─────────────────────────────\n",
    "    report = classification_report(y_encoded, y_pred, target_names=le.classes_)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d6c46-cbed-44b1-acd1-f36a71195fca",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 10: Save Visualization and Evaluation of Model** <a class=\"anchor\" id=\"tki_page_3\"></a>\n",
    "\n",
    "[Back to Top](#tki_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b7e7cb8-ba04-4b99-b982-7dde60729478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded embeddings from: ../Embeddings/tki_embeddings.csv\n",
      "✅ LabelEncoder loaded from: ../Models/tki_label_encoder.pkl\n",
      "✅ RandomForest model loaded from: ../Models/tki_rf_model.pkl\n",
      "⏳ Run started at 2025-05-24 23:38:15.583762\n",
      "✅ PCA plot saved: tki_pca.png\n",
      "✅ Clustered data saved: tki_clustered_embeddings.csv\n",
      "✅ Cluster plot saved: tki_clusters.png\n",
      "✅ Run finished at 2025-05-24 23:38:15.732010 (Duration: 0:00:00.148248)\n",
      "🏃 View run TKI PCA & Clustering at: http://127.0.0.1:5000/#/experiments/0/runs/1390abf768ac46dcbe5f51efc1e03d54\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import joblib\n",
    "import mlflow\n",
    "\n",
    "#── 1) Paths ─────────────────────────────────────────────────────────────────\n",
    "EMBEDDINGS_CSV = '../Embeddings/tki_embeddings.csv'\n",
    "LABEL_ENCODER_PKL = '../Models/tki_label_encoder.pkl'\n",
    "RF_MODEL_PKL = '../Models/tki_rf_model.pkl'\n",
    "\n",
    "#── 2) Load embeddings and parse ──────────────────────────────────────────────\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        EMBEDDINGS_CSV,\n",
    "        converters={'Embedding': lambda s: np.array(ast.literal_eval(s))}\n",
    "    )\n",
    "    print(f\"✅ Loaded embeddings from: {EMBEDDINGS_CSV}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ Embeddings CSV not found: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "#── 3) Load artifacts ─────────────────────────────────────────────────────────\n",
    "try:\n",
    "    label_encoder = joblib.load(LABEL_ENCODER_PKL)\n",
    "    print(f\"✅ LabelEncoder loaded from: {LABEL_ENCODER_PKL}\")\n",
    "    rf_model = joblib.load(RF_MODEL_PKL)\n",
    "    print(f\"✅ RandomForest model loaded from: {RF_MODEL_PKL}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ Artifact missing: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "#── 4) Prepare data ──────────────────────────────────────────────────────────\n",
    "X = np.stack(df['Embedding'].values)\n",
    "y = df['Factor'].values                # use 'Index', not 'Factor'\n",
    "y_encoded = label_encoder.transform(y)\n",
    "\n",
    "#── 5) Begin MLflow run ──────────────────────────────────────────────────────\n",
    "with mlflow.start_run(run_name=\"TKI PCA & Clustering\") as run:\n",
    "    mlflow.log_param(\"step\", \"PCA_and_KMeans\")\n",
    "    mlflow.log_param(\"embeddings_csv\", EMBEDDINGS_CSV)\n",
    "    start_ts = datetime.now()\n",
    "    mlflow.log_param(\"start_time\", str(start_ts))\n",
    "    print(f\"⏳ Run started at {start_ts}\")\n",
    "\n",
    "    #── 6) PCA visualization ────────────────────────────────────────────────\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    scatter = plt.scatter(X_pca[:,0], X_pca[:,1], c=y_encoded, cmap='viridis', alpha=0.7)\n",
    "    handles, _ = scatter.legend_elements()\n",
    "    plt.legend(handles, label_encoder.classes_, title=\"Factor\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.title(\"PCA of TKI Embeddings\")\n",
    "    plt.tight_layout()\n",
    "    pca_img = \"tki_pca.png\"\n",
    "    plt.savefig(pca_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(pca_img, artifact_path=\"visualization\")\n",
    "    print(f\"✅ PCA plot saved: {pca_img}\")\n",
    "\n",
    "    #── 7) K-Means clustering ───────────────────────────────────────────────\n",
    "    n_clusters = 4\n",
    "    mlflow.log_param(\"n_clusters\", n_clusters)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X)\n",
    "    df['Cluster'] = clusters\n",
    "\n",
    "    clustered_csv = \"tki_clustered_embeddings.csv\"\n",
    "    df.to_csv(clustered_csv, index=False)\n",
    "    mlflow.log_artifact(clustered_csv, artifact_path=\"clustered_data\")\n",
    "    print(f\"✅ Clustered data saved: {clustered_csv}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    scatter = plt.scatter(X_pca[:,0], X_pca[:,1], c=clusters, cmap='tab10', alpha=0.7)\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.title(\"K-Means Clusters of TKI Embeddings\")\n",
    "    plt.tight_layout()\n",
    "    cluster_img = \"tki_clusters.png\"\n",
    "    plt.savefig(cluster_img)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cluster_img, artifact_path=\"visualization\")\n",
    "    print(f\"✅ Cluster plot saved: {cluster_img}\")\n",
    "\n",
    "    #── 8) Model inference demo (optional) ───────────────────────────────────\n",
    "    # Using the loaded rf_model on the PCA features, if desired\n",
    "    # pred = rf_model.predict(X)\n",
    "    # print(\"Demo predictions:\", label_encoder.inverse_transform(pred[:5]))\n",
    "\n",
    "    #── 9) End run ────────────────────────────────────────────────────────────\n",
    "    end_ts = datetime.now()\n",
    "    mlflow.log_param(\"end_time\", str(end_ts))\n",
    "    print(f\"✅ Run finished at {end_ts} (Duration: {end_ts - start_ts})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013ba63c-ce13-4667-a5d9-a799ab883b97",
   "metadata": {},
   "source": [
    "This block of code integrates several stages that not only include training but also applying the model to new data and exploring the data through clustering:\n",
    "1. **Data Loading and Feature Parsing**: Similar to Block 1, with an additional step of displaying the parsed data.\n",
    "2. **Model Creation and Logging**: Training a RandomForestClassifier and logging the model directly with MLflow for possibly immediate deployment.\n",
    "3. **Model Evaluation and Reporting**: Assessing model performance with metrics and detailed reports, and logging these evaluations.\n",
    "4. **Clustering Analysis**: Utilizing KMeans to perform clustering on the embeddings, which adds an exploratory data analysis component.\n",
    "5. **Model Application on New Data**: Demonstrating a practical application of the trained model to predict factors for new text inputs.\n",
    "6. **End-to-End Experiment Tracking**: From the beginning of the run to its completion, tracking all parameters, artifacts, and outcomes, emphasizing a full-cycle view of the modeling process.\n",
    "\n",
    "This provides a broader overview of how a model can be developed and applied within a workflow that includes prediction and clustering alongside the fundamental steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f3cfce-24bd-4f6c-a748-54b1fe39d107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5916893-8b0f-450f-9ce6-09015901f5eb",
   "metadata": {},
   "source": [
    "The results show that the RandomForestClassifier model trained on the dataset of embeddings has achieved an accuracy of 1.0 on the test set, which means it has correctly classified all the test samples. Here is the breakdown of the evaluation:\n",
    "\n",
    "### Accuracy:\n",
    "- **1.0**: The model has 100% accuracy, meaning it correctly classified every instance in the test set.\n",
    "\n",
    "### Classification Report:\n",
    "- **Precision, Recall, and F1-score** for each class (0 through 4) are all 1.00.\n",
    "- **Support** indicates the number of actual occurrences of each class in the test set.\n",
    "\n",
    "### Interpretkiion:\n",
    "- **Precision**: This is the ratio of true positive predictions to the total predicted positives. A precision of 1.0 means that all instances predicted as a specific class were actually of that class.\n",
    "- **Recall**: This is the ratio of true positive predictions to the total actual positives. A recall of 1.0 means that all actual instances of a specific class were correctly predicted.\n",
    "- **F1-score**: This is the harmonic mean of precision and recall. An F1-score of 1.0 indicates perfect precision and recall.\n",
    "- **Support**: This indicates the number of true instances for each label in the test set. \n",
    "\n",
    "### Considerations:\n",
    "1. **Model Overfitting**: The perfect score could indicate overfitting, especially if the test set is small or not representkiive of unseen data.\n",
    "2. **Test Set Size**: The test set has only 24 samples, which is relatively small. It's important to ensure that the test set is large enough and representkiive to get a reliable estimate of model performance.\n",
    "3. **Data Leakage**: Double-check that there's no data leakage, meaning that no information from the test set was used during training.\n",
    "4. **Cross-Validation**: To better assess the model's performance, consider using cross-validation to ensure the model performs well across different subsets of the data.\n",
    "\n",
    "### Next Steps:\n",
    "- **Cross-validation**: Implement cross-validation to get a more robust evaluation of model performance.\n",
    "- **Larger Test Set**: If possible, increase the size of the test set to ensure the performance metrics are reliable.\n",
    "- **Feature Analysis**: Examine feature importance scores from the RandomForestClassifier to understand which parts of the embeddings contribute most to the predictions.\n",
    "\n",
    "### Updated Code for Cross-Validation:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(clf, X, y_encoded, cv=5)  # 5-fold cross-validation\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean cross-validation score: {np.mean(cv_scores)}\")\n",
    "```\n",
    "\n",
    "We added this cross-validation step will help us verify that the model generalizes well and is not just performing well on a small or potentially non-representkiive test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fac8dd-46d3-4595-99f0-f15b83e244a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(clf, X, y_encoded, cv=5)  # 5-fold cross-validation\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean cross-validation score: {np.mean(cv_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adf2f5ea-3181-4f0f-8a62-c95784cac78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 20 rows from ../Embeddings/tki_embeddings.csv\n",
      "✅ PCA plot saved: tki_embeddings_pca.png\n",
      "✅ Clustered data saved: tki_clustered_embeddings.csv\n",
      "✅ Cluster plot saved: tki_clusters.png\n",
      "✅ Cross‑val scores (4‑fold): [1. 1. 1. 1.]\n",
      "✅ Step 9 complete.\n",
      "🏃 View run Step 9: Model Application, Visualization, and Analysis at: http://127.0.0.1:5000/#/experiments/0/runs/16e8245b0c6144d69fff97dc15051cd2\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import joblib\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# ————————————— Load environment (if needed) —————————————\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# ————————————— Paths & Helpers —————————————\n",
    "EMBEDDINGS_CSV     = '../Embeddings/tki_embeddings.csv'\n",
    "LABEL_ENCODER_PKL  = '../Models/tki_label_encoder.pkl'\n",
    "RF_MODEL_PKL       = '../Models/tki_rf_model.pkl'\n",
    "\n",
    "def parse_embedding(embedding_str):\n",
    "    try:\n",
    "        return np.array(ast.literal_eval(embedding_str))\n",
    "    except Exception:\n",
    "        return np.array([])\n",
    "\n",
    "# ————————————— Main Run —————————————\n",
    "with mlflow.start_run(run_name=\"Step 9: Model Application, Visualization, and Analysis\"):\n",
    "\n",
    "    # Log inputs\n",
    "    mlflow.log_param(\"embeddings_csv\", EMBEDDINGS_CSV)\n",
    "    mlflow.log_param(\"label_encoder_pkl\", LABEL_ENCODER_PKL)\n",
    "    mlflow.log_param(\"rf_model_pkl\",      RF_MODEL_PKL)\n",
    "\n",
    "    # ---- 1. Load embeddings DataFrame ----\n",
    "    df = pd.read_csv(EMBEDDINGS_CSV, converters={'Embedding': parse_embedding})\n",
    "    print(f\"✅ Loaded {len(df)} rows from {EMBEDDINGS_CSV}\")\n",
    "\n",
    "    # Stack into X, extract raw labels y\n",
    "    X = np.stack(df['Embedding'].values)\n",
    "    raw_labels = df['Factor'].values   # use  'Factor'\n",
    "\n",
    "    # ---- 2. Load artifacts ----\n",
    "    label_encoder = joblib.load(LABEL_ENCODER_PKL)\n",
    "    rf_clf         = joblib.load(RF_MODEL_PKL)\n",
    "\n",
    "    # Encode labels\n",
    "    y = label_encoder.transform(raw_labels)\n",
    "\n",
    "    # ---- 3. PCA Visualization ----\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', alpha=0.7)\n",
    "    handles, _ = scatter.legend_elements()\n",
    "    plt.legend(handles, label_encoder.classes_, title=\"Factor\")\n",
    "    plt.xlabel(\"PCA Component 1\")\n",
    "    plt.ylabel(\"PCA Component 2\")\n",
    "    plt.title(\"PCA of TKI Embeddings\")\n",
    "    pca_plot = \"tki_embeddings_pca.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(pca_plot)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(pca_plot, artifact_path=\"visualization\")\n",
    "    print(f\"✅ PCA plot saved: {pca_plot}\")\n",
    "\n",
    "    # ---- 4. K‑Means Clustering ----\n",
    "    n_clusters = 5\n",
    "    mlflow.log_param(\"n_clusters\", n_clusters)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X)\n",
    "    df['Cluster'] = clusters\n",
    "\n",
    "    clustered_csv = \"tki_clustered_embeddings.csv\"\n",
    "    df.to_csv(clustered_csv, index=False)\n",
    "    mlflow.log_artifact(clustered_csv, artifact_path=\"clustering\")\n",
    "    print(f\"✅ Clustered data saved: {clustered_csv}\")\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='tab10', alpha=0.7)\n",
    "    plt.xlabel(\"PCA Component 1\")\n",
    "    plt.ylabel(\"PCA Component 2\")\n",
    "    plt.title(\"K‑Means Clusters of TKI Embeddings\")\n",
    "    cluster_plot = \"tki_clusters.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cluster_plot)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cluster_plot, artifact_path=\"visualization\")\n",
    "    print(f\"✅ Cluster plot saved: {cluster_plot}\")\n",
    "\n",
    "    # ---- 5. Safe Stratified CV ----\n",
    "    min_count    = df['Factor'].value_counts().min()\n",
    "    safe_splits  = min(5, min_count)\n",
    "    mlflow.log_param(\"safe_n_splits\", safe_splits)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=safe_splits, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(rf_clf, X, y, cv=cv, scoring='accuracy')\n",
    "    mlflow.log_metric(\"cv_mean_accuracy\", np.mean(cv_scores))\n",
    "    print(f\"✅ Cross‑val scores ({safe_splits}‑fold): {cv_scores}\")\n",
    "\n",
    "    # ---- 6. Finish ----\n",
    "    print(\"✅ Step 9 complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d8667c-30e8-4db0-8fca-03ccb53d773e",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 11: Test Model Directly** <a class=\"anchor\" id=\"tki_page_3\"></a>\n",
    "\n",
    "[Back to Top](#tki_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d8b6c39-c12d-4076-95e4-692d7a89371d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 20 rows\n",
      "Predicted Index for 'Active Energetic Activate Activator': Compromising\n",
      "Predicted Index for 'Calm Relaxed Soothing Pacify': Compromising\n",
      "Predicted Index for 'Curious Inquisitive Explore Investigator': Collaborating\n",
      "Predicted Index for 'Organized Meticulous Plan Planner': Collaborating\n",
      "Predicted Index for 'Moody Anxious Worry Worrier': Compromising\n",
      "Predicted Index for 'Unfriendly Stoic Indifferent Apathetic': Avoiding\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import joblib\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment & OpenAI client\n",
    "load_dotenv(override=True)\n",
    "def get_openai_api_key_from_file(filepath='~/openai_api_key.txt'):\n",
    "    filepath = os.path.expanduser(filepath)\n",
    "    with open(filepath) as f:\n",
    "        return f.read().strip()\n",
    "api_key = get_openai_api_key_from_file()\n",
    "client  = OpenAI(api_key=api_key)\n",
    "\n",
    "# Load the embeddings CSV, parsing the string back into arrays\n",
    "df = pd.read_csv(\n",
    "    '../Embeddings/tki_embeddings.csv',\n",
    "    converters={'Embedding': lambda s: np.array(ast.literal_eval(s))}\n",
    ")\n",
    "print(f\"✅ Loaded {len(df)} rows\")\n",
    "\n",
    "# Stack embeddings & extract the correct label column 'Index'\n",
    "X = np.stack(df['Embedding'].values)\n",
    "y = df['Factor'].values       # was 'Factor' before — use 'Index'\n",
    "\n",
    "# Load pretrained artifacts\n",
    "label_encoder = joblib.load('../Models/tki_label_encoder.pkl')\n",
    "clf           = joblib.load('../Models/tki_rf_model.pkl')\n",
    "\n",
    "# Function to get OpenAI embedding for new text\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    resp = client.embeddings.create(input=[text], model=model)\n",
    "    return resp.data[0].embedding\n",
    "\n",
    "# Prediction helper\n",
    "def predict_factor(new_text):\n",
    "    emb = get_embedding(new_text)\n",
    "    encoded = clf.predict([emb])[0]\n",
    "    return label_encoder.inverse_transform([encoded])[0]\n",
    "\n",
    "# Test on new examples\n",
    "test_texts = [\n",
    "    \"Active Energetic Activate Activator\",\n",
    "    \"Calm Relaxed Soothing Pacify\",\n",
    "    \"Curious Inquisitive Explore Investigator\",\n",
    "    \"Organized Meticulous Plan Planner\",\n",
    "    \"Moody Anxious Worry Worrier\",\n",
    "    \"Unfriendly Stoic Indifferent Apathetic\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    pred = predict_factor(text)\n",
    "    print(f\"Predicted Index for '{text}': {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "449f69a9-6e81-4d46-9b38-f7507243338c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Factor for 'Curious': Perceptual Reasoning Index (PRI)\n"
     ]
    }
   ],
   "source": [
    "# Test a single word or phrase\n",
    "test_text = \"Curious\"\n",
    "predicted_factor = predict_factor(test_text)\n",
    "print(f\"Predicted Factor for '{test_text}': {predicted_factor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6dba3c2-f6e1-4e26-a4c8-a0cc084763d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Factor for 'afraid': Verbal Comprehension Index (VCI)\n"
     ]
    }
   ],
   "source": [
    "# Test a single word or phrase\n",
    "test_text = \"afraid\"\n",
    "predicted_factor = predict_factor(test_text)\n",
    "print(f\"Predicted Factor for '{test_text}': {predicted_factor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6753f1a4-6f8b-499d-a267-9ee80d8fe097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Factor for 'scared': Processing Speed Index (PSI)\n"
     ]
    }
   ],
   "source": [
    "# Test a single word or phrase\n",
    "test_text = \"scared\"\n",
    "predicted_factor = predict_factor(test_text)\n",
    "print(f\"Predicted Factor for '{test_text}': {predicted_factor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89969172-6939-4347-a76b-bb8402e26584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Factor for 'sad': Processing Speed Index (PSI)\n"
     ]
    }
   ],
   "source": [
    "# Test a single word or phrase\n",
    "test_text = \"sad\"\n",
    "predicted_factor = predict_factor(test_text)\n",
    "print(f\"Predicted Factor for '{test_text}': {predicted_factor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed4e3183-7ca6-4f8f-94cd-cc5e8e9f6244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Factor for 'unemotional': Processing Speed Index (PSI)\n"
     ]
    }
   ],
   "source": [
    "# Test a single word or phrase\n",
    "test_text = \"unemotional\"\n",
    "predicted_factor = predict_factor(test_text)\n",
    "print(f\"Predicted Factor for '{test_text}': {predicted_factor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab54c21-ee36-4c0e-b9c4-445b11fa65ed",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 12: Test Neo4j Connection** <a class=\"anchor\" id=\"TKI_page_4\"></a>\n",
    "\n",
    "\n",
    "[Back to Top](#TKI_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce3fd307-5fcf-46d7-867d-78ecd5a83887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://localhost:7474/browser/\" target=\"_blank\">🔗 Open Neo4j Bolt Connection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Define Neo4j Browser URL\n",
    "neo4j_browser_url = \"http://localhost:7474/browser/\"\n",
    "\n",
    "# Create a clickable link\n",
    "html_code = f'<a href=\"{neo4j_browser_url}\" target=\"_blank\">🔗 Open Neo4j Bolt Connection</a>'\n",
    "\n",
    "# Display the clickable link in Jupyter Notebook\n",
    "display(HTML(html_code))\n",
    "\n",
    "# Open the Neo4j Browser in a new tab automatically\n",
    "webbrowser.open_new_tab(neo4j_browser_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a12796f0-11cb-40cb-8c48-e9e20760ed42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bolt port 7687 is reachable!\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "HOST = \"localhost\"\n",
    "PORT = 7687\n",
    "\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "result = sock.connect_ex((HOST, PORT))\n",
    "\n",
    "if result == 0:\n",
    "    print(f\"✅ Bolt port {PORT} is reachable!\")\n",
    "else:\n",
    "    print(f\"❌ Bolt port {PORT} is NOT reachable!\")\n",
    "\n",
    "sock.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3abeb19a-7681-4c01-bb52-3b567513142a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Python Connected Successfully: Connection successful!\n"
     ]
    }
   ],
   "source": [
    "from py2neo import Graph\n",
    "\n",
    "# Attempt connection with neo4j://\n",
    "NEO4J_URI = \"neo4j://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"mypassword\"\n",
    "\n",
    "try:\n",
    "    graph = Graph(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    result = graph.run(\"RETURN 'Connection successful!' AS message\").data()\n",
    "    print(\"✅ Python Connected Successfully:\", result[0][\"message\"])\n",
    "except Exception as e:\n",
    "    print(\"❌ Python Connection Failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54f9b222-dd9d-4205-b4ab-3221085fbe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n",
      "🏃 View run Test Neo4j Connection at: http://127.0.0.1:5000/#/experiments/576605481746526355/runs/273e189bc93e4c21950fd993236c53f2\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/576605481746526355\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from py2neo import Graph\n",
    "import mlflow\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# MLflow and Neo4j connection settings\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "\n",
    "# Set the MLflow tracking URI\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "# Set an experiment name\n",
    "mlflow.set_experiment(\"TKI\")\n",
    "#mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Function to test database connection\n",
    "def test_neo4j_connection(uri, user, password):\n",
    "    try:\n",
    "        # Connect to Neo4j\n",
    "        graph = Graph(uri, auth=(user, password))\n",
    "        # Run a simple query to test the connection\n",
    "        greeting = graph.run(\"RETURN 'Connection successful!' AS greeting\").data()\n",
    "        return greeting[0]['greeting']\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Start an MLFlow run\n",
    "with mlflow.start_run(run_name=\"Test Neo4j Connection\"):\n",
    "    # Log the test start\n",
    "    mlflow.log_param(\"Test\", \"Neo4j Connection\")\n",
    "    \n",
    "    # Test the Neo4j database connection\n",
    "    result = test_neo4j_connection(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
    "    \n",
    "    # Log the result of the connection test\n",
    "    mlflow.log_param(\"Connection Result\", result)\n",
    "    \n",
    "    # Output the result\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0ce307e-9ad1-4891-9f4f-8966af9ce07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Connection test result: Connection successful!\n",
      "🗑️  All nodes and relationships have been deleted.\n",
      "📊 Remaining node count after clear: 0\n",
      "🏃 View run Test & Clear Neo4j at: http://127.0.0.1:5000/#/experiments/616263351584470447/runs/5a6bfcdf38ab46f096d2f355b554550d\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/616263351584470447\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from py2neo import Graph\n",
    "import mlflow\n",
    "\n",
    "# ─── Load environment variables ────────────────────────────────────────────────\n",
    "load_dotenv()\n",
    "\n",
    "# ─── Neo4j connection settings ────────────────────────────────────────────────\n",
    "raw_uri    = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASS = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "# Normalize URI: use bolt:// if someone set neo4j://\n",
    "if raw_uri and raw_uri.startswith(\"neo4j://\"):\n",
    "    NEO4J_URI = raw_uri.replace(\"neo4j://\", \"bolt://\", 1)\n",
    "else:\n",
    "    NEO4J_URI = raw_uri\n",
    "\n",
    "# ─── MLflow tracking setup ────────────────────────────────────────────────────\n",
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(\"MCMI\")\n",
    "\n",
    "def test_neo4j_connection(uri, user, password):\n",
    "    graph = Graph(uri, auth=(user, password))\n",
    "    return graph.run(\"RETURN 'Connection successful!' AS greeting\").evaluate()\n",
    "\n",
    "# ─── Test & Clear Neo4j inside an MLflow run ──────────────────────────────────\n",
    "with mlflow.start_run(run_name=\"Test & Clear Neo4j\"):\n",
    "    # 1) Test connection\n",
    "    result = test_neo4j_connection(NEO4J_URI, NEO4J_USER, NEO4J_PASS)\n",
    "    mlflow.log_param(\"Connection Test\", result)\n",
    "    print(f\"🔗 Connection test result: {result}\")\n",
    "\n",
    "    # 2) Clear the entire database\n",
    "    graph = Graph(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASS))\n",
    "    graph.delete_all()\n",
    "    mlflow.log_param(\"Database Cleared\", True)\n",
    "    print(\"🗑️  All nodes and relationships have been deleted.\")\n",
    "\n",
    "    # 3) Confirm it's empty\n",
    "    remaining = graph.run(\"MATCH (n) RETURN count(n) AS nodes\").evaluate()\n",
    "    mlflow.log_param(\"Remaining Nodes\", remaining)\n",
    "    print(f\"📊 Remaining node count after clear: {remaining}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a2d41d-2f56-4b50-b4b1-77ebcd2c7279",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">\n",
    "\n",
    "# **Step 13: Create TKI Schema in Neo4j** <a class=\"anchor\" id=\"TKI_page_4\"></a>\n",
    "\n",
    "\n",
    "[Back to Top](#TKI_toc)\n",
    "\n",
    "<hr style=\"height:3px;border-width:0;color:Blue;background-color:Blue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "957e5833-d44d-401d-8df7-0b430efac4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Category         Factor  \\\n",
      "0  Conflict Mode      Competing   \n",
      "1  Conflict Mode      Competing   \n",
      "2  Conflict Mode      Competing   \n",
      "3  Conflict Mode      Competing   \n",
      "4  Conflict Mode  Collaborating   \n",
      "\n",
      "                                           Adjective      Synonym  \\\n",
      "0  Assertive and uncooperative mode, pursuing own...   Aggressive   \n",
      "1  Assertive and uncooperative mode, pursuing own...    Assertive   \n",
      "2  Assertive and uncooperative mode, pursuing own...     Dominant   \n",
      "3  Assertive and uncooperative mode, pursuing own...  Controlling   \n",
      "4  Assertive and cooperative mode, finding mutual...  Cooperative   \n",
      "\n",
      "          Verb           Noun  \\\n",
      "0      Compete    Competition   \n",
      "1       Assert      Assertion   \n",
      "2     Dominate      Dominance   \n",
      "3      Control        Control   \n",
      "4  Collaborate  Collaboration   \n",
      "\n",
      "                                           Embedding  \n",
      "0  [0.018110601231455803, 0.010554433800280094, 0...  \n",
      "1  [0.01708870381116867, 0.009367242455482483, 0....  \n",
      "2  [0.015169601887464523, 0.018460361286997795, 0...  \n",
      "3  [0.017812145873904228, 0.025348054245114326, 0...  \n",
      "4  [0.0023178826086223125, 0.013064720667898655, ...  \n",
      "🏃 View run Create TKI Schema in Neo4j at: http://127.0.0.1:5000/#/experiments/576605481746526355/runs/fa1d5d1f152047259ec008b102b2a897\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/576605481746526355\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from py2neo import Graph\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ─── Load environment ──────────────────────────────────────────────────────────\n",
    "load_dotenv(override=True)\n",
    "NEO4J_URI      = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USER     = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "MLFLOW_URI     = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "mlflow.set_experiment(\"TKI\")\n",
    "\n",
    "# ─── Load the flattened TKI embeddings CSV ────────────────────────────────────\n",
    "dataset_path = \"../Embeddings/tki_embeddings.csv\"\n",
    "tki_df = pd.read_csv(\n",
    "    dataset_path,\n",
    "    converters={'Embedding': lambda x: ast.literal_eval(x) if isinstance(x, str) else x}\n",
    ")\n",
    "\n",
    "def create_tki_schema(graph: Graph, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Build Neo4j graph with taxonomy:\n",
    "      TKI_Category -> TKI_Factor -> TKI_Adjective -> {Synonym, Verb, Noun, Embedding}\n",
    "    \"\"\"\n",
    "    for _, row in df.iterrows():\n",
    "        category  = row.get('Category',  'Unknown')\n",
    "        factor    = row.get('Factor',    'Unknown')\n",
    "        adjective = row.get('Adjective', 'Unknown')\n",
    "        synonym   = row.get('Synonym',   '')\n",
    "        verb      = row.get('Verb',      '')\n",
    "        noun      = row.get('Noun',      '')\n",
    "        embedding = row.get('Embedding') or []\n",
    "\n",
    "        # Skip if core fields missing\n",
    "        if not (category and factor and adjective):\n",
    "            continue\n",
    "\n",
    "        # 1) MERGE Category node\n",
    "        graph.run(\n",
    "            \"MERGE (c:TKI_Category {name:$category})\",\n",
    "            category=category\n",
    "        )\n",
    "\n",
    "        # 2) MERGE Factor node + link to Category\n",
    "        graph.run(\n",
    "            \"MERGE (f:TKI_Factor {name:$factor})\",\n",
    "            factor=factor\n",
    "        )\n",
    "        graph.run(\n",
    "            \"\"\"\n",
    "            MATCH (c:TKI_Category {name:$category}), (f:TKI_Factor {name:$factor})\n",
    "            MERGE (c)-[:TKI_HAS_FACTOR]->(f)\n",
    "            \"\"\",\n",
    "            category=category, factor=factor\n",
    "        )\n",
    "\n",
    "        # 3) MERGE Adjective node + link to Factor\n",
    "        graph.run(\n",
    "            \"MERGE (a:TKI_Adjective {name:$adjective})\",\n",
    "            adjective=adjective\n",
    "        )\n",
    "        graph.run(\n",
    "            \"\"\"\n",
    "            MATCH (f:TKI_Factor {name:$factor}), (a:TKI_Adjective {name:$adjective})\n",
    "            MERGE (f)-[:TKI_HAS_ADJECTIVE]->(a)\n",
    "            \"\"\",\n",
    "            factor=factor, adjective=adjective\n",
    "        )\n",
    "\n",
    "        # 4) MERGE Synonym, Verb, Noun under Adjective\n",
    "        if synonym:\n",
    "            graph.run(\"MERGE (s:TKI_Synonym {name:$synonym})\", synonym=synonym)\n",
    "            graph.run(\n",
    "                \"\"\"\n",
    "                MATCH (a:TKI_Adjective {name:$adjective}), (s:TKI_Synonym {name:$synonym})\n",
    "                MERGE (a)-[:TKI_HAS_SYNONYM]->(s)\n",
    "                \"\"\",\n",
    "                adjective=adjective, synonym=synonym\n",
    "            )\n",
    "        if verb:\n",
    "            graph.run(\"MERGE (v:TKI_Verb {name:$verb})\", verb=verb)\n",
    "            graph.run(\n",
    "                \"\"\"\n",
    "                MATCH (a:TKI_Adjective {name:$adjective}), (v:TKI_Verb {name:$verb})\n",
    "                MERGE (a)-[:TKI_HAS_VERB]->(v)\n",
    "                \"\"\",\n",
    "                adjective=adjective, verb=verb\n",
    "            )\n",
    "        if noun:\n",
    "            graph.run(\"MERGE (n:TKI_Noun {name:$noun})\", noun=noun)\n",
    "            graph.run(\n",
    "                \"\"\"\n",
    "                MATCH (a:TKI_Adjective {name:$adjective}), (n:TKI_Noun {name:$noun})\n",
    "                MERGE (a)-[:TKI_HAS_NOUN]->(n)\n",
    "                \"\"\",\n",
    "                adjective=adjective, noun=noun\n",
    "            )\n",
    "\n",
    "        # 5) Optionally attach Embedding to the Adjective\n",
    "        if embedding:\n",
    "            graph.run(\n",
    "                \"\"\"\n",
    "                MATCH (a:TKI_Adjective {name:$adjective})\n",
    "                MERGE (e:TKI_Embedding {value:$embedding})\n",
    "                MERGE (a)-[:TKI_HAS_EMBEDDING]->(e)\n",
    "                \"\"\",\n",
    "                adjective=adjective, embedding=embedding\n",
    "            )\n",
    "\n",
    "# ─── Execute under MLflow run ─────────────────────────────────────────────────\n",
    "with mlflow.start_run(run_name=\"Create TKI Schema in Neo4j\"):\n",
    "    graph = Graph(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    create_tki_schema(graph, tki_df)\n",
    "\n",
    "    mlflow.log_artifact(dataset_path, artifact_path=\"datasets\")\n",
    "    mlflow.log_param(\"rows\", tki_df.shape[0])\n",
    "    mlflow.log_param(\"cols\", tki_df.shape[1])\n",
    "\n",
    "    print(tki_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746cc0fc-8e2f-4f59-b0e8-75b663e2802b",
   "metadata": {},
   "source": [
    "```cypher\n",
    "// Pull in Category → Factor → Adjective → (Synonym, Verb, Noun)\n",
    "MATCH (c:TKI_Category)-[:TKI_HAS_FACTOR]->(f:TKI_Factor)\n",
    "OPTIONAL MATCH (f)-[:TKI_HAS_ADJECTIVE]->(a:TKI_Adjective)\n",
    "OPTIONAL MATCH (a)-[:TKI_HAS_SYNONYM  | :TKI_HAS_VERB | :TKI_HAS_NOUN]->(leaf)\n",
    "RETURN c, f, a, leaf\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca5e75-3b9b-45a1-997b-a5fe4b4b4d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (personality-models-env)",
   "language": "python",
   "name": "personality-models-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
